{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Optical Flow from Fused Lidar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/opt/psegs')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from psegs.exp.fused_lidar import FusedLidarCloudTableBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SemanticKITTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psegs.exp.semantic_kitti import SemanticKITTISDTable\n",
    "class SemanticKITTIFusedWorldCloudTable(FusedLidarCloudTableBase):\n",
    "    SRC_SD_TABLE = SemanticKITTISDTable\n",
    "    \n",
    "    @classmethod\n",
    "    def _should_build_obj_clouds(cls, segment_uri):\n",
    "        # SemanticKITTI has no cuboids, so we skip this step.\n",
    "        return False\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_task_lidar_cuboid_rdd(cls, spark, segment_uri):\n",
    "        seg_rdd = cls.SRC_SD_TABLE.get_segment_datum_rdd(spark, segment_uri)\n",
    "        \n",
    "        # SemanticKITTI has no cuboids, so the Fuser algo simply concats the cloud points\n",
    "        def iter_task_rows(iter_sds):\n",
    "            from pyspark import Row\n",
    "            from oarphpy.spark import RowAdapter\n",
    "            for sd in iter_sds:\n",
    "                if sd.point_cloud is not None:\n",
    "                    pc = sd.point_cloud\n",
    "                    task_id = \"%s.%s\" % (sd.uri.segment_id, pc.extra['semantic_kitti.scan_id'])\n",
    "                    yield Row(\n",
    "                        task_id=task_id,\n",
    "                        point_clouds=[pc],\n",
    "                        cuboids=[])\n",
    "        \n",
    "        task_rdd = seg_rdd.mapPartitions(iter_task_rows)\n",
    "        return task_rdd\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KITTI-360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psegs.datasets.kitti_360 import KITTI360SDTable\n",
    "class KITTI360OurFusedClouds(KITTI360SDTable):\n",
    "    INCLUDE_FISHEYES = False\n",
    "    INCLUDE_FUSED_CLOUDS = False  # Use our own fused clouds\n",
    "\n",
    "class KITTI360OurFusedWorldCloudTable(FusedLidarCloudTableBase):\n",
    "    SRC_SD_TABLE = KITTI360OurFusedClouds\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_task_lidar_cuboid_rdd(cls, spark, segment_uri):\n",
    "        datum_df = cls.SRC_SD_TABLE.get_segment_datum_df(spark, segment_uri)\n",
    "        datum_df.registerTempTable('datums')\n",
    "        spark.sql(\"\"\"\n",
    "          CACHE TABLE culi_tasks_df OPTIONS ( 'storageLevel' 'DISK_ONLY' ) AS\n",
    "          SELECT \n",
    "              CONCAT(uri.segment_id, '.', uri.extra.`kitti-360.frame_id`) AS task_id,\n",
    "              FLATTEN(COLLECT_LIST(cuboids)) AS cuboids, \n",
    "              COLLECT_LIST(point_cloud) AS point_clouds\n",
    "          FROM datums\n",
    "          WHERE \n",
    "              uri.topic LIKE '%cuboid%' OR uri.topic LIKE '%lidar%'\n",
    "          GROUP BY task_id\n",
    "        \"\"\")\n",
    "        tasks_df = spark.sql('SELECT * FROM culi_tasks_df')\n",
    "        return tasks_df.rdd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NuScenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nuscenes-devkit==1.1.2\n",
      "  Downloading nuscenes_devkit-1.1.2-py3-none-any.whl (282 kB)\n",
      "\u001b[K     |████████████████████████████████| 282 kB 16.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/lib/python3/dist-packages (from nuscenes-devkit==1.1.2) (0.22.2.post1)\n",
      "Collecting descartes\n",
      "  Downloading descartes-1.1.0-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from nuscenes-devkit==1.1.2) (1.6.0)\n",
      "Requirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (from nuscenes-devkit==1.1.2) (3.1.2)\n",
      "Requirement already satisfied: cachetools in /usr/lib/python3/dist-packages (from nuscenes-devkit==1.1.2) (4.0.0)\n",
      "Requirement already satisfied: Pillow in /usr/lib/python3/dist-packages (from nuscenes-devkit==1.1.2) (7.0.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nuscenes-devkit==1.1.2) (4.56.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from nuscenes-devkit==1.1.2) (1.20.1)\n",
      "Collecting pyquaternion>=0.9.5\n",
      "  Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n",
      "Collecting pycocotools>=2.0.1\n",
      "  Downloading pycocotools-2.0.2.tar.gz (23 kB)\n",
      "Collecting fire\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
      "\u001b[K     |████████████████████████████████| 87 kB 12.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyter\n",
      "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from nuscenes-devkit==1.1.2) (4.5.1.48)\n",
      "Collecting Shapely\n",
      "  Downloading Shapely-1.7.1-cp38-cp38-manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 30.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.8/dist-packages (from pycocotools>=2.0.1->nuscenes-devkit==1.1.2) (53.0.0)\n",
      "Collecting cython>=0.27.3\n",
      "  Using cached Cython-0.29.21-cp38-cp38-manylinux1_x86_64.whl (1.9 MB)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from fire->nuscenes-devkit==1.1.2) (1.15.0)\n",
      "Requirement already satisfied: termcolor in /usr/lib/python3/dist-packages (from fire->nuscenes-devkit==1.1.2) (1.1.0)\n",
      "Requirement already satisfied: notebook in /usr/local/lib/python3.8/dist-packages (from jupyter->nuscenes-devkit==1.1.2) (6.2.0)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.8/dist-packages (from jupyter->nuscenes-devkit==1.1.2) (7.6.3)\n",
      "Requirement already satisfied: jupyter-console in /usr/lib/python3/dist-packages (from jupyter->nuscenes-devkit==1.1.2) (6.0.0)\n",
      "Requirement already satisfied: ipykernel in /usr/lib/python3/dist-packages (from jupyter->nuscenes-devkit==1.1.2) (5.2.0)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.8/dist-packages (from jupyter->nuscenes-devkit==1.1.2) (6.0.7)\n",
      "Collecting qtconsole\n",
      "  Downloading qtconsole-5.0.2-py3-none-any.whl (119 kB)\n",
      "\u001b[K     |████████████████████████████████| 119 kB 77.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ipython>=4.0.0 in /usr/lib/python3/dist-packages (from ipywidgets->jupyter->nuscenes-devkit==1.1.2) (7.13.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->jupyter->nuscenes-devkit==1.1.2) (1.0.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /usr/lib/python3/dist-packages (from ipywidgets->jupyter->nuscenes-devkit==1.1.2) (5.0.4)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/lib/python3/dist-packages (from ipywidgets->jupyter->nuscenes-devkit==1.1.2) (4.3.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->jupyter->nuscenes-devkit==1.1.2) (3.5.1)\n",
      "Requirement already satisfied: pexpect in /usr/lib/python3/dist-packages (from ipython>=4.0.0->ipywidgets->jupyter->nuscenes-devkit==1.1.2) (4.6.0)\n",
      "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/lib/python3/dist-packages (from notebook->jupyter->nuscenes-devkit==1.1.2) (4.6.3)\n",
      "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->nuscenes-devkit==1.1.2) (20.1.0)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->nuscenes-devkit==1.1.2) (0.9.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->nuscenes-devkit==1.1.2) (2.11.3)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->nuscenes-devkit==1.1.2) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->nuscenes-devkit==1.1.2) (0.9.2)\n",
      "Requirement already satisfied: ipython-genutils in /usr/lib/python3/dist-packages (from notebook->jupyter->nuscenes-devkit==1.1.2) (0.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->nuscenes-devkit==1.1.2) (6.1)\n",
      "Requirement already satisfied: jupyter-client>=5.3.4 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->nuscenes-devkit==1.1.2) (6.1.11)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/lib/python3/dist-packages (from notebook->jupyter->nuscenes-devkit==1.1.2) (18.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from jupyter-client>=5.3.4->notebook->jupyter->nuscenes-devkit==1.1.2) (2.8.1)\n",
      "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.8/dist-packages (from terminado>=0.8.3->notebook->jupyter->nuscenes-devkit==1.1.2) (0.7.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from argon2-cffi->notebook->jupyter->nuscenes-devkit==1.1.2) (1.14.4)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0.0->argon2-cffi->notebook->jupyter->nuscenes-devkit==1.1.2) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/lib/python3/dist-packages (from jinja2->notebook->jupyter->nuscenes-devkit==1.1.2) (1.1.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->nuscenes-devkit==1.1.2) (0.6.0)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->nuscenes-devkit==1.1.2) (0.4.4)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->nuscenes-devkit==1.1.2) (0.5.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->nuscenes-devkit==1.1.2) (1.4.3)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->nuscenes-devkit==1.1.2) (2.7.4)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->nuscenes-devkit==1.1.2) (0.8.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->nuscenes-devkit==1.1.2) (0.1.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/lib/python3/dist-packages (from nbconvert->jupyter->nuscenes-devkit==1.1.2) (0.3)\n",
      "Requirement already satisfied: bleach in /usr/lib/python3/dist-packages (from nbconvert->jupyter->nuscenes-devkit==1.1.2) (3.1.1)\n",
      "Requirement already satisfied: async-generator in /usr/local/lib/python3.8/dist-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter->nuscenes-devkit==1.1.2) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.8/dist-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter->nuscenes-devkit==1.1.2) (1.5.1)\n",
      "Collecting qtpy\n",
      "  Downloading QtPy-1.9.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[K     |████████████████████████████████| 54 kB 5.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pycocotools, fire\n",
      "  Building wheel for pycocotools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.2-cp38-cp38-linux_x86_64.whl size=417538 sha256=ef2c6bb9201cd102b7b55286cc51be2411322964ec7f1d878490018f6a20bec2\n",
      "  Stored in directory: /root/.cache/pip/wheels/e7/77/b2/6f38b5bea571cd8f4689f91a7c1ed2eaecb2c2ce17f9945b17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115928 sha256=250a287c72334853836b4f2562fbbae1d0db70c960e555efb641af473db607d9\n",
      "  Stored in directory: /root/.cache/pip/wheels/1f/10/06/2a990ee4d73a8479fe2922445e8a876d38cfbfed052284c6a1\n",
      "Successfully built pycocotools fire\n",
      "Installing collected packages: qtpy, qtconsole, cython, Shapely, pyquaternion, pycocotools, jupyter, fire, descartes, nuscenes-devkit\n",
      "Successfully installed Shapely-1.7.1 cython-0.29.21 descartes-1.1.0 fire-0.4.0 jupyter-1.0.0 nuscenes-devkit-1.1.2 pycocotools-2.0.2 pyquaternion-0.9.9 qtconsole-5.0.2 qtpy-1.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install nuscenes-devkit==1.1.2\n",
    "from psegs.datasets.nuscenes import NuscStampedDatumTableBase\n",
    "class NuscFusedWorldCloudTable(FusedLidarCloudTableBase):\n",
    "    SRC_SD_TABLE = NuscStampedDatumTableBase\n",
    "    \n",
    "    SPLITS = ['train_detect', 'train_track']\n",
    "    \n",
    "    @classmethod\n",
    "    def _filter_ego_vehicle(cls, cloud_ego):\n",
    "        cloud_ego = cloud_ego[np.where(  ~(\n",
    "                        (cloud_ego[:, 0] <= 1.5) & (cloud_ego[:, 0] >= -1.5) &  # Nusc lidar +x is +right\n",
    "                        (cloud_ego[:, 1] <= 2.5) & (cloud_ego[:, 0] >= -2.5) &  # Nusc lidar +y is +forward\n",
    "                        (cloud_ego[:, 1] <= 1.5) & (cloud_ego[:, 0] >= -1.5)   # Nusc lidar +z is +up\n",
    "        ))]\n",
    "        return cloud_ego\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_task_lidar_cuboid_rdd(cls, spark, segment_uri):\n",
    "        datum_df = cls.SRC_SD_TABLE.get_segment_datum_df(spark, segment_uri)\n",
    "        datum_df.registerTempTable('datums')\n",
    "        \n",
    "        if cls.SRC_SD_TABLE.LABELS_KEYFRAMES_ONLY:\n",
    "            # For Nusc: group by nuscenes-sample-token WITH KEYFRAMES\n",
    "            spark.sql(\"\"\"\n",
    "              CACHE TABLE culi_tasks_df OPTIONS ( 'storageLevel' 'DISK_ONLY' ) AS\n",
    "              SELECT \n",
    "                  uri.extra.`nuscenes-sample-token` AS task_id,\n",
    "                  FLATTEN(COLLECT_LIST(cuboids)) AS cuboids, \n",
    "                  COLLECT_LIST(point_cloud) AS point_clouds\n",
    "              FROM datums\n",
    "              WHERE \n",
    "                uri.extra.`nuscenes-is-keyframe` = 'True' AND (\n",
    "                  uri.extra['nuscenes-label-channel'] is NULL OR \n",
    "                  uri.extra['nuscenes-label-channel'] LIKE '%LIDAR%'\n",
    "                ) AND (\n",
    "                  uri.topic LIKE '%cuboid%' OR\n",
    "                  uri.topic LIKE '%lidar%'\n",
    "                )\n",
    "              GROUP BY task_id\n",
    "            \"\"\")\n",
    "        else:\n",
    "            # For Nusc: group by nuscenes-sample-token WITH ALL FRAMES\n",
    "            spark.sql(\"\"\"\n",
    "              CACHE TABLE culi_tasks_df OPTIONS ( 'storageLevel' 'DISK_ONLY' ) AS\n",
    "              SELECT \n",
    "                  CONCAT(uri.segment_id, '.', uri.timestamp) AS task_id,\n",
    "                  FLATTEN(COLLECT_LIST(cuboids)) AS cuboids, \n",
    "                  COLLECT_LIST(point_cloud) AS point_clouds\n",
    "              FROM datums\n",
    "              WHERE \n",
    "                (\n",
    "                  uri.extra['nuscenes-label-channel'] is NULL OR \n",
    "                  uri.extra['nuscenes-label-channel'] LIKE '%LIDAR%'\n",
    "                ) AND (\n",
    "                  uri.topic LIKE '%cuboid%' OR\n",
    "                  uri.topic LIKE '%lidar%'\n",
    "                )\n",
    "              GROUP BY task_id\n",
    "              HAVING SIZE(cuboids) > 0 AND SIZE(pcs) > 0\n",
    "            \"\"\")\n",
    "        \n",
    "        tasks_df = spark.sql('SELECT * FROM culi_tasks_df')\n",
    "        return tasks_df.rdd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-13 03:26:04,550\toarph 48 : Using source root /opt/psegs/psegs \n",
      "2021-02-13 03:26:04,551\toarph 48 : Using source root /opt/psegs \n",
      "2021-02-13 03:26:04,620\toarph 48 : Generating egg to /tmp/tmpkk0zf6m2_oarphpy_eggbuild ...\n",
      "2021-02-13 03:26:04,702\toarph 48 : ... done.  Egg at /tmp/tmpkk0zf6m2_oarphpy_eggbuild/psegs-0.0.0-py3.8.egg\n"
     ]
    }
   ],
   "source": [
    "from psegs.spark import NBSpark\n",
    "spark = NBSpark.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Fused Lidar Assets\n",
    "\n",
    "```\n",
    "docker --context default run -it --name=potree_viewer --rm --net=host -v `pwd`:/shared  jonazpiazu/potree\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-13 03:26:10,155\tps   48 : Creating shelve caches; will use ~8-10GB of RAM ...\n",
      "2021-02-13 03:26:56,931\tps   48 : ... NuScenes done loading & indexing JSON data ...\n",
      "2021-02-13 03:26:56,931\tps   48 : Building shelve cache for category (in /tmp/psegs_temp/nuscenes/v1.0-trainval/category) ...\n",
      "2021-02-13 03:26:56,948\tps   48 : Building shelve cache for attribute (in /tmp/psegs_temp/nuscenes/v1.0-trainval/attribute) ...\n",
      "2021-02-13 03:26:56,952\tps   48 : Building shelve cache for visibility (in /tmp/psegs_temp/nuscenes/v1.0-trainval/visibility) ...\n",
      "2021-02-13 03:26:56,955\tps   48 : Building shelve cache for instance (in /tmp/psegs_temp/nuscenes/v1.0-trainval/instance) ...\n",
      "2021-02-13 03:26:57,589\tps   48 : Building shelve cache for sensor (in /tmp/psegs_temp/nuscenes/v1.0-trainval/sensor) ...\n",
      "2021-02-13 03:26:57,592\tps   48 : Building shelve cache for calibrated_sensor (in /tmp/psegs_temp/nuscenes/v1.0-trainval/calibrated_sensor) ...\n",
      "2021-02-13 03:26:57,691\tps   48 : Building shelve cache for ego_pose (in /tmp/psegs_temp/nuscenes/v1.0-trainval/ego_pose) ...\n",
      "2021-02-13 03:27:25,213\tps   48 : Building shelve cache for log (in /tmp/psegs_temp/nuscenes/v1.0-trainval/log) ...\n",
      "2021-02-13 03:27:25,216\tps   48 : Building shelve cache for scene (in /tmp/psegs_temp/nuscenes/v1.0-trainval/scene) ...\n",
      "2021-02-13 03:27:25,225\tps   48 : Building shelve cache for sample (in /tmp/psegs_temp/nuscenes/v1.0-trainval/sample) ...\n",
      "2021-02-13 03:27:25,948\tps   48 : Building shelve cache for sample_data (in /tmp/psegs_temp/nuscenes/v1.0-trainval/sample_data) ...\n"
     ]
    }
   ],
   "source": [
    "seg_uris = NuscFusedWorldCloudTable.get_all_segment_uris()\n",
    "sd_rdd = NuscFusedWorldCloudTable._get_segment_datum_rdd_or_df(spark, seg_uris[0])\n",
    "print(sd_rdd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
