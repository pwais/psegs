{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Optical Flow from Fused Lidar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/opt/psegs')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from psegs.exp.fused_lidar_flow import FusedLidarCloudTableBase\n",
    "from psegs.exp.fused_lidar_flow import TaskLidarCuboidCameraDFFactory\n",
    "\n",
    "import IPython.display\n",
    "import PIL.Image\n",
    "\n",
    "\n",
    "## General Notebook Utilities\n",
    "    \n",
    "def imshow(x):\n",
    "    IPython.display.display(PIL.Image.fromarray(x))\n",
    "\n",
    "def show_html(x):\n",
    "    from IPython.core.display import display, HTML\n",
    "    display(HTML(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SemanticKITTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psegs.exp.semantic_kitti import SemanticKITTISDTable\n",
    "\n",
    "class SemanticKITTILCCDFFactory(TaskLidarCuboidCameraDFFactory):\n",
    "    \n",
    "    SRC_SD_TABLE = SemanticKITTISDTable\n",
    "    \n",
    "    @classmethod\n",
    "    def build_df_for_segment(cls, spark, segment_uri):\n",
    "        seg_rdd = cls.SRC_SD_TABLE.get_segment_datum_rdd(spark, segment_uri)\n",
    "        \n",
    "        def to_task_row(scan_id_iter_sds):\n",
    "            scan_id, iter_sds = scan_id_iter_sds\n",
    "            camera_images = []\n",
    "            point_clouds = []\n",
    "            for sd in iter_sds:\n",
    "                if sd.camera_image is not None:\n",
    "                    camera_images.append(sd)\n",
    "                elif sd.point_cloud is not None:\n",
    "                    point_clouds.append(sd)\n",
    "            \n",
    "            from pyspark import Row\n",
    "            r = Row(\n",
    "                    task_id=int(scan_id),\n",
    "                    pc_sds=point_clouds,\n",
    "                    cuboids_sds=[], # SemanticKITTI has no cuboids\n",
    "                    ci_sds=camera_images) \n",
    "            from oarphpy.spark import RowAdapter\n",
    "            return RowAdapter.to_row(r)\n",
    "            \n",
    "        grouped = seg_rdd.groupBy(lambda sd: sd.uri.extra['semantic_kitti.scan_id'])\n",
    "        row_rdd = grouped.map(to_task_row)\n",
    "\n",
    "        df = spark.createDataFrame(row_rdd, schema=cls.table_schema())\n",
    "        df = df.persist()\n",
    "        return df\n",
    "\n",
    "class SemanticKITTIFusedWorldCloudTable(FusedLidarCloudTableBase):\n",
    "    TASK_DF_FACTORY = SemanticKITTILCCDFFactory\n",
    "\n",
    "    # SemanticKITTI has no cuboids, so we skip this step.\n",
    "    HAS_OBJ_CLOUDS = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KITTI-360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psegs.datasets.kitti_360 import KITTI360SDTable\n",
    "class KITTI360OurFusedClouds(KITTI360SDTable):\n",
    "    INCLUDE_FISHEYES = False\n",
    "    INCLUDE_FUSED_CLOUDS = False  # Use our own fused clouds\n",
    "\n",
    "class KITTI360OurFusedWorldCloudTable(FusedLidarCloudTableBase):\n",
    "    SRC_SD_TABLE = KITTI360OurFusedClouds\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_task_lidar_cuboid_rdd(cls, spark, segment_uri):\n",
    "        datum_df = cls.SRC_SD_TABLE.get_segment_datum_df(spark, segment_uri)\n",
    "        datum_df.registerTempTable('datums')\n",
    "        spark.catalog.dropTempView('culi_tasks_df')\n",
    "        print('Building tasks table for %s ...' % segment_uri.segment_id)\n",
    "        spark.sql(\"\"\"\n",
    "          CACHE TABLE culi_tasks_df OPTIONS ( 'storageLevel' 'DISK_ONLY' ) AS\n",
    "          SELECT \n",
    "              CONCAT(uri.segment_id, '.', uri.extra.`kitti-360.frame_id`) AS task_id,\n",
    "              FLATTEN(COLLECT_LIST(cuboids)) AS cuboids, \n",
    "              COLLECT_LIST(point_cloud) AS point_clouds\n",
    "          FROM datums\n",
    "          WHERE \n",
    "              uri.topic LIKE '%cuboid%' OR uri.topic LIKE '%lidar%'\n",
    "          GROUP BY task_id\n",
    "        \"\"\")\n",
    "        \n",
    "        \n",
    "        # TODO! for lidar and camera image!\n",
    "        #         both_have_ego_pose = (\n",
    "        #             ci1.extra.get('kitti-360.has-valid-ego-pose') and\n",
    "        #             ci2.extra.get('kitti-360.has-valid-ego-pose'))\n",
    "        \n",
    "        tasks_df = spark.sql('SELECT * FROM culi_tasks_df')\n",
    "        print('... done.')\n",
    "        return tasks_df.rdd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NuScenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# !pip3 install nuscenes-devkit==1.1.2\n",
    "from psegs.datasets.nuscenes import NuscStampedDatumTableBase, NuscStampedDatumTableLabelsAllFrames\n",
    "class NuscFusedWorldCloudTableBase(FusedLidarCloudTableBase):\n",
    "    #SRC_SD_TABLE = NuscStampedDatumTableBase -- Subclass must pick a NuScenes configuration!\n",
    "    \n",
    "    SPLITS = ['train_detect', 'train_track']\n",
    "    \n",
    "    @classmethod\n",
    "    def _filter_ego_vehicle(cls, cloud_ego):\n",
    "        # Note: NuScenes authors have already corrected clouds for ego motion:\n",
    "        # https://github.com/nutonomy/nuscenes-devkit/issues/481#issuecomment-716250423\n",
    "        # But have not filtered out ego self-returns\n",
    "        cloud_ego = cloud_ego[np.where(  ~(\n",
    "                        (cloud_ego[:, 0] <= 1.5) & (cloud_ego[:, 0] >= -1.5) &  # Nusc lidar +x is +right\n",
    "                        (cloud_ego[:, 1] <= 2.5) & (cloud_ego[:, 0] >= -2.5) &  # Nusc lidar +y is +forward\n",
    "                        (cloud_ego[:, 1] <= 1.5) & (cloud_ego[:, 0] >= -1.5)    # Nusc lidar +z is +up\n",
    "        ))]\n",
    "        return cloud_ego\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_task_lidar_cuboid_rdd(cls, spark, segment_uri):\n",
    "        datum_df = cls.SRC_SD_TABLE.get_segment_datum_df(spark, segment_uri)\n",
    "        datum_df.registerTempTable('datums')\n",
    "        spark.catalog.dropTempView('culi_tasks_df')\n",
    "        print('Building tasks table for %s ...' % segment_uri.segment_id)\n",
    "        if cls.SRC_SD_TABLE.LABELS_KEYFRAMES_ONLY:\n",
    "            # For Nusc: group by nuscenes-sample-token WITH KEYFRAMES\n",
    "            spark.sql(\"\"\"\n",
    "              CACHE TABLE culi_tasks_df OPTIONS ( 'storageLevel' 'DISK_ONLY' ) AS\n",
    "              SELECT \n",
    "                  uri.extra.`nuscenes-sample-token` AS task_id,\n",
    "                  FLATTEN(COLLECT_LIST(cuboids)) AS cuboids, \n",
    "                  COLLECT_LIST(point_cloud) AS point_clouds\n",
    "              FROM datums\n",
    "              WHERE \n",
    "                uri.extra.`nuscenes-is-keyframe` = 'True' AND (\n",
    "                  uri.extra['nuscenes-label-channel'] is NULL OR \n",
    "                  uri.extra['nuscenes-label-channel'] LIKE '%LIDAR%'\n",
    "                ) AND (\n",
    "                  uri.topic LIKE '%cuboid%' OR\n",
    "                  uri.topic LIKE '%lidar%'\n",
    "                )\n",
    "              GROUP BY task_id\n",
    "            \"\"\")\n",
    "        else:\n",
    "            # For Nusc: group by nuscenes-sample-token WITH ALL FRAMES\n",
    "            spark.sql(\"\"\"\n",
    "              CACHE TABLE culi_tasks_df OPTIONS ( 'storageLevel' 'DISK_ONLY' ) AS\n",
    "              SELECT \n",
    "                  CONCAT(uri.segment_id, '.', uri.timestamp) AS task_id,\n",
    "                  FLATTEN(COLLECT_LIST(cuboids)) AS cuboids, \n",
    "                  COLLECT_LIST(point_cloud) AS point_clouds\n",
    "              FROM datums\n",
    "              WHERE \n",
    "                (\n",
    "                  uri.extra['nuscenes-label-channel'] is NULL OR \n",
    "                  uri.extra['nuscenes-label-channel'] LIKE '%LIDAR%'\n",
    "                ) AND (\n",
    "                  uri.topic LIKE '%cuboid%' OR\n",
    "                  uri.topic LIKE '%lidar%'\n",
    "                )\n",
    "              GROUP BY task_id\n",
    "              HAVING SIZE(cuboids) > 0 AND SIZE(point_clouds) > 0\n",
    "            \"\"\")\n",
    "        \n",
    "        tasks_df = spark.sql('SELECT * FROM culi_tasks_df')\n",
    "        print('... done.')\n",
    "        return tasks_df.rdd\n",
    "\n",
    "class NuscFusedWorldCloudKeyframesOnlyTable(NuscFusedWorldCloudTableBase):\n",
    "    SRC_SD_TABLE = NuscStampedDatumTableBase\n",
    "\n",
    "class NuscFusedWorldCloudAllFramesTable(NuscFusedWorldCloudTableBase):\n",
    "    SRC_SD_TABLE = NuscStampedDatumTableLabelsAllFrames\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 21:37:23,149\toarph 2168770 : Using source root /opt/psegs/psegs \n",
      "2021-02-19 21:37:23,150\toarph 2168770 : Using source root /opt/psegs \n",
      "2021-02-19 21:37:23,247\toarph 2168770 : Generating egg to /tmp/tmphise9bk1_oarphpy_eggbuild ...\n",
      "2021-02-19 21:37:23,337\toarph 2168770 : ... done.  Egg at /tmp/tmphise9bk1_oarphpy_eggbuild/psegs-0.0.0-py3.8.egg\n"
     ]
    }
   ],
   "source": [
    "from psegs.spark import NBSpark\n",
    "spark = NBSpark.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Fused Lidar Assets\n",
    "\n",
    "```\n",
    "docker --context default run -it --name=potree_viewer --rm --net=host -v `pwd`:/shared  jonazpiazu/potree\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# T = KITTI360OurFusedWorldCloudTable\n",
    "# rdds = T._create_datum_rdds(spark)\n",
    "# print([r.count() for r in rdds])\n",
    "\n",
    "# seg_uris = T.get_all_segment_uris()\n",
    "# samp = T.get_sample(seg_uris[0], spark=spark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print([lc.sensor_name for lc in samp.lidar_clouds][:10])\n",
    "# c = samp.lidar_clouds[0]#[lc for lc in samp.lidar_clouds if lc.sensor_name == '11002'][0]\n",
    "# print(c.get_cloud().shape)\n",
    "# imshow(c.get_bev_debug_image(x_bounds_meters=None, y_bounds_meters=None))\n",
    "# imshow(c.get_front_rv_debug_image(y_bounds_meters=None, z_bounds_meters=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Candidate Optical Flow Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 21:37:26,682\tps   2168770 : Found Sequence 00 with 4541 scans\n",
      "2021-02-19 21:37:26,683\tps   2168770 : Found Sequence 01 with 1101 scans\n",
      "2021-02-19 21:37:26,686\tps   2168770 : Found Sequence 02 with 4661 scans\n",
      "2021-02-19 21:37:26,687\tps   2168770 : Found Sequence 03 with 801 scans\n",
      "2021-02-19 21:37:26,688\tps   2168770 : Found Sequence 05 with 2761 scans\n",
      "2021-02-19 21:37:26,689\tps   2168770 : Found Sequence 06 with 1101 scans\n",
      "2021-02-19 21:37:26,690\tps   2168770 : Found Sequence 07 with 1101 scans\n",
      "2021-02-19 21:37:26,691\tps   2168770 : Found Sequence 09 with 1591 scans\n",
      "2021-02-19 21:37:26,692\tps   2168770 : Found Sequence 10 with 1201 scans\n",
      "2021-02-19 21:37:26,692\tps   2168770 : Found 18859 total scans\n",
      "2021-02-19 21:37:26,693\tps   2168770 : Filtering to only 1 segments\n",
      "2021-02-19 21:37:26,694\tps   2168770 : Finding scans for sequence 00 with no moving points ...\n",
      "2021-02-19 21:37:33,102\tps   2168770 : ... sequence 00 has 3097 scans with no movers.\n",
      "2021-02-19 21:37:47,578\tps   2168770 : Filtering to only 1 segments\n",
      "2021-02-19 21:37:47,578\tps   2168770 : SemanticKITTIFusedWorldCloudTable building fused clouds ...\n",
      "2021-02-19 21:37:47,579\tps   2168770 : ... have 1 segments to fuse ...\n",
      "2021-02-19 21:37:47,580\tps   2168770 : ... working on 00 ...\n",
      "2021-02-19 21:37:47,581\tps   2168770 : ... skipping 00; world and obj clouds done\n",
      "2021-02-19 21:37:47,581\tps   2168770 : World Cloud: /opt/psegs/dataroot/fused_world_clouds/naive_cuboid_scrubber/semantikitti/train/00/fused_world.ply\n",
      "2021-02-19 21:37:47,582\tps   2168770 : Obj Clouds: /opt/psegs/dataroot/fused_obj_clouds/naive_cuboid_scrubber/semantikitti/train/00\n",
      "2021-02-19 21:37:47,589\toarph 2168770 : Progress for \n",
      "FuseEachSegment [Pid:2168770 Id:139967877409520]\n",
      "-----------------------  ---------------\n",
      "Thruput\n",
      "N thru                   1 (of 1)\n",
      "N chunks                 1\n",
      "Total time               0 seconds\n",
      "Total thru               0 bytes\n",
      "Rate                     0.0 bytes / sec\n",
      "Hz                       337\n",
      "Progress\n",
      "Percent Complete         100.000000\n",
      "Est. Time To Completion  0 seconds\n",
      "-----------------------  ---------------\n",
      "2021-02-19 21:37:47,589\tps   2168770 : ... SemanticKITTIFusedWorldCloudTable done fusing clouds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num tasks 3097\n",
      "restrict to 50\n",
      "running map.. count\n"
     ]
    }
   ],
   "source": [
    "from psegs.exp.fused_lidar_flow import OpticalFlowRenderBase\n",
    "\n",
    "class SemanticKITTIOFlowRenderer(OpticalFlowRenderBase):\n",
    "    FUSED_LIDAR_SD_TABLE = SemanticKITTIFusedWorldCloudTable\n",
    "    MAX_TASKS_PER_SEGMENT = 50\n",
    "\n",
    "R = SemanticKITTIOFlowRenderer\n",
    "seg_uris = R.FUSED_LIDAR_SD_TABLE.get_all_segment_uris()\n",
    "R.build(spark=spark, only_segments=[seg_uris[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
