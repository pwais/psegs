{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cheap Optical Flow: Is it Good? Does it Boost?\n",
    "\n",
    "\n",
    "## Quickstart\n",
    "\n",
    "## Credits\n",
    "\n",
    "Some portions of this notebook adapted from:\n",
    " * [Middlebury Flow code by Johannes Oswald](https://github.com/Johswald/flow-code-python/blob/master/readFlowFile.py)\n",
    " * [DeepDeform Demo Code](https://github.com/AljazBozic/DeepDeform)\n",
    " * [OpticalFlowToolkit by RUOTENG LI](https://github.com/liruoteng/OpticalFlowToolkit)\n",
    " * [OpenCV Samples](https://github.com/opencv/opencv/blob/master/samples/python/opt_flow.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "SHOW_DEMO_OUTPUT = True\n",
    "DEMO_FPS = []\n",
    "\n",
    "RUN_FULL_ANALYSIS = False\n",
    "ALL_FP_FACTORY_CLSS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup\n",
    "\n",
    "!pip3 install pypng scikit-image\n",
    "print('fixme installs')\n",
    "print()\n",
    "print()\n",
    "\n",
    "import copy\n",
    "import imageio\n",
    "import IPython.display\n",
    "import math\n",
    "import os\n",
    "import PIL.Image\n",
    "import six\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "\n",
    "## General Notebook Utilities\n",
    "    \n",
    "def imshow(x):\n",
    "    IPython.display.display(PIL.Image.fromarray(x))\n",
    "\n",
    "def show_html(x):\n",
    "    from IPython.core.display import display, HTML\n",
    "    display(HTML(x))\n",
    "\n",
    "    \n",
    "PLOTLY_INIT_HTML = \"\"\"\n",
    "    <script src='https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js'></script>\n",
    "    <script>requirejs.config({\n",
    "        paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});\n",
    "        if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>\n",
    "    \"\"\"\n",
    "\n",
    "if SHOW_DEMO_OUTPUT:\n",
    "    show_html(PLOTLY_INIT_HTML)\n",
    "\n",
    "## Create a random temporary directory for analysis library (for Spark-enabled full analysis mode)\n",
    "old_cwd = os.getcwd()\n",
    "tempdir = tempfile.TemporaryDirectory(suffix='_cheap_optical_flow_eval_analysis')\n",
    "ALIB_SRC_DIR = tempdir.name\n",
    "print(\"Putting analysis lib in %s\" % ALIB_SRC_DIR)\n",
    "os.chdir(ALIB_SRC_DIR)\n",
    "!mkdir -p cheap_optical_flow_eval_analysis\n",
    "!touch cheap_optical_flow_eval_analysis/__init__.py\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append(ALIB_SRC_DIR)\n",
    "\n",
    "\n",
    "## Prepare a build of local psegs for inclusion\n",
    "!cd /opt/psegs && python3 setup.py clean bdist_egg\n",
    "PSEGS_EGG_PATH = '/opt/psegs/dist/psegs-0.0.1-py3.8.egg'\n",
    "assert os.path.exists(PSEGS_EGG_PATH), \"Build failed?\"\n",
    "sys.path.append('/opt/psegs')\n",
    "import psegs\n",
    "\n",
    "\n",
    "## Prepare Spark session with local PSegs and local Analysis Lib\n",
    "from psegs.spark import NBSpark\n",
    "NBSpark.SRC_ROOT = os.path.join(ALIB_SRC_DIR, 'cheap_optical_flow_eval_analysis')\n",
    "NBSpark.CONF_KV.update({\n",
    "    'spark.driver.maxResultSize': '2g',\n",
    "    'spark.driver.memory': '16g',\n",
    "    'spark.submit.pyFiles': PSEGS_EGG_PATH,\n",
    "  })\n",
    "spark = NBSpark.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cheap_optical_flow_eval_analysis/ofp.py\n",
    "\n",
    "## Data Model & Utility Code\n",
    "\n",
    "import attr\n",
    "import cv2\n",
    "import imageio\n",
    "import math\n",
    "import os\n",
    "import PIL.Image\n",
    "import six\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from psegs import datum\n",
    "\n",
    "from oarphpy import plotting as op_plt\n",
    "from oarphpy.spark import CloudpickeledCallable\n",
    "img_to_data_uri = lambda x: op_plt.img_to_data_uri(x, format='png')\n",
    "\n",
    "@attr.s(slots=True, eq=False, weakref_slot=False)\n",
    "class OpticalFlowPair(object):\n",
    "    \"\"\"A flyweight for a pair of images with an optical flow field.\n",
    "    Supports lazy-loading of large data attributes.\"\"\"\n",
    "    \n",
    "    ## Core Attributes (Required for All Datasets)\n",
    "    \n",
    "    dataset = attr.ib(type=str, default='')\n",
    "    \"\"\"(Display name) To which dataset does this pair belong?\"\"\"\n",
    "    \n",
    "    id1 = attr.ib(type=str, default='')\n",
    "    \"\"\"Identifier or URI for the first image\"\"\"\n",
    "    \n",
    "    id2 = attr.ib(type=str, default='')\n",
    "    \"\"\"Identifier or URI for the second image\"\"\"\n",
    "    \n",
    "    img1 = attr.ib(default=None)\n",
    "    \"\"\"URI or numpy array or CloudPickleCallable for the first image (source image)\"\"\"\n",
    "\n",
    "    img2 = attr.ib(default=None)\n",
    "    \"\"\"URI or numpy array or CloudpickeledCallable for the second image (target image)\"\"\"\n",
    "    \n",
    "    flow = attr.ib(default=None)\n",
    "    \"\"\"A numpy array or callable or CloudpickeledCallable representing optical flow from img1 -> img2\"\"\"\n",
    "    \n",
    "    uri = attr.ib(type=datum.URI, default=None, converter=datum.URI.from_str)\n",
    "    \"\"\"A URI addressing this pair; to make dynamic construction of the pair easier\"\"\"\n",
    "    \n",
    "    \n",
    "    ## Optional Attributes (For Select Datasets)\n",
    "    \n",
    "    diff_time_sec = attr.ib(type=float, default=0.0)\n",
    "    \"\"\"Difference in time (in seconds) between the views / poses depicted in `img1` and `img2`.\"\"\"\n",
    "    \n",
    "    translation_meters = attr.ib(type=float, default=0.0)\n",
    "    \"\"\"Difference in ego translation (in meters) between the views / poses depicted in `img1` and `img2`.\"\"\"\n",
    "    \n",
    "    uvdviz_im1 = attr.ib(default=None)\n",
    "    \"\"\"An nx4 numpy array representing UVD-visible points for `img1`\"\"\"\n",
    "    \n",
    "    uvdviz_im2 = attr.ib(default=None)\n",
    "    \"\"\"An nx4 numpy array representing UVD-visible points for `img2`\"\"\"\n",
    "    \n",
    "    K = attr.ib(default=None)\n",
    "    \"\"\"A 3x3 numpy array representing the camera matrix K for both views\"\"\"\n",
    "    \n",
    "    # to add:\n",
    "    # semantic image for frame 1, frame 2 [could be painted by cuboids]\n",
    "    # instance images for frame 1, frame 2 [could be painted by cuboids]\n",
    "    #   -- for colored images, at first just pivot all oflow metrics by colors\n",
    "    # get uvdviz1 uvdviz2 (scene flow)\n",
    "    #   * for deepeform, their load_flow will work\n",
    "    #   * for kitti, we have to read their disparity images\n",
    "    # get uvd1 uvd2 (lidar for nearest neighbor stuff)\n",
    "    # depth image for frame 1, frame 2 [could be interpolated by cuboids]\n",
    "    #   -- at first bucket the depth coarsely and pivot al oflow by colors\n",
    "    \n",
    "    def get_img1(self):\n",
    "        if isinstance(self.img1, CloudpickeledCallable):\n",
    "            self.img1 = self.img1()\n",
    "        if isinstance(self.img1, six.string_types):\n",
    "            self.img1 = imageio.imread(self.img1)\n",
    "        return self.img1\n",
    "    \n",
    "    def get_img2(self):\n",
    "        if isinstance(self.img2, CloudpickeledCallable):\n",
    "            self.img2 = self.img2()\n",
    "        if isinstance(self.img2, six.string_types):\n",
    "            self.img2 = imageio.imread(self.img2)\n",
    "        return self.img2\n",
    "    \n",
    "    def get_flow(self):\n",
    "        if not isinstance(self.flow, (np.ndarray, np.generic)):\n",
    "            self.flow = self.flow()\n",
    "        return self.flow\n",
    "    \n",
    "    def has_scene_flow(self):\n",
    "        return (self.uvdviz_im1 is not None and self.uvdviz_im2 is not None and self.K is not None)\n",
    "    \n",
    "    def get_sf_viz_html(self):\n",
    "        uvd1 = self.uvdviz_im1[self.uvdviz_im1[:, -1] == 1, :3]\n",
    "        uvd2 = self.uvdviz_im2[self.uvdviz_im2[:, -1] == 1, :3]\n",
    "        xyzrgb1 = uvd_to_xyzrgb(uvd1, self.K, imgs=[self.get_img1()])\n",
    "        xyzrgb2 = uvd_to_xyzrgb(uvd2, self.K, imgs=[self.get_img2()])\n",
    "        html1 = create_xyzrgb_3d_plot_html(xyzrgb1)\n",
    "        html2 = create_xyzrgb_3d_plot_html(xyzrgb2)\n",
    "        \n",
    "        html = \"View 1:<br />%s<br /><br />View 2:<br />%s\" % (html1, html2)\n",
    "        return html\n",
    "    \n",
    "    def to_html(self):\n",
    "        im1 = self.get_img1()\n",
    "        im2 = self.get_img2()\n",
    "        flow = self.get_flow()\n",
    "        fviz = draw_flow(im1, flow)\n",
    "        \n",
    "        sf_html = ''\n",
    "        if self.has_scene_flow():\n",
    "            sf_html = \"\"\"\n",
    "                <tr><td style=\"text-align:left\"><b>Scene Flow</b></td></tr>\n",
    "                <tr><td>{viz_html}</td></tr>\n",
    "            \"\"\".format(viz_html=self.get_sf_viz_html())\n",
    "        \n",
    "        html = \"\"\"\n",
    "            \n",
    "            <table>\n",
    "            \n",
    "            <tr><td style=\"text-align:left\"><b>Dataset:</b> {dataset}</td></tr>\n",
    "            <tr><td style=\"text-align:left\"><b>URI:</b> {uri}</td></tr>\n",
    "            \n",
    "            <tr><td style=\"text-align:left\"><b>Source Image:</b> {id1}</td></tr>\n",
    "            <tr><td><img src=\"{im1}\" /></td></tr>\n",
    "\n",
    "            <tr><td style=\"text-align:left\"><b>Target Image:</b> {id2}</td></tr>\n",
    "            <tr><td><img src=\"{im2}\" /></td></tr>\n",
    "\n",
    "            <tr><td style=\"text-align:left\"><b>Flow</b></td></tr>\n",
    "            <tr><td><img src=\"{fviz}\" /></td></tr>\n",
    "            \n",
    "            {sf_html}\n",
    "            </table>\n",
    "        \"\"\".format(\n",
    "                dataset=self.dataset,\n",
    "                uri=str(self.uri),\n",
    "                id1=self.id1, id2=self.id2,\n",
    "                im1=img_to_data_uri(im1), im2=img_to_data_uri(im2),\n",
    "                fviz=img_to_data_uri(fviz),\n",
    "                sf_html=sf_html)\n",
    "        return html\n",
    "\n",
    "def draw_flow(img, flow, step=8):\n",
    "    \"\"\"Based upon OpenCV sample: https://github.com/opencv/opencv/blob/master/samples/python/opt_flow.py\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    y, x = np.mgrid[step/2:h:step, step/2:w:step].reshape(2,-1).astype(int)\n",
    "    fx, fy = flow[y,x].T\n",
    "    lines = np.vstack([x, y, x+fx, y+fy]).T.reshape(-1, 2, 2)\n",
    "    lines = np.int32(lines + 0.5)\n",
    "    vis = img.copy()\n",
    "    cv2.polylines(vis, lines, 0, (0, 255, 0))\n",
    "    for (x1, y1), (_x2, _y2) in lines:\n",
    "        cv2.circle(vis, (x1, y1), 1, (0, 255, 0), -1)\n",
    "    return vis\n",
    "\n",
    "def uvd_to_xyzrgb(uvd, K, imgs=None):\n",
    "    import numpy as np\n",
    "    from psegs import datum\n",
    "    \n",
    "    fx = K[0, 0]\n",
    "    cx = K[0, 2]\n",
    "    fy = K[1, 1]\n",
    "    cy = K[1, 2]\n",
    "    \n",
    "    rays = np.zeros((uvd.shape[0], 3))\n",
    "    rays[:, 0] = (uvd[:, 0] - cx) / fx\n",
    "    rays[:, 1] = (uvd[:, 1] - cy) / fy\n",
    "    rays[:, 2] = 1.\n",
    "    rays /= np.linalg.norm(rays, axis=-1)[:, np.newaxis]\n",
    "    xyz = uvd[:, 2][:, np.newaxis] * rays\n",
    "    \n",
    "    from psegs import datum\n",
    "    pc = datum.PointCloud(cloud=xyz)\n",
    "    cis = [datum.CameraImage(image_factory=lambda: img, K=K) for img in (imgs or [])]\n",
    "    xyzrgb = datum.PointCloud.paint_ego_cloud(xyz, camera_images=cis)\n",
    "    return xyzrgb\n",
    "\n",
    "def create_xyzrgb_3d_plot_html(xyzrgb, max_points=10000):\n",
    "    import plotly\n",
    "    import plotly.graph_objects as go\n",
    "    import pandas as pd\n",
    "\n",
    "    pcloud_df = pd.DataFrame(xyzrgb, columns=['x', 'y', 'z', 'r', 'g', 'b'])\n",
    "    pcloud_df = pcloud_df.sample(n=min(xyzrgb.shape[0], max_points))\n",
    "    scatter = go.Scatter3d(\n",
    "                x=pcloud_df['x'], y=pcloud_df['y'], z=pcloud_df['z'],\n",
    "                mode='markers',\n",
    "                marker=dict(size=3, color=pcloud_df[['r', 'g', 'b']], opacity=0.9))\n",
    "    fig = go.Figure(data=[scatter])\n",
    "    fig.update_layout(\n",
    "            width=900, height=600,\n",
    "            scene_camera=dict(\n",
    "                up=dict(x=0, y=-1, z=0),\n",
    "                center=dict(x=0, y=0, z=0),\n",
    "                eye=dict(x=1.25, y=-1.25, z=-1.25)\n",
    "            ),\n",
    "            scene_aspectmode='data')\n",
    "    \n",
    "#     trace0 = go.Scatter(\n",
    "#       x=[1, 2, 3, 4],\n",
    "#       y=[10, 15, 13, 17]\n",
    "#     )\n",
    "#     fig = go.Figure(data=[trace0])\n",
    "    \n",
    "    center = xyzrgb[:, :3].mean(axis=0)\n",
    "    footer = \"<i>Showing %s of %s points with mean (%s, %s, %s)</i>\" % (\n",
    "                    len(pcloud_df), xyzrgb.shape[0], center[0], center[1], center[2])\n",
    "    \n",
    "    return fig.to_html(include_plotlyjs=False, full_html=False) + '<br/>' + footer\n",
    "#     fig_html = plotly.offline.plot(fig, include_plotlyjs=True, output_type='file', filename='/tmp/yay.html')\n",
    "    \n",
    "#     return \"<iframe>\" + open('/tmp/yay.html').read() + \"</iframe>\"\n",
    "# #     return fig.to_html(full_html=False, include_plotlyjs=\"cdn\")\n",
    "# #     html = \"\"\"\n",
    "# #         <iframe>\n",
    "# #         <html><head>\n",
    "# #             <script type=\"text/javascript\">\n",
    "# #                 if (typeof require !== 'undefined') {{\n",
    "# #                 require.undef(\"plotly\");\n",
    "# #                 requirejs.config({{\n",
    "# #                     paths: {{\n",
    "# #                         'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
    "# #                     }}\n",
    "# #                 }});\n",
    "# #                 require(['plotly'], function(Plotly) {{\n",
    "# #                     window._Plotly = Plotly;\n",
    "# #                 }});\n",
    "# #                 }}\n",
    "# #         </script></head>\n",
    "# #         <body>\"\"\" + fig_html + \"\"\"\n",
    "# #         <div id=\"7979e646-13e6-4f44-8d32-d8effc3816df\" style=\"height: 525; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"7979e646-13e6-4f44-8d32-d8effc3816df\", [{\"x\": [1, 2, 3], \"y\": [3, 1, 6]}], {}, {\"showLink\": false, \"linkText\": \"\"})</script>\n",
    "# #         </body>        \n",
    "# #         </iframe>\n",
    "# #         \"\"\"\n",
    "# #     return html\n",
    "\n",
    "class FlowPairFactoryBase(object):\n",
    "    DATASET = ''\n",
    "\n",
    "    @classmethod\n",
    "    def list_fp_uris(cls, spark):\n",
    "        return []\n",
    "    \n",
    "    @classmethod\n",
    "    def get_fp_rdd_for_uris(cls, spark, uris):\n",
    "        uris = [datum.URI.from_str(u) for u in uris]\n",
    "        uris = [u for u in uris if u.dataset == cls.DATASET]\n",
    "        if not uris:\n",
    "            return None\n",
    "        return cls._get_fp_rdd_for_uris(spark, uris)\n",
    "\n",
    "    @classmethod\n",
    "    def _get_fp_rdd_for_uris(cls, spark, uris):\n",
    "        return None\n",
    "\n",
    "class FlowPairUnionFactory(FlowPairFactoryBase):\n",
    "    FACTORIES = []\n",
    "    \n",
    "    @classmethod\n",
    "    def list_fp_uris(cls, spark):\n",
    "        import itertools\n",
    "        return list(itertools.chain.from_iterable(F.list_fp_uris(spark) for F in cls.FACTORIES))\n",
    "    \n",
    "    @classmethod\n",
    "    def get_fp_rdd_for_uris(cls, spark, uris):\n",
    "        rdds = []\n",
    "        for F in cls.FACTORIES:\n",
    "            rdd = F.get_fp_rdd_for_uris(spark, uris)\n",
    "            if rdd is not None:\n",
    "                rdds.append(rdd)\n",
    "        assert rdds, \"No RDDs for %s\" % uris\n",
    "        return spark.sparkContext.union(rdds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from cheap_optical_flow_eval_analysis.ofp import *\n",
    "\n",
    "# # from plotly.offline import init_notebook_mode, iplot\n",
    "# # from plotly.graph_objs import *\n",
    "\n",
    "# # # init_notebook_mode(connected=False)         # initiate notebook for offline plot\n",
    "\n",
    "# # trace0 = Scatter(\n",
    "# #   x=[1, 2, 3, 4],\n",
    "# #   y=[10, 15, 13, 17]\n",
    "# # )\n",
    "# # trace1 = Scatter(\n",
    "# #   x=[1, 2, 3, 4],\n",
    "# #   y=[16, 5, 11, 9]\n",
    "# # )\n",
    "\n",
    "# # iplot([trace0, trace1])  \n",
    "\n",
    "# # from IPython.core.display import display, HTML\n",
    "# # omg finally!\n",
    "# show_html('''\n",
    "#             <script src='https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js'></script>\n",
    "#             <script>requirejs.config({\n",
    "#                 paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});\n",
    "#                 if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>\n",
    "#                 ''')\n",
    "\n",
    "# # import plotly\n",
    "# # plotly.offline.init_notebook_mode(connected=True)\n",
    "# show_html(fp.to_html())\n",
    "\n",
    "# # import plotly\n",
    "# # plotly.__version__\n",
    "# with open('/opt/psegs/tast.html', 'w') as f:\n",
    "#     f.write(fp.to_html())\n",
    "# # import IPython\n",
    "# # IPython.display.HTML(filename='/opt/psegs/tast.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Middlebury Optical Flow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO talk configs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cheap_optical_flow_eval_analysis/midd.py\n",
    "\n",
    "from psegs import datum\n",
    "\n",
    "from cheap_optical_flow_eval_analysis.ofp import *\n",
    "\n",
    "# Please unzip `other-color-allframes.zip` and `other-gt-flow.zip` to a directory and provide the target below:\n",
    "MIDD_DATA_ROOT = '/opt/psegs/ext_data/middlebury-flow/'\n",
    "\n",
    "# For the Middlebury Flow dataset, we only consider the real scenes\n",
    "MIDD_SCENES = [\n",
    "    {\n",
    "        'input': 'other-data/Dimetrodon/frame10.png',\n",
    "        'expected_out': 'other-data/Dimetrodon/frame11.png',\n",
    "        'flow_gt': 'other-gt-flow/Dimetrodon/flow10.flo',\n",
    "    },\n",
    "        {\n",
    "        'input': 'other-data/Hydrangea/frame10.png',\n",
    "        'expected_out': 'other-data/Hydrangea/frame11.png',\n",
    "        'flow_gt': 'other-gt-flow/Hydrangea/flow10.flo',\n",
    "    },\n",
    "        {\n",
    "        'input': 'other-data/RubberWhale/frame10.png',\n",
    "        'expected_out': 'other-data/RubberWhale/frame11.png',\n",
    "        'flow_gt': 'other-gt-flow/RubberWhale/flow10.flo',\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "def midd_read_flow(path):\n",
    "    import os\n",
    "    import numpy as np\n",
    "    # Based upon: https://github.com/Johswald/flow-code-python/blob/master/readFlowFile.py\n",
    "    # compute colored image to visualize optical flow file .flo\n",
    "    # Author: Johannes Oswald, Technical University Munich\n",
    "    # Contact: johannes.oswald@tum.de\n",
    "    # Date: 26/04/2017\n",
    "    # For more information, check http://vision.middlebury.edu/flow/ \n",
    "    assert os.path.exists(path) and path.endswith('.flo'), path\n",
    "    f = open(path, 'rb')\n",
    "    flo_number = np.fromfile(f, np.float32, count=1)[0]\n",
    "    TAG_FLOAT = 202021.25\n",
    "    assert flo_number == TAG_FLOAT, 'Flow number %r incorrect.' % flo_number\n",
    "    w = np.fromfile(f, np.int32, count=1)\n",
    "    h = np.fromfile(f, np.int32, count=1)\n",
    "\n",
    "    #if error try: data = np.fromfile(f, np.float32, count=2*w[0]*h[0])\n",
    "    data = np.fromfile(f, np.float32, count=int(2*w*h))\n",
    "\n",
    "    # Reshape data into 3D array (columns, rows, bands)\n",
    "    flow = np.resize(data, (int(h), int(w), 2))\t\n",
    "    f.close()\n",
    "\n",
    "    # We found that there are some invalid (?) (i.e. very large) flows, so we're going\n",
    "    # to ignore those for this experiment.\n",
    "    invalid = (flow >= 1666)\n",
    "    flow[invalid] = 0\n",
    "\n",
    "    return flow\n",
    "\n",
    "def midd_create_fp(uri):\n",
    "    scene_idx = int(uri.extra['midd.scene_idx'])\n",
    "    scene = MIDD_SCENES[scene_idx]\n",
    "    data_root = uri.extra['midd.dataroot']\n",
    "    return OpticalFlowPair(\n",
    "                uri=uri,\n",
    "                dataset=\"Middlebury Optical Flow\",\n",
    "                id1=scene['input'],\n",
    "                img1='file://' + os.path.join(data_root, scene['input']),\n",
    "                id2=scene['expected_out'],\n",
    "                img2='file://' + os.path.join(data_root, scene['expected_out']),\n",
    "                flow=CloudpickeledCallable(lambda: midd_read_flow(os.path.join(data_root, scene['flow_gt']))))\n",
    "    \n",
    "\n",
    "class MiddFactory(FlowPairFactoryBase):\n",
    "    DATASET = 'midd_oflow'\n",
    "    \n",
    "    @classmethod\n",
    "    def list_fp_uris(cls, spark):\n",
    "        return [\n",
    "            datum.URI(dataset=cls.DATASET, extra={'midd.scene_idx': i, 'midd.dataroot': MIDD_DATA_ROOT})\n",
    "            for i, scene in enumerate(MIDD_SCENES)\n",
    "        ]\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_fp_rdd_for_uris(cls, spark, uris):\n",
    "        uri_rdd = spark.sparkContext.parallelize(uris)\n",
    "        fp_rdd = uri_rdd.map(midd_create_fp)\n",
    "        return fp_rdd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cheap_optical_flow_eval_analysis.midd import MiddFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ALL_FP_FACTORY_CLSS.append(MiddFactory)\n",
    "\n",
    "print(\"Found %s Midd scenes\" % len(MiddFactory.list_fp_uris(spark)))\n",
    "\n",
    "if SHOW_DEMO_OUTPUT:\n",
    "    demo_uris = MiddFactory.list_fp_uris(spark)\n",
    "    fp_rdd = MiddFactory.get_fp_rdd_for_uris(spark, demo_uris)\n",
    "    fps = fp_rdd.collect()\n",
    "    \n",
    "    for fp in fps:\n",
    "        show_html(fp.to_html() + \"<br/><br/><br/>\")\n",
    "        DEMO_FPS.append(fp)\n",
    "\n",
    "# for i, scene in enumerate(MIDD_SCENES):\n",
    "#     p = OpticalFlowPair(\n",
    "#             dataset=\"Middlebury Optical Flow\",\n",
    "#             id1=scene['input'],\n",
    "#             img1='file://' + os.path.join(MIDD_DATA_ROOT, scene['input']),\n",
    "#             id2=scene['expected_out'],\n",
    "#             img2='file://' + os.path.join(MIDD_DATA_ROOT, scene['expected_out']),\n",
    "#             flow=CloudpickeledCallable(lambda: midd_read_flow(os.path.join(MIDD_DATA_ROOT, scene['flow_gt']))))\n",
    "    \n",
    "#     if RUN_FULL_ANALYSIS:\n",
    "#         ALL_FPS.append(copy.deepcopy(p))\n",
    "    \n",
    "#     if SHOW_DEMO_OUTPUT:\n",
    "#         show_html(p.to_html() + \"<br/><br/><br/>\")\n",
    "#         DEMO_FPS.append(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepDeform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cheap_optical_flow_eval_analysis/deepdeform.py\n",
    "\n",
    "from psegs import datum\n",
    "\n",
    "from cheap_optical_flow_eval_analysis.ofp import *\n",
    "\n",
    "# Please extract deepdeform_v1.7z to a directory and provide the target below:\n",
    "DD_DATA_ROOT = '/opt/psegs/ext_data/deepdeform_v1/'\n",
    "\n",
    "def dd_load_raw_flow(path):\n",
    "    # Based upon https://github.com/AljazBozic/DeepDeform/blob/master/utils.py#L1\n",
    "    import shutil\n",
    "    import struct\n",
    "    import os\n",
    "    import numpy as np\n",
    "\n",
    "    # Flow is stored row-wise in order [channels, height, width].\n",
    "    assert os.path.isfile(path), path\n",
    "\n",
    "    flow_gt = None\n",
    "    with open(path, 'rb') as fin:\n",
    "        width = struct.unpack('I', fin.read(4))[0]\n",
    "        height = struct.unpack('I', fin.read(4))[0]\n",
    "        channels = struct.unpack('I', fin.read(4))[0]\n",
    "        n_elems = height * width * channels\n",
    "\n",
    "        flow = struct.unpack('f' * n_elems, fin.read(n_elems * 4))\n",
    "        raw_flow_gt = np.asarray(flow, dtype=np.float32).reshape([channels, height, width])\n",
    "    return raw_flow_gt\n",
    "\n",
    "def dd_load_oflow(path):\n",
    "    raw_flow_gt = dd_load_raw_flow(path)\n",
    "\n",
    "    # Match format used in this analysis\n",
    "    flow_gt = np.moveaxis(raw_flow_gt, 0, -1) # (h, w, 2)\n",
    "    invalid_flow = flow_gt == -np.Inf\n",
    "    flow_gt[invalid_flow] = 0.0\n",
    "    return flow_gt\n",
    "\n",
    "def dd_load_depth_meters(path):\n",
    "    import imageio\n",
    "    \n",
    "    # \"Every pixel contains 3 values for flow in x, y and z direction, in meters\"\n",
    "    depth_img_raw = imageio.imread(path)\n",
    "    d_meters = depth_img_raw.astype('float64') / 1000.\n",
    "    return d_meters\n",
    "\n",
    "def dd_load_sflow(sflow_path):\n",
    "    # NB: we actually ignore the the DeepDeform SceneFlow data since it appears to be\n",
    "    # deduced from the optical flow / visual point correspondence.  So we just\n",
    "    # do the same deduction but capture the Scene Flow in uvd form; Deep\n",
    "    # Deform has it in (x, y, z) [meters]\n",
    "    raw_flow = dd_load_raw_flow(sflow_path.replace('.sflow', '.oflow').replace('scene_flow', 'optical_flow'))\n",
    "    raw_flow = np.moveaxis(raw_flow, 0, -1) # (h, w, 2)\n",
    "    \n",
    "    # File name format: {obj_id}_{src_frame}_{dest_frame}.sflow\n",
    "    obj_id, src_id, target_id = os.path.basename(sflow_path).replace('.sflow', '').split('_')\n",
    "    \n",
    "    # So we need the depth for frame 1 at least\n",
    "    depth_path1 = os.path.join(os.path.dirname(sflow_path), '../depth/%s.png' % src_id)\n",
    "    depth_path2 = os.path.join(os.path.dirname(sflow_path), '../depth/%s.png' % target_id)\n",
    "    \n",
    "    d1 = dd_load_depth_meters(depth_path1)\n",
    "    d2 = dd_load_depth_meters(depth_path2)\n",
    "    \n",
    "    h, w = d1.shape[:2]\n",
    "    px_y = np.tile(np.arange(h)[:, np.newaxis], [1, w])\n",
    "    px_x = np.tile(np.arange(w)[np.newaxis, :], [h, 1])\n",
    "    pxy = np.concatenate([px_y[:,:,np.newaxis], px_x[:, :, np.newaxis]], axis=-1)\n",
    "    pxy = pxy.astype(np.float32)\n",
    "    \n",
    "    uvd1 = np.dstack([pxy, d1]).reshape([-1, 3])\n",
    "    uvd2 = np.dstack([pxy + raw_flow, d2]).reshape([-1, 3])\n",
    "    \n",
    "    uvdviz_im1 = np.zeros((uvd1.shape[0], 4))\n",
    "    uvdviz_im1[:, :3] = uvd1\n",
    "    uvdviz_im1[:, -1] = (raw_flow != -np.Inf).reshape([-1, 2])[:, 0]\n",
    "    \n",
    "    uvdviz_im2 = np.zeros((uvd2.shape[0], 4))\n",
    "    uvdviz_im2[:, :3] = uvd2\n",
    "    uvdviz_im2[:, -1] = (uvdviz_im2[:, 0] != -np.Inf)\n",
    "    \n",
    "    return uvdviz_im1, uvdviz_im2\n",
    "\n",
    "\n",
    "# def dd_load_sflow(path):\n",
    "#     # Based upon https://github.com/AljazBozic/DeepDeform/blob/master/utils.py#L1\n",
    "#     import shutil\n",
    "#     import struct\n",
    "#     import os\n",
    "#     import numpy as np\n",
    "#     import imageio\n",
    "\n",
    "#     # Scene Flow is stored row-wise in order [channels (x, y, z), height, width].\n",
    "#     assert os.path.isfile(path)\n",
    "\n",
    "#     flow_gt = None\n",
    "#     with open(path, 'rb') as fin:\n",
    "#         width = struct.unpack('I', fin.read(4))[0]\n",
    "#         height = struct.unpack('I', fin.read(4))[0]\n",
    "#         channels = struct.unpack('I', fin.read(4))[0]\n",
    "#         n_elems = height * width * channels\n",
    "#         flow = struct.unpack('f' * n_elems, fin.read(n_elems * 4))\n",
    "#         flow_gt = np.asarray(flow, dtype=np.float32).reshape([channels, height, width])\n",
    "\n",
    "#     sflow_gt = np.moveaxis(flow_gt, 0, -1) # (h, w, 3)\n",
    "        \n",
    "#     # \"Every pixel contains 3 values for flow in x, y and z direction, in meters\"\n",
    "#     # So we need the depth for frame 1 at least\n",
    "#     obj_id, src_id, target_id = os.path.basename(path).replace('.sflow', '').split('_')\n",
    "#     depth_path = os.path.join(os.path.dirname(path), '../depth/%s.png' % src_id)\n",
    "#     depth_img_raw = imageio.imread(depth_path)\n",
    "    \n",
    "#     # \"depth images as 16-bit .png (divide by 1000 to obtain depth in meters)\"\n",
    "#     d_uvd_meters = depth_img_raw.astype('float64') / 1000.\n",
    "        \n",
    "#     sflow_uv_dxyz = np.dstack([d_uvd_meters[:, :, np.newaxis], sflow_gt])\n",
    "#     return sflow_uv_dxyz\n",
    "\n",
    "\n",
    "# def dd_convert_sflow(K, sflow_uv_dxyz):\n",
    "#     import numpy as np\n",
    "\n",
    "#     h, w = sflow_uv_dxyz.shape[:2]\n",
    "#     px_y = np.tile(np.arange(h)[:, np.newaxis], [1, w])\n",
    "#     px_x = np.tile(np.arange(w)[np.newaxis, :], [h, 1])\n",
    "#     pxy = np.concatenate([px_y[:,:,np.newaxis], px_x[:, :, np.newaxis]], axis=-1)\n",
    "\n",
    "    \n",
    "#     sflow_uv_ijdxyz = np.dstack([pxy, sflow_uv_dxyz])\n",
    "#     sflow_ijdxyz = sflow_uv_ijdxyz.reshape([-1, 6])\n",
    "    \n",
    "#     # Trim invalid / invisible\n",
    "#     sflow_ijdxyz = sflow_ijdxyz[sflow_ijdxyz[:, -1] != -np.Inf]\n",
    "\n",
    "#     uvdviz_im1 = np.ones((sflow_ijdxyz.shape[0], 4))\n",
    "#     uvdviz_im1[:, 0] = sflow_ijdxyz[:, 1]\n",
    "#     uvdviz_im1[:, 1] = sflow_ijdxyz[:, 0]\n",
    "#     uvdviz_im1[:, 2] = sflow_ijdxyz[:, 2]\n",
    "\n",
    "#     fx, fy, cx, cy = K[0, 0], K[1, 1], K[0, 2], K[1, 2]\n",
    "#     rays = np.zeros((h, w, 3))\n",
    "#     rays[:, :, 0] = (rays[:, :, 0] - cy) / fy\n",
    "#     rays[:, :, 1] = (rays[:, :, 1] - cx) / fx\n",
    "#     rays[:, :, 2] = 1\n",
    "#     rays /= np.linalg.norm(rays, axis=-1)[:, :, np.newaxis]\n",
    "\n",
    "#     yxz_1 = rays * sflow_uv_dxyz[:, :, 0][:, :, np.newaxis]\n",
    "#     yxz_2 = yxz_1 + sflow_uv_dxyz[:, :, (2, 1, 3)]\n",
    "#     xyz_2 = yxz_2[:, :, (1, 0, 2)]\n",
    "    \n",
    "#     xyz_2_valid = xyz_2.reshape([-1, 3])\n",
    "#     xyz_2_valid = xyz_2_valid[xyz_2_valid[:, 0] != -np.Inf]\n",
    "    \n",
    "#     # nawwww use the oflow look at the paper they prolly are inferring SF from oflow and depth \n",
    "    \n",
    "#     # DeepDeform scene flow is always visible -> visible\n",
    "#     assert xyz_2_valid.shape[0] == uvdviz_im1.shape[0], (xyz_2_valid.shape, uvdviz_im1.shape)\n",
    "    \n",
    "#     uvd2 = K[:3, :3].dot(xyz_2_valid.T)\n",
    "#     uvd2[0:2, :] /= uvd2[2, :]\n",
    "#     uvd2 = uvd2.T\n",
    "    \n",
    "#     uvdviz_im2 = np.ones((xyz_2_valid.shape[0], 4))\n",
    "#     uvdviz_im2[:, 0:3] = uvd2\n",
    "    \n",
    "    \n",
    "# #     uvdviz_im2[:, 0] = (fx * xyz_2_valid[:, 0]) / (xyz_2_valid[:, 2] + cx)\n",
    "# #     uvdviz_im2[:, 1] = (fy * xyz_2_valid[:, 1]) / (xyz_2_valid[:, 2] + cy)\n",
    "# #     uvdviz_im2[:, 2] = np.linalg.norm(xyz_2_valid, axis=1)\n",
    "    \n",
    "#     return uvdviz_im1, uvdviz_im2\n",
    "\n",
    "def dd_create_fp(uri):\n",
    "    if \"dd.sf_gt\" in uri.extra:\n",
    "        K = dd_read_K(os.path.join(DD_DATA_ROOT, uri.extra['dd.K']))\n",
    "        uvdviz_im1, uvdviz_im2 = dd_load_sflow(os.path.join(DD_DATA_ROOT, uri.extra[\"dd.sf_gt\"]))\n",
    "    else:\n",
    "        K = None\n",
    "        uvdviz_im1 = None\n",
    "        uvdviz_im2 = None\n",
    "    return OpticalFlowPair(\n",
    "                uri=uri,\n",
    "                dataset=\"DeepDeform Semi-Synthetic Optical Flow\",\n",
    "                id1=uri.extra['dd.input'],\n",
    "                img1='file://' + os.path.join(DD_DATA_ROOT, uri.extra['dd.input']),\n",
    "                id2=uri.extra['dd.expected_out'],\n",
    "                img2='file://' + os.path.join(DD_DATA_ROOT, uri.extra['dd.expected_out']),\n",
    "                flow=dd_load_oflow(os.path.join(DD_DATA_ROOT, uri.extra['dd.flow_gt'])),\n",
    "        \n",
    "                K=K[:3, :3],\n",
    "                uvdviz_im1=uvdviz_im1,\n",
    "                uvdviz_im2=uvdviz_im2)\n",
    "\n",
    "def dd_read_K(path):\n",
    "    import numpy as np\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "    lines = [l for l in lines if l]\n",
    "    K = np.array([[float(ll) for ll in l.split(' ') if ll] for l in lines])\n",
    "    return K\n",
    "\n",
    "class DDFactory(FlowPairFactoryBase):\n",
    "    DATASET = 'deep_deform'\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_all_scenes(cls):\n",
    "        import json\n",
    "        DD_ALIGNMENTS = json.load(open(os.path.join(DD_DATA_ROOT, 'train_alignments.json')))\n",
    "        ALL_DD_SCENES = [\n",
    "            {\n",
    "                \"dd.input\": ascene['source_color'],\n",
    "                \"dd.expected_out\": ascene['target_color'],\n",
    "                \"dd.flow_gt\": ascene['optical_flow'],\n",
    "                \"dd.sf_gt\": ascene['scene_flow'],\n",
    "                \"dd.K\": os.path.join(os.path.dirname(ascene['scene_flow']), '../intrinsics.txt'),\n",
    "            }\n",
    "            for ascene in DD_ALIGNMENTS\n",
    "        ]\n",
    "        return ALL_DD_SCENES\n",
    "    \n",
    "    @classmethod\n",
    "    def list_fp_uris(cls, spark):\n",
    "        scenes = cls._get_all_scenes()\n",
    "        return [\n",
    "            datum.URI(dataset=cls.DATASET, extra=scene)\n",
    "            for scene in scenes\n",
    "        ]\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_fp_rdd_for_uris(cls, spark, uris):\n",
    "        uri_rdd = spark.sparkContext.parallelize(uris)\n",
    "        fp_rdd = uri_rdd.map(dd_create_fp)\n",
    "        return fp_rdd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cheap_optical_flow_eval_analysis.deepdeform import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from psegs import datum\n",
    "\n",
    "DD_DEMO_URIS = [\n",
    "    datum.URI(dataset=DDFactory.DATASET, extra={\n",
    "        \"dd.input\": \"train/seq000/color/000000.jpg\",\n",
    "        \"dd.expected_out\": \"train/seq000/color/000200.jpg\",\n",
    "        \"dd.flow_gt\": \"train/seq000/optical_flow/blackdog_000000_000200.oflow\",\n",
    "        \"dd.sf_gt\": \"train/seq000/scene_flow/blackdog_000000_000200.sflow\",\n",
    "        \"dd.K\": \"train/seq000/intrinsics.txt\",\n",
    "    }),\n",
    "#     datum.URI(dataset=DDFactory.DATASET, extra={\n",
    "#         \"dd.input\": \"train/seq000/color/000000.jpg\",\n",
    "#         \"dd.expected_out\": \"train/seq000/color/001200.jpg\",\n",
    "#         \"dd.flow_gt\": \"train/seq000/optical_flow/blackdog_000000_001200.oflow\",\n",
    "#         \"dd.sf_gt\": \"train/seq000/scene_flow/blackdog_000000_001200.sflow\",\n",
    "#         \"dd.K\": \"train/seq000/intrinsics.txt\",\n",
    "#     }),\n",
    "    datum.URI(dataset=DDFactory.DATASET, extra={\n",
    "        \"dd.input\": \"train/seq001/color/003400.jpg\",\n",
    "        \"dd.expected_out\": \"train/seq001/color/003600.jpg\",\n",
    "        \"dd.flow_gt\": \"train/seq001/optical_flow/lady_003400_003600.oflow\",\n",
    "        \"dd.sf_gt\": \"train/seq001/scene_flow/lady_003400_003600.sflow\",\n",
    "        \"dd.K\": \"train/seq001/intrinsics.txt\",\n",
    "    }),\n",
    "    datum.URI(dataset=DDFactory.DATASET, extra={\n",
    "        \"dd.input\": \"train/seq337/color/000050.jpg\",\n",
    "        \"dd.expected_out\": \"train/seq337/color/000350.jpg\",\n",
    "        \"dd.flow_gt\": \"train/seq337/optical_flow/adult_000050_000350.oflow\",\n",
    "        \"dd.sf_gt\": \"train/seq337/scene_flow/adult_000050_000350.sflow\",\n",
    "        \"dd.K\": \"train/seq337/intrinsics.txt\",\n",
    "    }),\n",
    "]\n",
    "\n",
    "ALL_FP_FACTORY_CLSS.append(DDFactory)\n",
    "\n",
    "print(\"Found %s DeepDeform scenes\" % len(DDFactory.list_fp_uris(spark)))\n",
    "\n",
    "if SHOW_DEMO_OUTPUT:\n",
    "    fp_rdd = DDFactory.get_fp_rdd_for_uris(spark, DD_DEMO_URIS)\n",
    "    fps = fp_rdd.collect()\n",
    "    \n",
    "    for fp in fps:\n",
    "        show_html(fp.to_html() + \"<br/><br/><br/>\")\n",
    "        DEMO_FPS.append(fp)\n",
    "\n",
    "\n",
    "\n",
    "# import json\n",
    "# DD_ALIGNMENTS = json.load(open(os.path.join(DD_DATA_ROOT, 'train_alignments.json')))\n",
    "# ALL_DD_SCENES = [\n",
    "#     {\n",
    "#         \"input\": ascene['source_color'],\n",
    "#         \"expected_out\": ascene['target_color'],\n",
    "#         \"flow_gt\": ascene['optical_flow'],\n",
    "#     }\n",
    "#     for ascene in DD_ALIGNMENTS\n",
    "# ]\n",
    "\n",
    "# print(\"Found %s DeepDeform scenes\" % len(ALL_DD_SCENES))\n",
    "# if SHOW_DEMO_OUTPUT:\n",
    "#     for scene in DD_DEMO_SCENES:\n",
    "#         p = dd_create_fp(scene)\n",
    "#         show_html(p.to_html())\n",
    "#         DEMO_FPS.append(p)\n",
    "\n",
    "# if RUN_FULL_ANALYSIS:\n",
    "#     for scene in ALL_DD_SCENES:\n",
    "#         p = dd_create_fp(scene)\n",
    "#         ALL_FPS.append(p)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kitti Scene Flow Benchmark (2015)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Please unzip `data_scene_flow.zip` and `data_scene_flow_calib.zip` to a directory and provide that target below:\n",
    "# KITTI_SF15_DATA_ROOT = '/opt/psegs/ext_data/kitti_scene_flow_2015/'\n",
    "\n",
    "\n",
    "\n",
    "# from oarphpy import util as oputil\n",
    "# KITTI_SF15_ALL_FLOW_OCC = [\n",
    "#     os.path.basename(p)\n",
    "#     for p in oputil.all_files_recursive(\n",
    "#         os.path.join(KITTI_SF15_DATA_ROOT, 'training/flow_occ'), pattern='*.png')\n",
    "# ]\n",
    "    \n",
    "# KITTI_SF15_ALL_SCENES = [\n",
    "#     {\n",
    "#         \"input\": 'training/image_2/%s' % fname,\n",
    "#         \"expected_out\": 'training/image_2/%s' % fname.replace('_10', '_11'),\n",
    "#         \"flow_gt\": 'training/flow_occ/%s' % fname,\n",
    "#     }\n",
    "#     for fname in KITTI_SF15_ALL_FLOW_OCC\n",
    "# ]\n",
    "# print(\"Found %s KITTI SceneFlow 2015 scenes\" % len(KITTI_SF15_ALL_SCENES))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cheap_optical_flow_eval_analysis/kittisf15.py\n",
    "\n",
    "from psegs import datum\n",
    "\n",
    "from cheap_optical_flow_eval_analysis.ofp import *\n",
    "\n",
    "# Please unzip `data_scene_flow.zip` and `data_scene_flow_calib.zip` to a directory and provide that target below:\n",
    "KITTI_SF15_DATA_ROOT = '/opt/psegs/ext_data/kitti_scene_flow_2015/'\n",
    "\n",
    "\n",
    "def kittisf15_load_flow(path):\n",
    "    # Based upon https://github.com/liruoteng/OpticalFlowToolkit/blob/master/lib/flowlib.py#L559\n",
    "    import png\n",
    "    import numpy as np\n",
    "    flow_object = png.Reader(filename=path)\n",
    "    flow_direct = flow_object.asDirect()\n",
    "    flow_data = list(flow_direct[2])\n",
    "    w, h = flow_direct[3]['size']\n",
    "    flow = np.zeros((h, w, 3), dtype=np.float64)\n",
    "    for i in range(len(flow_data)):\n",
    "        flow[i, :, 0] = flow_data[i][0::3]\n",
    "        flow[i, :, 1] = flow_data[i][1::3]\n",
    "        flow[i, :, 2] = flow_data[i][2::3]\n",
    "\n",
    "    invalid_idx = (flow[:, :, 2] == 0)\n",
    "    flow[:, :, 0:2] = (flow[:, :, 0:2] - 2 ** 15) / 64.0\n",
    "    flow[invalid_idx, 0] = 0\n",
    "    flow[invalid_idx, 1] = 0\n",
    "    return flow[:, :, :2]\n",
    "\n",
    "def kittisf15_create_fp(uri):\n",
    "    return OpticalFlowPair(\n",
    "                uri=uri,\n",
    "                dataset=\"KITTI Scene Flow 2015\",\n",
    "                id1=uri.extra['ksf15.input'],\n",
    "                img1='file://' + os.path.join(KITTI_SF15_DATA_ROOT, uri.extra['ksf15.input']),\n",
    "                id2=uri.extra['ksf15.expected_out'],\n",
    "                img2='file://' + os.path.join(KITTI_SF15_DATA_ROOT, uri.extra['ksf15.expected_out']),\n",
    "                flow=kittisf15_load_flow(os.path.join(KITTI_SF15_DATA_ROOT, uri.extra['ksf15.flow_gt'])))\n",
    "\n",
    "\n",
    "class KITTISF15Factory(FlowPairFactoryBase):\n",
    "    DATASET = 'kitti_sf15'\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_all_scenes(cls):\n",
    "        from oarphpy import util as oputil\n",
    "        KITTI_SF15_ALL_FLOW_OCC = [\n",
    "            os.path.basename(p)\n",
    "            for p in oputil.all_files_recursive(\n",
    "                os.path.join(KITTI_SF15_DATA_ROOT, 'training/flow_occ'), pattern='*.png')\n",
    "        ]\n",
    "\n",
    "        KITTI_SF15_ALL_SCENES = [\n",
    "            {\n",
    "                \"ksf15.input\": 'training/image_2/%s' % fname,\n",
    "                \"ksf15.expected_out\": 'training/image_2/%s' % fname.replace('_10', '_11'),\n",
    "                \"ksf15.flow_gt\": 'training/flow_occ/%s' % fname,\n",
    "            }\n",
    "            for fname in KITTI_SF15_ALL_FLOW_OCC\n",
    "        ]\n",
    "        return KITTI_SF15_ALL_SCENES\n",
    "\n",
    "    \n",
    "    @classmethod\n",
    "    def list_fp_uris(cls, spark):\n",
    "        scenes = cls._get_all_scenes()\n",
    "        return [\n",
    "            datum.URI(dataset=cls.DATASET, extra=scene)\n",
    "            for scene in scenes\n",
    "        ]\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_fp_rdd_for_uris(cls, spark, uris):\n",
    "        uri_rdd = spark.sparkContext.parallelize(uris)\n",
    "        fp_rdd = uri_rdd.map(kittisf15_create_fp)\n",
    "        return fp_rdd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cheap_optical_flow_eval_analysis.kittisf15 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from psegs import datum\n",
    "\n",
    "# You have to ls flow_occ to get the paths\n",
    "KITTI_SF15_DEMO_URIS = [\n",
    "    datum.URI(dataset=KITTISF15Factory.DATASET, extra={\n",
    "        'ksf15.input': 'training/image_2/000000_10.png',\n",
    "        'ksf15.expected_out': 'training/image_2/000000_11.png',\n",
    "        'ksf15.flow_gt': 'training/flow_occ/000000_10.png',\n",
    "    }),\n",
    "    datum.URI(dataset=KITTISF15Factory.DATASET, extra={\n",
    "        'ksf15.input': 'training/image_2/000007_10.png',\n",
    "        'ksf15.expected_out': 'training/image_2/000007_11.png',\n",
    "        'ksf15.flow_gt': 'training/flow_occ/000007_10.png',\n",
    "    }),\n",
    "    datum.URI(dataset=KITTISF15Factory.DATASET, extra={\n",
    "        'ksf15.input': 'training/image_2/000023_10.png',\n",
    "        'ksf15.expected_out': 'training/image_2/000023_11.png',\n",
    "        'ksf15.flow_gt': 'training/flow_occ/000023_10.png',\n",
    "    }),\n",
    "    datum.URI(dataset=KITTISF15Factory.DATASET, extra={\n",
    "        'ksf15.input': 'training/image_2/000051_10.png',\n",
    "        'ksf15.expected_out': 'training/image_2/000051_11.png',\n",
    "        'ksf15.flow_gt': 'training/flow_occ/000051_10.png',\n",
    "    }),\n",
    "    datum.URI(dataset=KITTISF15Factory.DATASET, extra={\n",
    "        'ksf15.input': 'training/image_2/000003_10.png',\n",
    "        'ksf15.expected_out': 'training/image_2/000003_11.png',\n",
    "        'ksf15.flow_gt': 'training/flow_occ/000003_10.png',\n",
    "    }),\n",
    "]\n",
    "\n",
    "ALL_FP_FACTORY_CLSS.append(KITTISF15Factory)\n",
    "\n",
    "print(\"Found %s Kitti Scene Flow 2015 scenes\" % len(KITTISF15Factory.list_fp_uris(spark)))\n",
    "\n",
    "if SHOW_DEMO_OUTPUT:\n",
    "    fp_rdd = KITTISF15Factory.get_fp_rdd_for_uris(spark, KITTI_SF15_DEMO_URIS)\n",
    "    fps = fp_rdd.collect()\n",
    "    \n",
    "    for fp in fps:\n",
    "        show_html(fp.to_html() + \"<br/><br/><br/>\")\n",
    "        DEMO_FPS.append(fp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def kitti_sf15_create_fp(info):\n",
    "#      return OpticalFlowPair(\n",
    "#                 dataset=\"KITTI Scene Flow 2015\",\n",
    "#                 id1=scene['input'],\n",
    "#                 img1='file://' + os.path.join(KITTI_SF15_DATA_ROOT, scene['input']),\n",
    "#                 id2=scene['expected_out'],\n",
    "#                 img2='file://' + os.path.join(KITTI_SF15_DATA_ROOT, scene['expected_out']),\n",
    "#                 flow=KITTISF15LoadFlowFromPng(os.path.join(KITTI_SF15_DATA_ROOT, scene['flow_gt'])))\n",
    "\n",
    "# if SHOW_DEMO_OUTPUT:\n",
    "#     for scene in KITTI_SF15_DEMO_SCENES:\n",
    "#         p = kitti_sf15_create_fp(scene)\n",
    "#         show_html(p.to_html())\n",
    "#         DEMO_FPS.append(p)\n",
    "\n",
    "# if RUN_FULL_ANALYSIS:\n",
    "#     for scene in KITTI_SF15_ALL_SCENES:\n",
    "#         p = kitti_sf15_create_fp(scene)\n",
    "#         ALL_FPS.append(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSegs Synthetic Flow from Fused Lidar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSEGS_SYNTHFLOW_PARQUET_ROOT = '/outer_root/media/rocket4q/psegs_flow_records_short'\n",
    "\n",
    "# from psegs.exp.fused_lidar_flow import FlowRecTable\n",
    "\n",
    "# T = FlowRecTable(spark, PSEGS_SYNTHFLOW_PARQUET_ROOT)\n",
    "# synthflow_record_uris = T.get_record_uris()\n",
    "# print(\"Found %s PSegs SynthFlow records\" % len(synthflow_record_uris))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fr_samp_rdd = T.get_records_with_samples_rdd(\n",
    "#                     record_uris=[PSEGS_SYNTHFLOW_DEMO_RECORD_URIS[0]],\n",
    "#                     include_cameras=False,\n",
    "#                     include_cuboids=False,\n",
    "#                     include_point_clouds=False)\n",
    "# flow_rec = fr_samp_rdd.take(1)[0][0]\n",
    "\n",
    "# print(\"Sample record:\")\n",
    "# show_html(flow_rec.to_html())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cheap_optical_flow_eval_analysis/psegs_synthflow.py\n",
    "\n",
    "from psegs import datum\n",
    "from psegs.exp.fused_lidar_flow import FlowRecTable\n",
    "\n",
    "from cheap_optical_flow_eval_analysis.ofp import *\n",
    "\n",
    "from oarphpy.spark import CloudpickeledCallable\n",
    "\n",
    "\n",
    "# Please provide the PSegs synthetic flow Parquet directory root below:\n",
    "PSEGS_SYNTHFLOW_PARQUET_ROOT = '/outer_root/media/rocket4q/psegs_flow_records_short_fixed'\n",
    "# PSEGS_SYNTHFLOW_PARQUET_ROOT = '/outer_root/media/rocket4q/psegs_synthflow.parquet'\n",
    "\n",
    "def psegs_synthflow_flow_rec_to_fp(flow_rec, sample):\n",
    "  fr = flow_rec\n",
    "\n",
    "  uri_str_to_datum = sample.get_uri_str_to_datum()\n",
    "\n",
    "  # Find the camera_images associated with `flow_rec`\n",
    "  ci1_url_str = str(flow_rec.clouds[0].ci_uris[0])\n",
    "  ci1_sd = uri_str_to_datum[ci1_url_str]\n",
    "  ci1 = ci1_sd.camera_image\n",
    "\n",
    "  ci2_url_str = str(flow_rec.clouds[1].ci_uris[0])\n",
    "  ci2_sd = uri_str_to_datum[ci2_url_str]\n",
    "  ci2 = ci2_sd.camera_image\n",
    "\n",
    "  import numpy as np\n",
    "  world_T1 = ci1.ego_pose.translation\n",
    "  world_T2 = ci2.ego_pose.translation\n",
    "  translation_meters = np.linalg.norm(world_T2 - world_T1)\n",
    "\n",
    "  id1 = ci1_url_str + '&extra.psegs_flow_sids=' + str(fr.clouds[0].sample_id)\n",
    "  id2 = ci2_url_str + '&extra.psegs_flow_sids=' + str(fr.clouds[1].sample_id)\n",
    "\n",
    "  import urllib.parse\n",
    "  eval_uri = datum.URI(dataset=PSegsSynthFlowFactory.DATASET, extra={'pssf.ruri': urllib.parse.quote(str(fr.uri))})\n",
    "\n",
    "  uvdviz_im1 = flow_rec.clouds[0].uvdvis\n",
    "  uvdviz_im2 = flow_rec.clouds[1].uvdvis\n",
    "  K = ci1.K\n",
    "\n",
    "  fp = OpticalFlowPair(\n",
    "          uri=eval_uri,\n",
    "          dataset=\"PSegs SynthFlow for %s (%s)\" % (fr.uri.dataset, fr.uri.split),\n",
    "          id1=id1,\n",
    "          id2=id2,\n",
    "          img1=CloudpickeledCallable(lambda: ci1.image),\n",
    "          img2=CloudpickeledCallable(lambda: ci2.image),\n",
    "          flow=CloudpickeledCallable(lambda: fr.to_optical_flow()),\n",
    "\n",
    "          diff_time_sec=abs(ci2_sd.uri.timestamp - ci1_sd.uri.timestamp),\n",
    "          translation_meters=translation_meters,\n",
    "      \n",
    "          uvdviz_im1=uvdviz_im1,\n",
    "          uvdviz_im2=uvdviz_im2,\n",
    "          K=K)\n",
    "  return fp\n",
    "\n",
    "def psegs_synthflow_create_fps(\n",
    "        spark,\n",
    "        flow_record_pq_table_path,\n",
    "        record_uris,\n",
    "        include_cuboids=False,\n",
    "        include_point_clouds=False):\n",
    "\n",
    "  T = FlowRecTable(spark, flow_record_pq_table_path)\n",
    "  rec_sample_rdd = T.get_records_with_samples_rdd(\n",
    "                          record_uris=record_uris,\n",
    "                          include_cameras=True,\n",
    "                          include_cuboids=include_cuboids,\n",
    "                          include_point_clouds=include_point_clouds)\n",
    "\n",
    "  fps = [\n",
    "    flow_rec_to_fp(flow_rec, sample)\n",
    "    for flow_rec, sample in rec_sample_rdd.collect()\n",
    "  ]\n",
    "\n",
    "  return fps\n",
    "\n",
    "\n",
    "class PSegsSynthFlowFactory(FlowPairFactoryBase):\n",
    "    DATASET = 'psegs_synthflow'\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_frec_table(cls, spark):\n",
    "        if not hasattr(cls, '_frec_table'):\n",
    "            cls._frec_table = FlowRecTable(spark, PSEGS_SYNTHFLOW_PARQUET_ROOT)\n",
    "        return cls._frec_table\n",
    "    \n",
    "    @classmethod\n",
    "    def list_fp_uris(cls, spark):\n",
    "        import urllib.parse\n",
    "        T = cls._get_frec_table(spark)\n",
    "        ruris = T.get_record_uris()\n",
    "        return [\n",
    "            datum.URI(dataset=cls.DATASET, extra={'pssf.ruri': urllib.parse.quote(str(ruri))})\n",
    "            for ruri in ruris\n",
    "        ]\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_fp_rdd_for_uris(cls, spark, uris):\n",
    "        import urllib.parse\n",
    "        T = cls._get_frec_table(spark)\n",
    "        ruris = [urllib.parse.unquote(uri.extra['pssf.ruri']) for uri in uris]\n",
    "        rec_sample_rdd = T.get_records_with_samples_rdd(\n",
    "                          record_uris=ruris,\n",
    "                          include_cameras=True,\n",
    "                          include_cuboids=False,\n",
    "                          include_point_clouds=False)\n",
    "        fp_rdd = rec_sample_rdd.map(lambda fs: psegs_synthflow_flow_rec_to_fp(*fs))\n",
    "        return fp_rdd\n",
    "        \n",
    "\n",
    "\n",
    "# def psegs_synthflow_iter_fp_rdds(\n",
    "#         spark,\n",
    "#         flow_record_pq_table_path,\n",
    "#         fps_per_rdd=100,\n",
    "#         include_cuboids=False,\n",
    "#         include_point_clouds=False):\n",
    "  \n",
    "#   T = FlowRecTable(spark, flow_record_pq_table_path)\n",
    "#   ruris = T.get_record_uris()\n",
    "\n",
    "#   # Ensure a sort so that pairs from similar segments will load in the same\n",
    "#   # RDD -- that makes joins smaller and faster\n",
    "#   ruris = sorted(ruris)\n",
    "\n",
    "#   from oarphpy import util as oputil\n",
    "#   for ruri_chunk in oputil.ichunked(ruris, fps_per_rdd):\n",
    "#     frec_sample_rdd = T.get_records_with_samples_rdd(\n",
    "#                           record_uris=rids,\n",
    "#                           include_cuboids=include_cuboids,\n",
    "#                           include_point_clouds=include_point_clouds)\n",
    "#     fp_rdd = frec_sample_rdd.map(flow_rec_to_fp)\n",
    "#     yield fp_rdd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cheap_optical_flow_eval_analysis.psegs_synthflow import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from psegs import datum\n",
    "\n",
    "import urllib.parse\n",
    "\n",
    "PSEGS_SYNTHFLOW_DEMO_FPS_DO_CACHE = True\n",
    "PSEGS_SYNTHFLOW_DEMO_FPS_CACHE_PATH = '/tmp/psegs_synthflow_demo.pkl'\n",
    "\n",
    "PSEGS_SYNTHFLOW_DEMO_RECORD_RURIS = (\n",
    "  'psegs://dataset=kitti-360&split=train&segment_id=2013_05_28_drive_0000_sync&extra.psegs_flow_sids=4340,4339',\n",
    "  'psegs://dataset=kitti-360&split=train&segment_id=2013_05_28_drive_0000_sync&extra.psegs_flow_sids=11219,11269',\n",
    "\n",
    "  'psegs://dataset=nuscenes&split=train_track&segment_id=scene-0501&extra.psegs_flow_sids=40009,40010',\n",
    "  'psegs://dataset=nuscenes&split=train_track&segment_id=scene-0501&extra.psegs_flow_sids=50013,50014',\n",
    "\n",
    "#   'psegs://dataset=kitti-360-fused&split=train&segment_id=2013_05_28_drive_0000_sync&extra.psegs_flow_sids=11103,11104',\n",
    "#   'psegs://dataset=kitti-360-fused&split=train&segment_id=2013_05_28_drive_0000_sync&extra.psegs_flow_sids=1181,1182',\n",
    "\n",
    "#   'psegs://dataset=nuscenes&split=train_detect&segment_id=scene-0002&extra.psegs_flow_sids=10016,10017',\n",
    "#   'psegs://dataset=nuscenes&split=train_detect&segment_id=scene-0582&extra.psegs_flow_sids=60035,60036',\n",
    "\n",
    "#   'psegs://dataset=nuscenes&split=train_track&segment_id=scene-0393&extra.psegs_flow_sids=50017,50018',\n",
    "#   'psegs://dataset=nuscenes&split=train_track&segment_id=scene-0501&extra.psegs_flow_sids=40019,40020',\n",
    "    #  'psegs://dataset=psegs_synthflow&extra.pssf.ruri=psegs%3A//dataset%3Dnuscenes%26split%3Dtrain_track%26segment_id%3Dscene-0501%26extra.psegs_flow_sids%3D30009%2C30010%26sel_datums%3Dcamera%7CCAM_BACK_RIGHT%2C1535478534928113000%2Ccamera%7CCAM_BACK_RIGHT%2C1535478535428113000',\n",
    "#  'psegs://dataset=psegs_synthflow&extra.pssf.ruri=psegs%3A//dataset%3Dnuscenes%26split%3Dtrain_track%26segment_id%3Dscene-0501%26extra.psegs_flow_sids%3D50016%2C50017%26sel_datums%3Dcamera%7CCAM_FRONT_LEFT%2C1535478538404799000%2Ccamera%7CCAM_FRONT_LEFT%2C1535478538904799000',\n",
    "#  'psegs://dataset=psegs_synthflow&extra.pssf.ruri=psegs%3A//dataset%3Dnuscenes%26split%3Dtrain_track%26segment_id%3Dscene-0501%26extra.psegs_flow_sids%3D50018%2C50019%26sel_datums%3Dcamera%7CCAM_FRONT_LEFT%2C1535478539504799000%2Ccamera%7CCAM_FRONT_LEFT%2C1535478540004799000',\n",
    "#  'psegs://dataset=psegs_synthflow&extra.pssf.ruri=psegs%3A//dataset%3Dnuscenes%26split%3Dtrain_track%26segment_id%3Dscene-0501%26extra.psegs_flow_sids%3D30031%2C30032%26sel_datums%3Dcamera%7CCAM_BACK_RIGHT%2C1535478546028113000%2Ccamera%7CCAM_BACK_RIGHT%2C1535478546528113000',\n",
    "#  'psegs://dataset=psegs_synthflow&extra.pssf.ruri=psegs%3A//dataset%3Dnuscenes%26split%3Dtrain_track%26segment_id%3Dscene-0501%26extra.psegs_flow_sids%3D50023%2C50024%26sel_datums%3Dcamera%7CCAM_FRONT_LEFT%2C1535478541904799000%2Ccamera%7CCAM_FRONT_LEFT%2C1535478542504811000',\n",
    "#  'psegs://dataset=psegs_synthflow&extra.pssf.ruri=psegs%3A//dataset%3Dnuscenes%26split%3Dtrain_track%26segment_id%3Dscene-0501%26extra.psegs_flow_sids%3D20006%2C20007%26sel_datums%3Dcamera%7CCAM_BACK_LEFT%2C1535478533447405000%2Ccamera%7CCAM_BACK_LEFT%2C1535478533947405000',\n",
    "#  'psegs://dataset=psegs_synthflow&extra.pssf.ruri=psegs%3A//dataset%3Dnuscenes%26split%3Dtrain_track%26segment_id%3Dscene-0501%26extra.psegs_flow_sids%3D10019%2C10020%26sel_datums%3Dcamera%7CCAM_BACK%2C1535478540037558000%2Ccamera%7CCAM_BACK%2C1535478540537558000',\n",
    "#  'psegs://dataset=psegs_synthflow&extra.pssf.ruri=psegs%3A//dataset%3Dnuscenes%26split%3Dtrain_track%26segment_id%3Dscene-0501%26extra.psegs_flow_sids%3D30023%2C30024%26sel_datums%3Dcamera%7CCAM_BACK_RIGHT%2C1535478541928113000%2Ccamera%7CCAM_BACK_RIGHT%2C1535478542528113000',\n",
    "#  'psegs://dataset=psegs_synthflow&extra.pssf.ruri=psegs%3A//dataset%3Dnuscenes%26split%3Dtrain_track%26segment_id%3Dscene-0501%26extra.psegs_flow_sids%3D50007%2C50008%26sel_datums%3Dcamera%7CCAM_FRONT_LEFT%2C1535478533904799000%2Ccamera%7CCAM_FRONT_LEFT%2C1535478534404799000',\n",
    " 'psegs://dataset=psegs_synthflow&extra.pssf.ruri=psegs%3A//dataset%3Dnuscenes%26split%3Dtrain_track%26segment_id%3Dscene-0501%26extra.psegs_flow_sids%3D60014%2C60015%26sel_datums%3Dcamera%7CCAM_FRONT_RIGHT%2C1535478537420482000%2Ccamera%7CCAM_FRONT_RIGHT%2C1535478537870482000',\n",
    " 'psegs://dataset=psegs_synthflow&extra.pssf.ruri=psegs%3A//dataset%3Dkitti-360%26split%3Dtrain%26segment_id%3D2013_05_28_drive_0004_sync%26extra.psegs_flow_sids%3D10412%2C10413%26sel_datums%3Dcamera%7Cright_rect%2C1369736347374754304%2Ccamera%7Cright_rect%2C1369736347479072256',\n",
    "#  'psegs://dataset=psegs_synthflow&extra.pssf.ruri=psegs%3A//dataset%3Dnuscenes%26split%3Dtrain_track%26segment_id%3Dscene-0501%26extra.psegs_flow_sids%3D50002%2C50003%26sel_datums%3Dcamera%7CCAM_FRONT_LEFT%2C1535478531354799000%2Ccamera%7CCAM_FRONT_LEFT%2C1535478531854807000',\n",
    "#  'psegs://dataset=psegs_synthflow&extra.pssf.ruri=psegs%3A//dataset%3Dnuscenes%26split%3Dtrain_track%26segment_id%3Dscene-0501%26extra.psegs_flow_sids%3D50027%2C50028%26sel_datums%3Dcamera%7CCAM_FRONT_LEFT%2C1535478543904799000%2Ccamera%7CCAM_FRONT_LEFT%2C1535478544404799000',\n",
    "#  'psegs://dataset=psegs_synthflow&extra.pssf.ruri=psegs%3A//dataset%3Dkitti-360%26split%3Dtrain%26segment_id%3D2013_05_28_drive_0004_sync%26extra.psegs_flow_sids%3D10412%2C10413%26sel_datums%3Dcamera%7Cleft_rect%2C1369736347374744320%2Ccamera%7Cleft_rect%2C1369736347479187968',\n",
    "#  'psegs://dataset=psegs_synthflow&extra.pssf.ruri=psegs%3A//dataset%3Dnuscenes%26split%3Dtrain_track%26segment_id%3Dscene-0501%26extra.psegs_flow_sids%3D10027%2C10028%26sel_datums%3Dcamera%7CCAM_BACK%2C1535478543937558000%2Ccamera%7CCAM_BACK%2C1535478544437558000',\n",
    "#  'psegs://dataset=psegs_synthflow&extra.pssf.ruri=psegs%3A//dataset%3Dnuscenes%26split%3Dtrain_track%26segment_id%3Dscene-0501%26extra.psegs_flow_sids%3D10035%2C10036%26sel_datums%3Dcamera%7CCAM_BACK%2C1535478548187558000%2Ccamera%7CCAM_BACK%2C1535478548687558000',\n",
    "#  'psegs://dataset=psegs_synthflow&extra.pssf.ruri=psegs%3A//dataset%3Dnuscenes%26split%3Dtrain_track%26segment_id%3Dscene-0501%26extra.psegs_flow_sids%3D40005%2C40006%26sel_datums%3Dcamera%7CCAM_FRONT%2C1535478532912404000%2Ccamera%7CCAM_FRONT%2C1535478533412404000',\n",
    "#  'psegs://dataset=psegs_synthflow&extra.pssf.ruri=psegs%3A//dataset%3Dnuscenes%26split%3Dtrain_track%26segment_id%3Dscene-0501%26extra.psegs_flow_sids%3D40002%2C40003%26sel_datums%3Dcamera%7CCAM_FRONT%2C1535478531362404000%2Ccamera%7CCAM_FRONT%2C1535478531862404000',\n",
    "#  'psegs://dataset=psegs_synthflow&extra.pssf.ruri=psegs%3A//dataset%3Dnuscenes%26split%3Dtrain_track%26segment_id%3Dscene-0501%26extra.psegs_flow_sids%3D30034%2C30035%26sel_datums%3Dcamera%7CCAM_BACK_RIGHT%2C1535478547628113000%2Ccamera%7CCAM_BACK_RIGHT%2C1535478548178113000',\n",
    "#  'psegs://dataset=psegs_synthflow&extra.pssf.ruri=psegs%3A//dataset%3Dkitti-360%26split%3Dtrain%26segment_id%3D2013_05_28_drive_0000_sync%26extra.psegs_flow_sids%3D4340%2C4339%26sel_datums%3Dcamera%7Cleft_rect%2C1369731215809577984%2Ccamera%7Cleft_rect%2C1369731215914083072'\n",
    "\n",
    ")\n",
    "\n",
    "PSEGS_SYNTHFLOW_DEMO_FP_URIS = [\n",
    "    datum.URI.from_str(s)\n",
    "    for s in (\n",
    "         'psegs://dataset=psegs_synthflow&extra.pssf.ruri=psegs%3A//dataset%3Dnuscenes%26split%3Dtrain_track%26segment_id%3Dscene-0501%26extra.psegs_flow_sids%3D60014%2C60015%26sel_datums%3Dcamera%7CCAM_FRONT_RIGHT%2C1535478537420482000%2Ccamera%7CCAM_FRONT_RIGHT%2C1535478537870482000',\n",
    "         'psegs://dataset=psegs_synthflow&extra.pssf.ruri=psegs%3A//dataset%3Dkitti-360%26split%3Dtrain%26segment_id%3D2013_05_28_drive_0004_sync%26extra.psegs_flow_sids%3D10412%2C10413%26sel_datums%3Dcamera%7Cright_rect%2C1369736347374754304%2Ccamera%7Cright_rect%2C1369736347479072256',\n",
    "    )\n",
    "]\n",
    "\n",
    "ALL_FP_FACTORY_CLSS.append(PSegsSynthFlowFactory)\n",
    "\n",
    "psegs_synthflow_all_rids = PSegsSynthFlowFactory.list_fp_uris(spark)\n",
    "print(\"Found %s PSegs SynthFlow scenes\" % len(psegs_synthflow_all_rids))\n",
    "\n",
    "if SHOW_DEMO_OUTPUT:\n",
    "    if os.path.exists(PSEGS_SYNTHFLOW_DEMO_FPS_CACHE_PATH):\n",
    "        print(\"Loading demo FlowPairs from %s\" % PSEGS_SYNTHFLOW_DEMO_FPS_CACHE_PATH)\n",
    "        import pickle\n",
    "        fps = pickle.load(open(PSEGS_SYNTHFLOW_DEMO_FPS_CACHE_PATH, 'rb'))\n",
    "    else:\n",
    "        print(\"Building Demo FlowPairs, this might take a while ....\")\n",
    "        fp_rdd = PSegsSynthFlowFactory.get_fp_rdd_for_uris(spark, PSEGS_SYNTHFLOW_DEMO_FP_URIS)\n",
    "        fps = fp_rdd.collect()\n",
    "        if PSEGS_SYNTHFLOW_DEMO_FPS_DO_CACHE:\n",
    "            print(\"Saving demo FlowPairs to %s ...\" % PSEGS_SYNTHFLOW_DEMO_FPS_CACHE_PATH)\n",
    "            import pickle\n",
    "            with open(PSEGS_SYNTHFLOW_DEMO_FPS_CACHE_PATH, 'wb') as f:\n",
    "                pickle.dump(fps, f, protocol=4)\n",
    "    \n",
    "    for fp in fps:\n",
    "        show_html(fp.to_html())\n",
    "        DEMO_FPS.append(fp)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     import urllib.parse\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     for fp in fps:\n",
    "#         show_html(fp.to_html() + \"<br/><br/><br/>\")\n",
    "#         DEMO_FPS.append(fp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if SHOW_DEMO_OUTPUT:\n",
    "#     if os.path.exists(PSEGS_SYNTHFLOW_DEMO_FPS_CACHE_PATH):\n",
    "#         print(\"Loading demo FlowPairs from %s\" % PSEGS_SYNTHFLOW_DEMO_FPS_CACHE_PATH)\n",
    "#         import pickle\n",
    "#         fps = pickle.load(open(PSEGS_SYNTHFLOW_DEMO_FPS_CACHE_PATH, 'rb'))\n",
    "#     else:\n",
    "#         print(\"Building Demo FlowPairs, this might take a while ....\")\n",
    "#         fps = psegs_synthflow_create_fps(spark, PSEGS_SYNTHFLOW_PARQUET_ROOT, PSEGS_SYNTHFLOW_DEMO_RECORD_URIS)\n",
    "#         if PSEGS_SYNTHFLOW_DEMO_FPS_DO_CACHE:\n",
    "#             print(\"Saving demo FlowPairs to %s ...\" % PSEGS_SYNTHFLOW_DEMO_FPS_CACHE_PATH)\n",
    "#             import pickle\n",
    "#             with open(PSEGS_SYNTHFLOW_DEMO_FPS_CACHE_PATH, 'wb') as f:\n",
    "#                 pickle.dump(fps, f, protocol=4)\n",
    "    \n",
    "#     for fp in fps:\n",
    "#         show_html(fp.to_html())\n",
    "#         DEMO_FPS.append(fp)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction via Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Reconstruction via Optical Flow\n",
    "\n",
    "def zero_flow(flow):\n",
    "    return (flow[:, :, :2] == np.array([0, 0])).all(axis=-1)\n",
    "\n",
    "def warp_flow_backwards(img, flow):\n",
    "    \"\"\"Given an image, apply the inverse of `flow`\"\"\"\n",
    "    h, w = flow.shape[:2]\n",
    "    flow = -flow\n",
    "    flow[:,:,0] += np.arange(w)\n",
    "    flow[:,:,1] += np.arange(h)[:,np.newaxis]\n",
    "    res = cv2.remap(img, flow.astype(np.float32), None, cv2.INTER_LINEAR)\n",
    "    return res\n",
    "    \n",
    "def warp_flow_forwards(img, flow):\n",
    "    \"\"\"Given an image, apply the given optical flow `flow`.  Returns not only the warped\n",
    "    image, but a `mask` indicating warped pixels (i.e. there was non-zero flow *into* these pixels ).\n",
    "    With some help from https://stackoverflow.com/questions/41703210/inverting-a-real-valued-index-grid/46009462#46009462\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    pts = flow.copy()\n",
    "    pts[:, :, 0] += np.arange(w)\n",
    "    pts[:, :, 1] += np.arange(h)[:, np.newaxis]\n",
    "    exclude = zero_flow(flow)\n",
    "    if exclude.all():\n",
    "        # No flow anywhere!\n",
    "        return img.copy(), np.zeros((h, w)).astype(np.bool)\n",
    "    else:\n",
    "        inpts = pts[~exclude]\n",
    "    \n",
    "    from scipy.interpolate import griddata\n",
    "    inpts = np.reshape(inpts, [-1, 2])\n",
    "    grid_y, grid_x = np.mgrid[:h, :w]\n",
    "    chan_out = []\n",
    "    for ch in range(img.shape[-1]):\n",
    "        spts = img[:, :, ch][~exclude].reshape([-1, 1])\n",
    "        mapped = griddata(inpts, spts, (grid_x, grid_y), method='linear')\n",
    "        chan_out.append(mapped.astype(img.dtype))\n",
    "    out = np.stack(chan_out, axis=-1)\n",
    "    out = out.reshape([h, w, len(chan_out)])\n",
    "\n",
    "    mask = np.reshape(inpts, [-1, 2])\n",
    "    mask = np.rint(mask).astype(np.int)\n",
    "    mask = mask[np.where((mask[:, 0] >= 0) & (mask[:, 0] < w) & (mask[:, 1] >= 0) & (mask[:, 1] < h))]\n",
    "    valid_mask = np.zeros((h, w))\n",
    "    valid_mask[mask[:, 1], mask[:, 0]] = 1\n",
    "    \n",
    "    return out, valid_mask.astype(np.bool)\n",
    "\n",
    "# @attr.s(slots=True, eq=False, weakref_slot=False)\n",
    "class FlowReconstructedImagePair(object):\n",
    "    \"\"\"A pair of reconstructed images using an input pair of images and optical\n",
    "    flow field (i.e. an `OpticalFlowPair` instance).\"\"\"\n",
    "\n",
    "    slots = (\n",
    "        'opair',\n",
    "        'img2_recon_fwd',\n",
    "        'img2_recon_fwd_valid',\n",
    "        'img1_recon_bkd',\n",
    "        'img1_recon_bkd_valid'\n",
    "    )\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        for k in self.slots:\n",
    "            setattr(self, k, kwargs.get(k))\n",
    "    \n",
    "#     opair = attr.ib(default=OpticalFlowPair())\n",
    "#     \"\"\"The original `OpticalFlowPair` with the source of the data for this reconstruction result.\"\"\"\n",
    "    \n",
    "#     img2_recon_fwd = attr.ib(default=np.array([]))\n",
    "#     \"\"\"A Numpy image containing the result of FORWARDS-WARPING OpticalFlowPair::img1\n",
    "#     via OpticalFlowPair::flow to reconstruct OpticalFlowPair::img2\"\"\"\n",
    "\n",
    "#     img2_recon_fwd_valid = attr.ib(default=np.array([]))\n",
    "#     \"\"\"A Numpy boolean mask indicating which pixels of `img2_recon_fwd` were modified via non-zero flow\"\"\"\n",
    "    \n",
    "#     img1_recon_bkd = attr.ib(default=np.array([]))\n",
    "#     \"\"\"A Numpy image containing the result of BACKWARDS-WARPING OpticalFlowPair::img2\n",
    "#     via OpticalFlowPair::flow to reconstruct OpticalFlowPair::img1\"\"\"\n",
    "\n",
    "#     img1_recon_bkd_valid = attr.ib(default=np.array([]))\n",
    "#     \"\"\"A Numpy boolean mask indicating which pixels of `img1_recon_bkd` were modified via non-zero flow\"\"\"\n",
    "        \n",
    "    @classmethod\n",
    "    def create_from(cls, oflow_pair: OpticalFlowPair):\n",
    "        flow = oflow_pair.get_flow()\n",
    "        \n",
    "        # Forward Warp\n",
    "        fwarped, fvalid = warp_flow_forwards(oflow_pair.get_img1(), flow)\n",
    "\n",
    "        # Backwards Warp\n",
    "        exclude = zero_flow(flow)\n",
    "        bwarped = warp_flow_backwards(oflow_pair.get_img2(), -flow[:, :, :2])\n",
    "        bvalid = ~exclude\n",
    "        \n",
    "        return FlowReconstructedImagePair(\n",
    "                opair=oflow_pair,\n",
    "                img2_recon_fwd=fwarped,\n",
    "                img2_recon_fwd_valid=fvalid,\n",
    "                img1_recon_bkd=bwarped,\n",
    "                img1_recon_bkd_valid=bvalid)\n",
    "    \n",
    "    def to_html(self):\n",
    "        # We use pixels from the destination image in order to make the reconstruction \n",
    "        # easier to interpret; we'll fade them in intensity so that they are more\n",
    "        # conspicuous.        \n",
    "        FADE_UNTOUCHED_PIXELS = 0.3\n",
    "        \n",
    "        viz_fwd = self.img2_recon_fwd.copy().astype(np.float32)\n",
    "        im2 = self.opair.get_img2()\n",
    "        if (~self.img2_recon_fwd_valid).any():\n",
    "            viz_fwd[~self.img2_recon_fwd_valid] = im2[~self.img2_recon_fwd_valid]\n",
    "            viz_fwd[~self.img2_recon_fwd_valid] *= FADE_UNTOUCHED_PIXELS\n",
    "        else:\n",
    "            # viz_fwd = im2.copy() * FADE_UNTOUCHED_PIXELS\n",
    "            print('no invalids forward!')\n",
    "        \n",
    "        viz_bkd = self.img1_recon_bkd.copy().astype(np.float32)\n",
    "        im1 = self.opair.get_img1()\n",
    "        if (~self.img1_recon_bkd_valid).any():\n",
    "            viz_bkd[~self.img1_recon_bkd_valid] = im1[~self.img1_recon_bkd_valid]\n",
    "            viz_bkd[~self.img1_recon_bkd_valid] *= FADE_UNTOUCHED_PIXELS\n",
    "        else:\n",
    "            # viz_bkd = im1.copy() * FADE_UNTOUCHED_PIXELS\n",
    "            print('no invalids backwards!')\n",
    "        \n",
    "        html = \"\"\"\n",
    "            <table>\n",
    "            \n",
    "            <tr><td style=\"text-align:left\"><b>Forwards Warped <i>(dark pixels unwarped)</i></b></td></tr>\n",
    "            <tr><td><img src=\"{viz_fwd}\" width=\"100%\" /></td></tr>\n",
    "\n",
    "            <tr><td style=\"text-align:left\"><b>Backwards Warped <i>(dark pixels unwarped)</i></b></td></tr>\n",
    "            <tr><td><img src=\"{viz_bkd}\" width=\"100%\" /></td></tr>\n",
    "\n",
    "            </table>\n",
    "        \"\"\".format(\n",
    "                viz_fwd=img_to_data_uri(viz_fwd.astype(np.uint8)),\n",
    "                viz_bkd=img_to_data_uri(viz_bkd.astype(np.uint8)))\n",
    "        return html\n",
    "\n",
    "        \n",
    "if SHOW_DEMO_OUTPUT:\n",
    "    DEMO_RECONS = []\n",
    "    for p in DEMO_FPS:\n",
    "        recon = FlowReconstructedImagePair.create_from(p)\n",
    "        show_html(recon.to_html() + \"</br></br></br>\")\n",
    "        DEMO_RECONS.append(recon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Analysis Utils\n",
    "\n",
    "def mse(i1, i2, valid):\n",
    "    return np.mean((i1[valid] - i2[valid]) ** 2)\n",
    "\n",
    "def rmse(i1, i2, valid):\n",
    "    return math.sqrt(mse(i1, i2, valid))\n",
    "\n",
    "def psnr(i1, i2, valid):\n",
    "    return 20 * math.log10(255) - 10 * math.log10(max((mse(i1, i2, valid), 1e-12)))\n",
    "\n",
    "def ssim(i1, i2, valid):\n",
    "    # Some variance out there ...\n",
    "    # https://github.com/scikit-image/scikit-image/blob/master/skimage/metrics/_structural_similarity.py#L12-L232\n",
    "    # https://github.com/nianticlabs/monodepth2/blob/13200ab2f29f2f10dec3aa5db29c32a23e29d376/layers.py#L218\n",
    "    # https://cvnote.ddlee.cn/2019/09/12/psnr-ssim-python\n",
    "    # We will just use SKImage for now ...\n",
    "    from skimage.metrics import structural_similarity as ssim\n",
    "    mssim, S = ssim(i1, i2, win_size=11, multichannel=True, full=True)\n",
    "    return np.mean(S[valid])\n",
    "\n",
    "def to_edge_im(img):\n",
    "    return np.stack([\n",
    "        cv2.Laplacian(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY), cv2.CV_32F, ksize=1),\n",
    "        cv2.Sobel(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY), cv2.CV_32F, 1, 0, ksize=3),\n",
    "        cv2.Sobel(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY), cv2.CV_32F, 0, 1, ksize=3),\n",
    "    ], axis=-1)\n",
    "\n",
    "def edges_mse(i1, i2, valid):\n",
    "    return mse(to_edge_im(i1), to_edge_im(i2), valid)\n",
    "\n",
    "\n",
    "def oflow_coverage(valid):\n",
    "    return valid.sum() / (valid.shape[0] * valid.shape[1])\n",
    "\n",
    "def oflow_magnitude_hist(flow, valid, bins=50):\n",
    "    flow_l2s = np.sqrt( flow[valid][:, 0] ** 2 + flow[valid][:, 1] ** 2 )\n",
    "    bin_counts, bin_edges = np.histogram(flow_l2s, bins=bins)\n",
    "    return bin_edges, bin_counts\n",
    "\n",
    "\n",
    "# Analysis Data Model\n",
    "\n",
    "class OFlowReconErrors(object):\n",
    "    \"\"\"Various measures of reconstruction error for a `FlowReconstructedImagePair` instance.\n",
    "    Encapsulated as two dictionaries of stats for easy interop with Spark SQL.\"\"\"\n",
    "\n",
    "    RECONSTRUCTION_ERR_METRICS = {\n",
    "        'SSIM': ssim,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'PSNR': psnr,\n",
    "        'Edges_MSE': edges_mse,\n",
    "    }\n",
    "    \n",
    "    def __init__(self, recon_pair: FlowReconstructedImagePair):\n",
    "        im2 = recon_pair.opair.get_img2()\n",
    "        img2_recon_fwd = recon_pair.img2_recon_fwd\n",
    "        img2_recon_fwd_valid = recon_pair.img2_recon_fwd_valid\n",
    "        self.forward_stats = dict(\n",
    "            (name, func(im2, img2_recon_fwd, img2_recon_fwd_valid))\n",
    "            for name, func in self.RECONSTRUCTION_ERR_METRICS.items())\n",
    "        \n",
    "        im1 = recon_pair.opair.get_img1()\n",
    "        img1_recon_fwd = recon_pair.img1_recon_bkd\n",
    "        img1_recon_fwd_valid = recon_pair.img1_recon_bkd_valid\n",
    "        self.backward_stats = dict(\n",
    "            (name, func(im1, img1_recon_fwd, img1_recon_fwd_valid))\n",
    "            for name, func in self.RECONSTRUCTION_ERR_METRICS.items())\n",
    "\n",
    "    def to_html(self):\n",
    "        stat_names = self.RECONSTRUCTION_ERR_METRICS.keys()\n",
    "\n",
    "        rows = [\n",
    "            \"\"\"\n",
    "            <tr>\n",
    "              <td style=\"text-align:left\"><b>{name}</b></td>\n",
    "              <td style=\"text-align:left\">{fwd:.2f}</td>\n",
    "              <td style=\"text-align:left\">{bkd:.2f}</td>\n",
    "            </tr>\n",
    "            \"\"\".format(name=name, fwd=self.forward_stats[name], bkd=self.backward_stats[name])\n",
    "            for name in stat_names\n",
    "        ]\n",
    "        \n",
    "        \n",
    "        html = \"\"\"\n",
    "            <table>\n",
    "              <tr>\n",
    "                  <th></th> <th><b>Forwards Warp</b></th> <th><b>Backwards Warp</b></th>\n",
    "              </tr>\n",
    "\n",
    "              {table_rows}\n",
    "\n",
    "            </table>\n",
    "        \"\"\".format(table_rows=\"\".join(rows))\n",
    "        \n",
    "        return html\n",
    "            \n",
    "# @attr.s(slots=True, eq=False, weakref_slot=False)\n",
    "class OFlowStats(object):\n",
    "    \"\"\"Stats on the optical flow of a `OpticalFlowPair` instance\"\"\"\n",
    "\n",
    "    slots = (\n",
    "        'opair',\n",
    "        'coverage',\n",
    "        'magnitude_hist',\n",
    "    )\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        for k in self.slots:\n",
    "            setattr(self, k, kwargs.get(k))\n",
    "    \n",
    "#     opair = attr.ib(default=OpticalFlowPair())\n",
    "#     \"\"\"The original `OpticalFlowPair` with the source of the data for this reconstruction result.\"\"\"\n",
    "    \n",
    "#     coverage = attr.ib(default=0)\n",
    "#     \"\"\"Fraction of the image with valid flow\"\"\"\n",
    "    \n",
    "#     magnitude_hist = attr.ib(default=[np.array([]), np.array([])])\n",
    "#     \"\"\"Histogram [bin edges, bin counts] of flow magnitudes\"\"\"\n",
    "    \n",
    "    @classmethod\n",
    "    def create_from(cls, oflow_pair: OpticalFlowPair):\n",
    "        flow = oflow_pair.get_flow()\n",
    "        valid = ~zero_flow(flow)\n",
    "        return OFlowStats(\n",
    "                 opair=oflow_pair,\n",
    "                 coverage=oflow_coverage(valid),\n",
    "                 magnitude_hist=oflow_magnitude_hist(flow, valid))\n",
    "                 \n",
    "    def to_html(self):\n",
    "        import matplotlib.pyplot as plt\n",
    "        fig = plt.figure()\n",
    "        bin_edges, bin_counts = self.magnitude_hist\n",
    "        plt.bar(bin_edges[:-1], bin_counts)\n",
    "        plt.title(\"Histogram of Flow Magnitudes\")\n",
    "        plt.xlabel('Flow Magnitude (pixels)')\n",
    "        plt.ylabel('Count')\n",
    "\n",
    "        hist_img = matplotlib_fig_to_img(fig)\n",
    "        \n",
    "        html = \"\"\"\n",
    "            <table>           \n",
    "            <tr><td style=\"text-align:left\"><b>Flow Coverage:</b> {coverage:.2f}% </td></tr>\n",
    "            <tr><td><img src=\"{flow_hist}\" width=\"100%\" /></td></tr>\n",
    "            </table>\n",
    "        \"\"\".format(\n",
    "                coverage=100. * self.coverage,\n",
    "                flow_hist=img_to_data_uri(matplotlib_fig_to_img(hist_img)))\n",
    "        return html\n",
    "\n",
    "\n",
    "# Misc\n",
    "\n",
    "def matplotlib_fig_to_img(fig):\n",
    "    import io\n",
    "    import matplotlib.pyplot as plt\n",
    "    from PIL import Image\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    im = Image.open(buf)\n",
    "    im.show()\n",
    "    buf.seek(0)\n",
    "\n",
    "    import imageio\n",
    "    hist_img = imageio.imread(buf)\n",
    "    buf.close()\n",
    "    return hist_img\n",
    "\n",
    "\n",
    "if SHOW_DEMO_OUTPUT:\n",
    "    %matplotlib agg\n",
    "    for recon in DEMO_RECONS:\n",
    "        p = recon.opair\n",
    "        errors = OFlowReconErrors(recon)\n",
    "        err_html = errors.to_html()  \n",
    "            \n",
    "        fstats = OFlowStats.create_from(p)\n",
    "        stats_html = fstats.to_html()\n",
    "            \n",
    "        title = \"<b>{dataset} {id1} -> {id2}</b>\".format(dataset=p.dataset, id1=p.id1, id2=p.id2)\n",
    "        \n",
    "        show_html(title + stats_html + err_html + \"</br></br></br>\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene Flow Analysis (where depth and intrinsics are available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " * for psegs, we have uvd and K\n",
    " * for kitti tracking, we'll be able to have uvd and K\n",
    " * for deepdeform, the intrinsics are in each seq.  also a mask for maybe the images of interest?\n",
    " * for kitti sf, we can get K (P) from kitti-like file.  !!! kitti has obj_map colors image!!  \n",
    "     need to figure out depth meters from disparity ...  derrrp to get the raw velodynes we have to cross-ref\n",
    "     with odometry dataset. let's talk to yiyi about that...\n",
    " * !!! do a test where you use nearest neighbor correspondence on raw clouds for OFlow. then can see how bad\n",
    "     the pairing is sometimes\n",
    " \n",
    " * metrics: end-pt-error for NN forward; same for backward; then also do a chamfer distance metric\n",
    " * (do all this again but first do an ICP on the raw depths-- the rigid background should probably align, right?\n",
    "     use the ICP's RT to pose raw and \n",
    " * a common class for all these is background / foreground.  want to break down chamfer dist etc bucket by at least\n",
    "      background / foreground\n",
    " * debug image: surface pairs of points with end pt error larger than E and plot on the image\n",
    " \n",
    " * another good test: (1) train self-sup SF on raw clouds.  then test on large displacement pair \n",
    "     (walk a prediction forward many time steps). then can see how well that holds up vs our \"GT\"\n",
    " \n",
    "# From code above, which we won't run every time since\n",
    "# it's complicated and just gets static information.\n",
    "f, cx, cy, w, h = 1144.27150333,  960. ,  540., 1920, 1080\n",
    "K = np.array([\n",
    "      [f, 0, cx],\n",
    "      [0, f, cy],\n",
    "      [0, 0, 1],\n",
    "])\n",
    "\n",
    "px_y = np.tile(np.arange(h)[:, np.newaxis], [1, w])\n",
    "px_x = np.tile(np.arange(w)[np.newaxis, :], [h, 1])\n",
    "PYX = np.concatenate([px_y[:,:,np.newaxis], px_x[:, :,np.newaxis]], axis=-1)\n",
    "RAYS_FOR_CAM = np.zeros((h, w, 3))\n",
    "RAYS_FOR_CAM[:, :, 0] = (PYX[:, :, 0] - cy) / f\n",
    "RAYS_FOR_CAM[:, :, 1] = (PYX[:, :, 1] - cx) / f\n",
    "RAYS_FOR_CAM[:, :, 2] = 1\n",
    "\n",
    "yxz = RAYS_FOR_CAM * (demo[:, :, 3][:, :,np.newaxis])\n",
    "yxz = yxz.reshape([-1, 3])\n",
    "yxzrgb = np.concatenate([yxz, demo[:, :, :3].reshape([-1, 3])], axis=-1)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def nn_distance(xyz_src, xyz_target):\n",
    "    import numpy as np\n",
    "    import open3d as o3d\n",
    "    pcds = o3d.geometry.PointCloud()\n",
    "    pcds.points = o3d.utility.Vector3dVector(xyz_src)\n",
    "    pcdt = o3d.geometry.PointCloud()\n",
    "    pcdt.points = o3d.utility.Vector3dVector(xyz_target)\n",
    "    dists = pcds.compute_point_cloud_distance(pcdt)\n",
    "    dists = np.asarray(dists)\n",
    "    return dists\n",
    "\n",
    "\n",
    "class SFlowStats(object):\n",
    "    \"\"\"Stats on the scene flow of a `OpticalFlowPair` instance (that has scene flow data)\"\"\"\n",
    "\n",
    "    slots = (\n",
    "        'fwd_nn_end_point_error',\n",
    "        'bkd_nn_end_point_error',\n",
    "        'chamfer_distance',\n",
    "        'fwd_epe_50th',\n",
    "        'fwd_epe_75th',\n",
    "        'fwd_epe_95th',\n",
    "#         'icp_fwd_nn_end_point_error',\n",
    "#         'icp_bkd_nn_end_point_error',\n",
    "#         'icp_chamfer_distance',\n",
    "        \n",
    "        'opair',\n",
    "        'coverage',\n",
    "        'magnitude_hist',\n",
    "    )\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        for k in self.slots:\n",
    "            setattr(self, k, kwargs.get(k))\n",
    "    \n",
    "#     opair = attr.ib(default=OpticalFlowPair())\n",
    "#     \"\"\"The original `OpticalFlowPair` with the source of the data for this reconstruction result.\"\"\"\n",
    "    \n",
    "#     coverage = attr.ib(default=0)\n",
    "#     \"\"\"Fraction of the image with valid flow\"\"\"\n",
    "    \n",
    "#     magnitude_hist = attr.ib(default=[np.array([]), np.array([])])\n",
    "#     \"\"\"Histogram [bin edges, bin counts] of flow magnitudes\"\"\"\n",
    "    \n",
    "#     @classmethod\n",
    "#     def create_from(cls, oflow_pair: OpticalFlowPair):\n",
    "#         flow = oflow_pair.get_flow()\n",
    "#         valid = ~zero_flow(flow)\n",
    "#         return OFlowStats(\n",
    "#                  opair=oflow_pair,\n",
    "#                  coverage=oflow_coverage(valid),\n",
    "#                  magnitude_hist=oflow_magnitude_hist(flow, valid))\n",
    "                 \n",
    "#     def to_html(self):\n",
    "#         import matplotlib.pyplot as plt\n",
    "#         fig = plt.figure()\n",
    "#         bin_edges, bin_counts = self.magnitude_hist\n",
    "#         plt.bar(bin_edges[:-1], bin_counts)\n",
    "#         plt.title(\"Histogram of Flow Magnitudes\")\n",
    "#         plt.xlabel('Flow Magnitude (pixels)')\n",
    "#         plt.ylabel('Count')\n",
    "\n",
    "#         hist_img = matplotlib_fig_to_img(fig)\n",
    "        \n",
    "#         html = \"\"\"\n",
    "#             <table>           \n",
    "#             <tr><td style=\"text-align:left\"><b>Flow Coverage:</b> {coverage:.2f}% </td></tr>\n",
    "#             <tr><td><img src=\"{flow_hist}\" width=\"100%\" /></td></tr>\n",
    "#             </table>\n",
    "#         \"\"\".format(\n",
    "#                 coverage=100. * self.coverage,\n",
    "#                 flow_hist=img_to_data_uri(matplotlib_fig_to_img(hist_img)))\n",
    "#         return html\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis on Full Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('/opt/psegs')\n",
    "\n",
    "# from oarphpy.spark import NBSpark\n",
    "# NBSpark.SRC_ROOT = os.path.join(ALIB_SRC_DIR, 'cheap_optical_flow_eval_analysis')\n",
    "# NBSpark.CONF_KV.update({\n",
    "#     'spark.driver.maxResultSize': '2g',\n",
    "#     'spark.driver.memory': '16g',\n",
    "#   })\n",
    "# spark = NBSpark.getOrCreate()\n",
    "\n",
    "\n",
    "from oarphpy.spark import RowAdapter\n",
    "\n",
    "from pyspark import Row\n",
    "\n",
    "\n",
    "def flow_pair_to_full_row(fp):\n",
    "    from threadpoolctl import threadpool_limits\n",
    "    with threadpool_limits(limits=1, user_api='blas'):\n",
    "        recon = FlowReconstructedImagePair.create_from(fp)\n",
    "        fstats = OFlowStats.create_from(fp)\n",
    "        errors = OFlowReconErrors(recon)\n",
    "\n",
    "        rowdata = dict(\n",
    "                fp_datset=fp.dataset,\n",
    "                fp_uri=str(fp.uri),\n",
    "                flow_coverage=fstats.coverage,\n",
    "                diff_time_sec=fp.diff_time_sec,\n",
    "                translation_meters=fp.translation_meters,\n",
    "        )\n",
    "        rowdata.update(\n",
    "            ('Forwards_' + k, float(v))\n",
    "            for k, v in errors.forward_stats.items())\n",
    "        rowdata.update(\n",
    "            ('Backwards_' + k, float(v))\n",
    "            for k, v in errors.backward_stats.items())\n",
    "        return RowAdapter.to_row(rowdata)\n",
    "\n",
    "\n",
    "analysis_uris_demo = MiddFactory.list_fp_uris(spark) + PSEGS_SYNTHFLOW_DEMO_URIS + KITTI_SF15_DEMO_URIS + DD_DEMO_URIS\n",
    "\n",
    "\n",
    "class UnionFactory(FlowPairUnionFactory):\n",
    "    FACTORIES = ALL_FP_FACTORY_CLSS\n",
    "\n",
    "analysis_uris_full = UnionFactory.list_fp_uris(spark)\n",
    "# analysis_uris_full = analysis_uris_full[4900:]\n",
    "print('analysis_uris_full', len(analysis_uris_full))\n",
    "\n",
    "from oarphpy import util as oputil\n",
    "thru = oputil.ThruputObserver(name='run_analysis', n_total=len(analysis_uris_full))\n",
    "for uri_chunk in oputil.ichunked(analysis_uris_full, 100):\n",
    "    thru.start_block()\n",
    "    fp_rdd = UnionFactory.get_fp_rdd_for_uris(spark, uri_chunk)\n",
    "    result_rdd = fp_rdd.map(flow_pair_to_full_row)\n",
    "    df = spark.createDataFrame(result_rdd)\n",
    "    df.write.save(\n",
    "            mode='append',\n",
    "            path='/outer_root/media/rocket4q/oflow_pq_eval_test.parquet',\n",
    "            format='parquet',\n",
    "            compression='lz4')\n",
    "    thru.stop_block(n=len(uri_chunk))\n",
    "    thru.maybe_log_progress(every_n=1)\n",
    "\n",
    "\n",
    "# if True:#RUN_FULL_ANALYSIS:\n",
    "# #     spark = Spark.getOrCreate()\n",
    "    \n",
    "# #     for p in ALL_FPS:\n",
    "# #         import cloudpickle\n",
    "# #         try:\n",
    "# #             cloudpickle.dumps(p)\n",
    "# #         except Exception:\n",
    "# #             assert False, p\n",
    "# #     print('all good')\n",
    "    \n",
    "#     import pickle\n",
    "#     fp_rdd = spark.sparkContext.parallelize(ALL_FPS, numSlices=200)\n",
    "# #     print(fp_rdd.count())\n",
    "#     df = spark.createDataFrame(fp_rdd.map(flow_pair_to_full_row)).persist()\n",
    "\n",
    "#     print(df.count())\n",
    "#     df.show(10)\n",
    "#     df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = spark.read.parquet('/outer_root/media/rocket4q/oflow_pq_eval_test.parquet')\n",
    "\n",
    "\n",
    "def add_dataset(row):\n",
    "    from psegs import datum\n",
    "    row = row.asDict()\n",
    "    uri = datum.URI.from_str(row['fp_uri'])\n",
    "    row['fp_dataset'] = uri.dataset\n",
    "    return row\n",
    "\n",
    "results_df = spark.createDataFrame(results_df.rdd.map(add_dataset))\n",
    "results_df = results_df.persist()\n",
    "\n",
    "results_df.show()\n",
    "results_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def fp_uri_to_fname(fp_uri):\n",
    "    fp_uri = str(fp_uri)\n",
    "    import urllib.parse\n",
    "    fname = urllib.parse.quote(fp_uri)\n",
    "    from slugify import slugify\n",
    "    fname = slugify(fname)\n",
    "    return fname\n",
    "\n",
    "def extract_fp_uris_from_html(html):\n",
    "    import re\n",
    "    matches = list(set(re.findall(r'alt=\\\\\"(.*?)\\\\\"', html)))\n",
    "    import html\n",
    "    return set(html.unescape(s) for s in matches)\n",
    "\n",
    "FLOW_EVAL_REPORT_BASEDIR = '/tmp/flow_eval/'\n",
    "from oarphpy import util as oputil\n",
    "oputil.mkdir(FLOW_EVAL_REPORT_BASEDIR)\n",
    "\n",
    "from oarphpy import plotting as pl\n",
    "class Plotter(pl.HistogramWithExamplesPlotter):\n",
    "    NUM_BINS = 50\n",
    "    ROWS_TO_DISPLAY_PER_BUCKET = 10\n",
    "    SUB_PIVOT_COL = 'fp_dataset'\n",
    "\n",
    "    def display_bucket(self, sub_pivot, bucket_id, irows):\n",
    "        from oarphpy.spark import RowAdapter\n",
    "        from psegs import datum\n",
    "        \n",
    "        # Sample from irows using reservior sampling\n",
    "        import random\n",
    "        rows = []\n",
    "        for i, row in enumerate(irows):\n",
    "            r = random.randint(0, i)\n",
    "            if r < cls.ROWS_TO_DISPLAY_PER_BUCKET:\n",
    "                if i < cls.ROWS_TO_DISPLAY_PER_BUCKET:\n",
    "                    rows.insert(r, row)\n",
    "                else:\n",
    "                    rows[r] = row\n",
    "        \n",
    "        # Now render each row to HTML\n",
    "        row_htmls = []\n",
    "        for row in rows:\n",
    "            rowdata = RowAdapter.from_row(row)\n",
    "            \n",
    "            fp_uri_str = rowdata['fp_uri']\n",
    "            fp_uri = datum.URI.from_str(fp_uri_str)\n",
    "            fp_page_uri = fp_uri_to_fname(fp_uri_str) + '.html'\n",
    "            dataset = fp_uri.dataset\n",
    "            id1 = \"TODO\"\n",
    "            id2 = \"TODO\"\n",
    "            \n",
    "            row_html = f\"\"\"\n",
    "                <a href=\"{fp_page_uri}\" alt=\"{fp_uri_str}\">\n",
    "                    {fp_uri.dataset} {fp_uri.split} {fp_uri.segment_id} {id1} -> {id2}\n",
    "                </a><br />\"\"\"\n",
    "            row_htmls.append(row_html)\n",
    "        \n",
    "        HTML = \"\"\"\n",
    "        <b>Pivot: {spv} Bucket: {bucket_id} </b> <br/>\n",
    "        \n",
    "        {row_bodies}\n",
    "        \"\"\".format(\n",
    "              spv=sub_pivot,\n",
    "              bucket_id=bucket_id,\n",
    "              row_bodies=\"<br/><br/><br/>\".join(row_htmls))\n",
    "        \n",
    "        return bucket_id, HTML\n",
    "\n",
    "plotter = Plotter()\n",
    "\n",
    "chosen_fp_uris = set()\n",
    "histogram_htmls = []\n",
    "cols = [col for col in results_df.columns if col not in ('fp_uri', 'fp_dataset')]\n",
    "print(\"Rendering %s histograms\" % len(cols))\n",
    "for col in cols:\n",
    "    print(\"Working on %s\" % col)\n",
    "#     fig = plotter.run(results_df, col)\n",
    "    dest = os.path.join(FLOW_EVAL_REPORT_BASEDIR, '%s.html' % col)\n",
    "#     pl.save_bokeh_fig(fig, dest)\n",
    "    \n",
    "    with open(dest, 'r') as f:\n",
    "        cur_chosen_fp_uris = extract_fp_uris_from_html(f.read())\n",
    "        print(len(cur_chosen_fp_uris))\n",
    "    chosen_fp_uris |= cur_chosen_fp_uris\n",
    "# assert False, len(chosen_fp_uris)\n",
    "    \n",
    "print(\"Rendering %s histogram bucket pages\" % len(chosen_fp_uris))\n",
    "class UnionFactory(FlowPairUnionFactory):\n",
    "    FACTORIES = ALL_FP_FACTORY_CLSS\n",
    "\n",
    "analysis_uris_full = UnionFactory.list_fp_uris(spark)\n",
    "\n",
    "fp_rdd = UnionFactory.get_fp_rdd_for_uris(spark, list(chosen_fp_uris))\n",
    "def render_and_save(fp):\n",
    "    from threadpoolctl import threadpool_limits\n",
    "    with threadpool_limits(limits=1, user_api='blas'):\n",
    "        import os\n",
    "        recon = FlowReconstructedImagePair.create_from(fp)\n",
    "        fstats = OFlowStats.create_from(fp)\n",
    "        errors = OFlowReconErrors(recon)\n",
    "        page_html = \"<br/>\".join((fp.to_html(), recon.to_html(), fstats.to_html(), errors.to_html()))\n",
    "\n",
    "        dest = os.path.join(FLOW_EVAL_REPORT_BASEDIR, fp_uri_to_fname(fp.uri) + '.html')\n",
    "        with open(dest, 'w') as f:\n",
    "            f.write(page_html)\n",
    "fp_rdd.foreach(render_and_save)\n",
    "    \n",
    "    \n",
    "# from bokeh.io import output_notebook\n",
    "# output_notebook()\n",
    "# from bokeh.plotting import show\n",
    "# show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
