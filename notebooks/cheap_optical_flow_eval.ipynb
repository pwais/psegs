{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cheap Optical Flow: Is it Good? Does it Boost?\n",
    "\n",
    "\n",
    "## Quickstart\n",
    "\n",
    "## Credits\n",
    "\n",
    "Some portions of this notebook adapted from:\n",
    " * [Middlebury Flow code by Johannes Oswald](https://github.com/Johswald/flow-code-python/blob/master/readFlowFile.py)\n",
    " * [DeepDeform Demo Code](https://github.com/AljazBozic/DeepDeform)\n",
    " * [OpticalFlowToolkit by RUOTENG LI](https://github.com/liruoteng/OpticalFlowToolkit)\n",
    " * [OpenCV Samples](https://github.com/opencv/opencv/blob/master/samples/python/opt_flow.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "SHOW_DEMO_OUTPUT = False\n",
    "DEMO_FPS = []\n",
    "\n",
    "RUN_FULL_ANALYSIS = False\n",
    "ALL_FP_FACTORY_CLSS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypng in /usr/local/lib/python3.8/dist-packages (0.0.20)\n",
      "Requirement already satisfied: scikit-image in /usr/lib/python3/dist-packages (0.16.2)\n",
      "fixme installs\n",
      "\n",
      "\n",
      "Putting analysis lib in /tmp/tmpr1cv1xt4_cheap_optical_flow_eval_analysis\n",
      "running clean\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing psegs.egg-info/PKG-INFO\n",
      "writing dependency_links to psegs.egg-info/dependency_links.txt\n",
      "writing top-level names to psegs.egg-info/top_level.txt\n",
      "reading manifest file 'psegs.egg-info/SOURCES.txt'\n",
      "writing manifest file 'psegs.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "warning: build_py: byte-compiling is disabled, skipping.\n",
      "\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/psegs\n",
      "copying build/lib/psegs/dummyrun.py -> build/bdist.linux-x86_64/egg/psegs\n",
      "creating build/bdist.linux-x86_64/egg/psegs/datasets\n",
      "copying build/lib/psegs/datasets/kitti.py -> build/bdist.linux-x86_64/egg/psegs/datasets\n",
      "copying build/lib/psegs/datasets/idsutil.py -> build/bdist.linux-x86_64/egg/psegs/datasets\n",
      "copying build/lib/psegs/datasets/kitti_360.py -> build/bdist.linux-x86_64/egg/psegs/datasets\n",
      "copying build/lib/psegs/datasets/__init__.py -> build/bdist.linux-x86_64/egg/psegs/datasets\n",
      "copying build/lib/psegs/datasets/nuscenes.py -> build/bdist.linux-x86_64/egg/psegs/datasets\n",
      "creating build/bdist.linux-x86_64/egg/psegs/util\n",
      "copying build/lib/psegs/util/__init__.py -> build/bdist.linux-x86_64/egg/psegs/util\n",
      "copying build/lib/psegs/util/misc.py -> build/bdist.linux-x86_64/egg/psegs/util\n",
      "copying build/lib/psegs/util/plotting.py -> build/bdist.linux-x86_64/egg/psegs/util\n",
      "creating build/bdist.linux-x86_64/egg/psegs/table\n",
      "copying build/lib/psegs/table/sd_db.py -> build/bdist.linux-x86_64/egg/psegs/table\n",
      "copying build/lib/psegs/table/sd_table.py -> build/bdist.linux-x86_64/egg/psegs/table\n",
      "copying build/lib/psegs/table/__init__.py -> build/bdist.linux-x86_64/egg/psegs/table\n",
      "copying build/lib/psegs/browser.py -> build/bdist.linux-x86_64/egg/psegs\n",
      "creating build/bdist.linux-x86_64/egg/psegs/datum\n",
      "copying build/lib/psegs/datum/uri.py -> build/bdist.linux-x86_64/egg/psegs/datum\n",
      "copying build/lib/psegs/datum/bbox2d.py -> build/bdist.linux-x86_64/egg/psegs/datum\n",
      "copying build/lib/psegs/datum/datumutils.py -> build/bdist.linux-x86_64/egg/psegs/datum\n",
      "copying build/lib/psegs/datum/transform.py -> build/bdist.linux-x86_64/egg/psegs/datum\n",
      "copying build/lib/psegs/datum/stamped_datum.py -> build/bdist.linux-x86_64/egg/psegs/datum\n",
      "copying build/lib/psegs/datum/cuboid.py -> build/bdist.linux-x86_64/egg/psegs/datum\n",
      "copying build/lib/psegs/datum/frame.py -> build/bdist.linux-x86_64/egg/psegs/datum\n",
      "copying build/lib/psegs/datum/point_cloud.py -> build/bdist.linux-x86_64/egg/psegs/datum\n",
      "copying build/lib/psegs/datum/camera_image.py -> build/bdist.linux-x86_64/egg/psegs/datum\n",
      "copying build/lib/psegs/datum/__init__.py -> build/bdist.linux-x86_64/egg/psegs/datum\n",
      "copying build/lib/psegs/spark.py -> build/bdist.linux-x86_64/egg/psegs\n",
      "copying build/lib/psegs/conf.py -> build/bdist.linux-x86_64/egg/psegs\n",
      "copying build/lib/psegs/dsutil.py -> build/bdist.linux-x86_64/egg/psegs\n",
      "copying build/lib/psegs/__init__.py -> build/bdist.linux-x86_64/egg/psegs\n",
      "creating build/bdist.linux-x86_64/egg/psegs/exp\n",
      "copying build/lib/psegs/exp/semantic_kitti.py -> build/bdist.linux-x86_64/egg/psegs/exp\n",
      "copying build/lib/psegs/exp/fused_lidar_flow.py -> build/bdist.linux-x86_64/egg/psegs/exp\n",
      "copying build/lib/psegs/exp/__init__.py -> build/bdist.linux-x86_64/egg/psegs/exp\n",
      "copying build/lib/psegs/ros.py -> build/bdist.linux-x86_64/egg/psegs\n",
      "warning: install_lib: byte-compiling is disabled, skipping.\n",
      "\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying psegs.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying psegs.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying psegs.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying psegs.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "creating 'dist/psegs-0.0.1-py3.8.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-10 00:21:41,483\toarph 1825795 : Using source root /tmp/tmpr1cv1xt4_cheap_optical_flow_eval_analysis/cheap_optical_flow_eval_analysis \n",
      "2021-04-10 00:21:41,483\toarph 1825795 : Using source root /tmp/tmpr1cv1xt4_cheap_optical_flow_eval_analysis \n",
      "2021-04-10 00:21:41,526\toarph 1825795 : Generating egg to /tmp/tmp9to_13vm_oarphpy_eggbuild ...\n",
      "2021-04-10 00:21:41,538\toarph 1825795 : ... done.  Egg at /tmp/tmp9to_13vm_oarphpy_eggbuild/cheap_optical_flow_eval_analysis-0.0.0-py3.8.egg\n"
     ]
    }
   ],
   "source": [
    "## Setup\n",
    "\n",
    "!pip3 install pypng scikit-image\n",
    "print('fixme installs')\n",
    "print()\n",
    "print()\n",
    "\n",
    "import copy\n",
    "import imageio\n",
    "import IPython.display\n",
    "import math\n",
    "import os\n",
    "import PIL.Image\n",
    "import six\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "\n",
    "## General Notebook Utilities\n",
    "    \n",
    "def imshow(x):\n",
    "    IPython.display.display(PIL.Image.fromarray(x))\n",
    "\n",
    "def show_html(x):\n",
    "    from IPython.core.display import display, HTML\n",
    "    display(HTML(x))\n",
    "\n",
    "\n",
    "## Create a random temporary directory for analysis library (for Spark-enabled full analysis mode)\n",
    "old_cwd = os.getcwd()\n",
    "tempdir = tempfile.TemporaryDirectory(suffix='_cheap_optical_flow_eval_analysis')\n",
    "ALIB_SRC_DIR = tempdir.name\n",
    "print(\"Putting analysis lib in %s\" % ALIB_SRC_DIR)\n",
    "os.chdir(ALIB_SRC_DIR)\n",
    "!mkdir -p cheap_optical_flow_eval_analysis\n",
    "!touch cheap_optical_flow_eval_analysis/__init__.py\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append(ALIB_SRC_DIR)\n",
    "\n",
    "\n",
    "## Prepare a build of local psegs for inclusion\n",
    "!cd /opt/psegs && python3 setup.py clean bdist_egg\n",
    "PSEGS_EGG_PATH = '/opt/psegs/dist/psegs-0.0.1-py3.8.egg'\n",
    "assert os.path.exists(PSEGS_EGG_PATH), \"Build failed?\"\n",
    "sys.path.append('/opt/psegs')\n",
    "import psegs\n",
    "\n",
    "\n",
    "## Prepare Spark session with local PSegs and local Analysis Lib\n",
    "from psegs.spark import NBSpark\n",
    "NBSpark.SRC_ROOT = os.path.join(ALIB_SRC_DIR, 'cheap_optical_flow_eval_analysis')\n",
    "NBSpark.CONF_KV.update({\n",
    "    'spark.driver.maxResultSize': '2g',\n",
    "    'spark.driver.memory': '16g',\n",
    "    'spark.submit.pyFiles': PSEGS_EGG_PATH,\n",
    "  })\n",
    "spark = NBSpark.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cheap_optical_flow_eval_analysis/ofp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile cheap_optical_flow_eval_analysis/ofp.py\n",
    "\n",
    "## Data Model & Utility Code\n",
    "\n",
    "import attr\n",
    "import cv2\n",
    "import imageio\n",
    "import math\n",
    "import os\n",
    "import PIL.Image\n",
    "import six\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from psegs import datum\n",
    "\n",
    "from oarphpy import plotting as op_plt\n",
    "from oarphpy.spark import CloudpickeledCallable\n",
    "img_to_data_uri = lambda x: op_plt.img_to_data_uri(x, format='png')\n",
    "\n",
    "@attr.s(slots=True, eq=False, weakref_slot=False)\n",
    "class OpticalFlowPair(object):\n",
    "    \"\"\"A flyweight for a pair of images with an optical flow field.\n",
    "    Supports lazy-loading of large data attributes.\"\"\"\n",
    "    \n",
    "    ## Core Attributes (Required for All Datasets)\n",
    "    \n",
    "    dataset = attr.ib(type=str, default='')\n",
    "    \"\"\"(Display name) To which dataset does this pair belong?\"\"\"\n",
    "    \n",
    "    id1 = attr.ib(type=str, default='')\n",
    "    \"\"\"Identifier or URI for the first image\"\"\"\n",
    "    \n",
    "    id2 = attr.ib(type=str, default='')\n",
    "    \"\"\"Identifier or URI for the second image\"\"\"\n",
    "    \n",
    "    img1 = attr.ib(default=None)\n",
    "    \"\"\"URI or numpy array or CloudPickleCallable for the first image (source image)\"\"\"\n",
    "\n",
    "    img2 = attr.ib(default=None)\n",
    "    \"\"\"URI or numpy array or CloudpickeledCallable for the second image (target image)\"\"\"\n",
    "    \n",
    "    flow = attr.ib(default=None)\n",
    "    \"\"\"A numpy array or callable or CloudpickeledCallable representing optical flow from img1 -> img2\"\"\"\n",
    "    \n",
    "    uri = attr.ib(type=datum.URI, default=None, converter=datum.URI.from_str)\n",
    "    \"\"\"A URI addressing this pair; to make dynamic construction of the pair easier\"\"\"\n",
    "    \n",
    "    ## Optional Attributes (For Select Datasets)\n",
    "    \n",
    "    diff_time_sec = attr.ib(type=float, default=0.0)\n",
    "    \"\"\"Difference in time (in seconds) between the views / poses depicted in `img1` and `img2`.\"\"\"\n",
    "    \n",
    "    translation_meters = attr.ib(type=float, default=0.0)\n",
    "    \"\"\"Difference in ego translation (in meters) between the views / poses depicted in `img1` and `img2`.\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    # to add:\n",
    "    # diff time seconds\n",
    "    # semantic image for frame 1, frame 2 [could be painted by cuboids]\n",
    "    # instance images for frame 1, frame 2 [could be painted by cuboids]\n",
    "    #   -- for colored images, at first just pivot all oflow metrics by colors\n",
    "    # get uvdviz1 uvdviz2 (scene flow)\n",
    "    #   * for deepeform, their load_flow will work\n",
    "    #   * for kitti, we have to read their disparity images\n",
    "    # get uvd1 uvd2 (lidar for nearest neighbor stuff)\n",
    "    # depth image for frame 1, frame 2 [could be interpolated by cuboids]\n",
    "    #   -- at first bucket the depth coarsely and pivot al oflow by colors\n",
    "    \n",
    "    def get_img1(self):\n",
    "        if isinstance(self.img1, CloudpickeledCallable):\n",
    "            self.img1 = self.img1()\n",
    "        if isinstance(self.img1, six.string_types):\n",
    "            self.img1 = imageio.imread(self.img1)\n",
    "        return self.img1\n",
    "    \n",
    "    def get_img2(self):\n",
    "        if isinstance(self.img2, CloudpickeledCallable):\n",
    "            self.img2 = self.img2()\n",
    "        if isinstance(self.img2, six.string_types):\n",
    "            self.img2 = imageio.imread(self.img2)\n",
    "        return self.img2\n",
    "    \n",
    "    def get_flow(self):\n",
    "        if not isinstance(self.flow, (np.ndarray, np.generic)):\n",
    "            self.flow = self.flow()\n",
    "        return self.flow\n",
    "    \n",
    "    def to_html(self):\n",
    "        im1 = self.get_img1()\n",
    "        im2 = self.get_img2()\n",
    "        flow = self.get_flow()\n",
    "        fviz = draw_flow(im1, flow)\n",
    "        html = \"\"\"\n",
    "            <table>\n",
    "            \n",
    "            <tr><td style=\"text-align:left\"><b>Dataset:</b> {dataset}</td></tr>\n",
    "            <tr><td style=\"text-align:left\"><b>URI:</b> {uri}</td></tr>\n",
    "            \n",
    "            <tr><td style=\"text-align:left\"><b>Source Image:</b> {id1}</td></tr>\n",
    "            <tr><td><img src=\"{im1}\" /></td></tr>\n",
    "\n",
    "            <tr><td style=\"text-align:left\"><b>Target Image:</b> {id2}</td></tr>\n",
    "            <tr><td><img src=\"{im2}\" /></td></tr>\n",
    "\n",
    "            <tr><td style=\"text-align:left\"><b>Flow</b></td></tr>\n",
    "            <tr><td><img src=\"{fviz}\" /></td></tr>\n",
    "            </table>\n",
    "        \"\"\".format(\n",
    "                dataset=self.dataset,\n",
    "                uri=str(self.uri),\n",
    "                id1=self.id1, id2=self.id2,\n",
    "                im1=img_to_data_uri(im1), im2=img_to_data_uri(im2),\n",
    "                fviz=img_to_data_uri(fviz))\n",
    "        return html\n",
    "\n",
    "def draw_flow(img, flow, step=8):\n",
    "    \"\"\"Based upon OpenCV sample: https://github.com/opencv/opencv/blob/master/samples/python/opt_flow.py\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    y, x = np.mgrid[step/2:h:step, step/2:w:step].reshape(2,-1).astype(int)\n",
    "    fx, fy = flow[y,x].T\n",
    "    lines = np.vstack([x, y, x+fx, y+fy]).T.reshape(-1, 2, 2)\n",
    "    lines = np.int32(lines + 0.5)\n",
    "    vis = img.copy()\n",
    "    cv2.polylines(vis, lines, 0, (0, 255, 0))\n",
    "    for (x1, y1), (_x2, _y2) in lines:\n",
    "        cv2.circle(vis, (x1, y1), 1, (0, 255, 0), -1)\n",
    "    return vis\n",
    "\n",
    "\n",
    "class FlowPairFactoryBase(object):\n",
    "    DATASET = ''\n",
    "\n",
    "    @classmethod\n",
    "    def list_fp_uris(cls, spark):\n",
    "        return []\n",
    "    \n",
    "    @classmethod\n",
    "    def get_fp_rdd_for_uris(cls, spark, uris):\n",
    "        uris = [datum.URI.from_str(u) for u in uris]\n",
    "        uris = [u for u in uris if u.dataset == cls.DATASET]\n",
    "        if not uris:\n",
    "            return None\n",
    "        return cls._get_fp_rdd_for_uris(spark, uris)\n",
    "\n",
    "    @classmethod\n",
    "    def _get_fp_rdd_for_uris(cls, spark, uris):\n",
    "        return None\n",
    "\n",
    "class FlowPairUnionFactory(FlowPairFactoryBase):\n",
    "    FACTORIES = []\n",
    "    \n",
    "    @classmethod\n",
    "    def list_fp_uris(cls, spark):\n",
    "        import itertools\n",
    "        return list(itertools.chain.from_iterable(F.list_fp_uris(spark) for F in cls.FACTORIES))\n",
    "    \n",
    "    @classmethod\n",
    "    def get_fp_rdd_for_uris(cls, spark, uris):\n",
    "        rdds = []\n",
    "        for F in cls.FACTORIES:\n",
    "            rdd = F.get_fp_rdd_for_uris(spark, uris)\n",
    "            if rdd is not None:\n",
    "                rdds.append(rdd)\n",
    "        assert rdds, \"No RDDs for %s\" % uris\n",
    "        return spark.sparkContext.union(rdds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-10 00:21:44,800\toarph 1825795 : Source has changed! Rebuilding Egg ...\n",
      "2021-04-10 00:21:44,800\toarph 1825795 : Using source root /tmp/tmpr1cv1xt4_cheap_optical_flow_eval_analysis/cheap_optical_flow_eval_analysis \n",
      "2021-04-10 00:21:44,801\toarph 1825795 : Using source root /tmp/tmpr1cv1xt4_cheap_optical_flow_eval_analysis \n",
      "2021-04-10 00:21:44,803\toarph 1825795 : Generating egg to /tmp/tmp_922idch_oarphpy_eggbuild ...\n",
      "2021-04-10 00:21:44,810\toarph 1825795 : ... done.  Egg at /tmp/tmp_922idch_oarphpy_eggbuild/cheap_optical_flow_eval_analysis-0.0.0-py3.8.egg\n"
     ]
    }
   ],
   "source": [
    "from cheap_optical_flow_eval_analysis.ofp import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Middlebury Optical Flow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO talk configs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cheap_optical_flow_eval_analysis/midd.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile cheap_optical_flow_eval_analysis/midd.py\n",
    "\n",
    "from psegs import datum\n",
    "\n",
    "from cheap_optical_flow_eval_analysis.ofp import *\n",
    "\n",
    "# Please unzip `other-color-allframes.zip` and `other-gt-flow.zip` to a directory and provide the target below:\n",
    "MIDD_DATA_ROOT = '/opt/psegs/ext_data/middlebury-flow/'\n",
    "\n",
    "# For the Middlebury Flow dataset, we only consider the real scenes\n",
    "MIDD_SCENES = [\n",
    "    {\n",
    "        'input': 'other-data/Dimetrodon/frame10.png',\n",
    "        'expected_out': 'other-data/Dimetrodon/frame11.png',\n",
    "        'flow_gt': 'other-gt-flow/Dimetrodon/flow10.flo',\n",
    "    },\n",
    "        {\n",
    "        'input': 'other-data/Hydrangea/frame10.png',\n",
    "        'expected_out': 'other-data/Hydrangea/frame11.png',\n",
    "        'flow_gt': 'other-gt-flow/Hydrangea/flow10.flo',\n",
    "    },\n",
    "        {\n",
    "        'input': 'other-data/RubberWhale/frame10.png',\n",
    "        'expected_out': 'other-data/RubberWhale/frame11.png',\n",
    "        'flow_gt': 'other-gt-flow/RubberWhale/flow10.flo',\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "def midd_read_flow(path):\n",
    "    import os\n",
    "    import numpy as np\n",
    "    # Based upon: https://github.com/Johswald/flow-code-python/blob/master/readFlowFile.py\n",
    "    # compute colored image to visualize optical flow file .flo\n",
    "    # Author: Johannes Oswald, Technical University Munich\n",
    "    # Contact: johannes.oswald@tum.de\n",
    "    # Date: 26/04/2017\n",
    "    # For more information, check http://vision.middlebury.edu/flow/ \n",
    "    assert os.path.exists(path) and path.endswith('.flo'), path\n",
    "    f = open(path, 'rb')\n",
    "    flo_number = np.fromfile(f, np.float32, count=1)[0]\n",
    "    TAG_FLOAT = 202021.25\n",
    "    assert flo_number == TAG_FLOAT, 'Flow number %r incorrect.' % flo_number\n",
    "    w = np.fromfile(f, np.int32, count=1)\n",
    "    h = np.fromfile(f, np.int32, count=1)\n",
    "\n",
    "    #if error try: data = np.fromfile(f, np.float32, count=2*w[0]*h[0])\n",
    "    data = np.fromfile(f, np.float32, count=int(2*w*h))\n",
    "\n",
    "    # Reshape data into 3D array (columns, rows, bands)\n",
    "    flow = np.resize(data, (int(h), int(w), 2))\t\n",
    "    f.close()\n",
    "\n",
    "    # We found that there are some invalid (?) (i.e. very large) flows, so we're going\n",
    "    # to ignore those for this experiment.\n",
    "    invalid = (flow >= 1666)\n",
    "    flow[invalid] = 0\n",
    "\n",
    "    return flow\n",
    "\n",
    "def midd_create_fp(uri):\n",
    "    scene_idx = int(uri.extra['midd.scene_idx'])\n",
    "    scene = MIDD_SCENES[scene_idx]\n",
    "    data_root = uri.extra['midd.dataroot']\n",
    "    return OpticalFlowPair(\n",
    "                uri=uri,\n",
    "                dataset=\"Middlebury Optical Flow\",\n",
    "                id1=scene['input'],\n",
    "                img1='file://' + os.path.join(data_root, scene['input']),\n",
    "                id2=scene['expected_out'],\n",
    "                img2='file://' + os.path.join(data_root, scene['expected_out']),\n",
    "                flow=CloudpickeledCallable(lambda: midd_read_flow(os.path.join(data_root, scene['flow_gt']))))\n",
    "    \n",
    "\n",
    "class MiddFactory(FlowPairFactoryBase):\n",
    "    DATASET = 'midd_oflow'\n",
    "    \n",
    "    @classmethod\n",
    "    def list_fp_uris(cls, spark):\n",
    "        return [\n",
    "            datum.URI(dataset=cls.DATASET, extra={'midd.scene_idx': i, 'midd.dataroot': MIDD_DATA_ROOT})\n",
    "            for i, scene in enumerate(MIDD_SCENES)\n",
    "        ]\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_fp_rdd_for_uris(cls, spark, uris):\n",
    "        uri_rdd = spark.sparkContext.parallelize(uris)\n",
    "        fp_rdd = uri_rdd.map(midd_create_fp)\n",
    "        return fp_rdd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-10 00:21:44,897\toarph 1825795 : Source has changed! Rebuilding Egg ...\n",
      "2021-04-10 00:21:44,898\toarph 1825795 : Using source root /tmp/tmpr1cv1xt4_cheap_optical_flow_eval_analysis/cheap_optical_flow_eval_analysis \n",
      "2021-04-10 00:21:44,899\toarph 1825795 : Using source root /tmp/tmpr1cv1xt4_cheap_optical_flow_eval_analysis \n",
      "2021-04-10 00:21:44,900\toarph 1825795 : Generating egg to /tmp/tmpa1c4wqjj_oarphpy_eggbuild ...\n",
      "2021-04-10 00:21:44,907\toarph 1825795 : ... done.  Egg at /tmp/tmpa1c4wqjj_oarphpy_eggbuild/cheap_optical_flow_eval_analysis-0.0.0-py3.8.egg\n"
     ]
    }
   ],
   "source": [
    "from cheap_optical_flow_eval_analysis.midd import MiddFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 Midd scenes\n"
     ]
    }
   ],
   "source": [
    "ALL_FP_FACTORY_CLSS.append(MiddFactory)\n",
    "\n",
    "print(\"Found %s Midd scenes\" % len(MiddFactory.list_fp_uris(spark)))\n",
    "\n",
    "if SHOW_DEMO_OUTPUT:\n",
    "    demo_uris = MiddFactory.list_fp_uris(spark)\n",
    "    fp_rdd = MiddFactory.get_fp_rdd_for_uris(spark, demo_uris)\n",
    "    fps = fp_rdd.collect()\n",
    "    \n",
    "    for fp in fps:\n",
    "        show_html(fp.to_html() + \"<br/><br/><br/>\")\n",
    "        DEMO_FPS.append(fp)\n",
    "\n",
    "# for i, scene in enumerate(MIDD_SCENES):\n",
    "#     p = OpticalFlowPair(\n",
    "#             dataset=\"Middlebury Optical Flow\",\n",
    "#             id1=scene['input'],\n",
    "#             img1='file://' + os.path.join(MIDD_DATA_ROOT, scene['input']),\n",
    "#             id2=scene['expected_out'],\n",
    "#             img2='file://' + os.path.join(MIDD_DATA_ROOT, scene['expected_out']),\n",
    "#             flow=CloudpickeledCallable(lambda: midd_read_flow(os.path.join(MIDD_DATA_ROOT, scene['flow_gt']))))\n",
    "    \n",
    "#     if RUN_FULL_ANALYSIS:\n",
    "#         ALL_FPS.append(copy.deepcopy(p))\n",
    "    \n",
    "#     if SHOW_DEMO_OUTPUT:\n",
    "#         show_html(p.to_html() + \"<br/><br/><br/>\")\n",
    "#         DEMO_FPS.append(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepDeform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cheap_optical_flow_eval_analysis/deepdeform.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile cheap_optical_flow_eval_analysis/deepdeform.py\n",
    "\n",
    "from psegs import datum\n",
    "\n",
    "from cheap_optical_flow_eval_analysis.ofp import *\n",
    "\n",
    "# Please extract deepdeform_v1.7z to a directory and provide the target below:\n",
    "DD_DATA_ROOT = '/opt/psegs/ext_data/deepdeform_v1/'\n",
    "\n",
    "def dd_load_oflow(path):\n",
    "    # Based upon https://github.com/AljazBozic/DeepDeform/blob/master/utils.py#L1\n",
    "    import shutil\n",
    "    import struct\n",
    "    import os\n",
    "    import numpy as np\n",
    "\n",
    "    # Flow is stored row-wise in order [channels, height, width].\n",
    "    assert os.path.isfile(path)\n",
    "\n",
    "    flow_gt = None\n",
    "    with open(path, 'rb') as fin:\n",
    "        width = struct.unpack('I', fin.read(4))[0]\n",
    "        height = struct.unpack('I', fin.read(4))[0]\n",
    "        channels = struct.unpack('I', fin.read(4))[0]\n",
    "        n_elems = height * width * channels\n",
    "\n",
    "        flow = struct.unpack('f' * n_elems, fin.read(n_elems * 4))\n",
    "        flow_gt = np.asarray(flow, dtype=np.float32).reshape([channels, height, width])\n",
    "\n",
    "    # Match format used in this analysis\n",
    "    flow_gt = np.moveaxis(flow_gt, 0, -1) # (h, w, 2)\n",
    "    invalid_flow = flow_gt == -np.Inf\n",
    "    flow_gt[invalid_flow] = 0.0\n",
    "    return flow_gt\n",
    "\n",
    "def dd_create_fp(uri):\n",
    "    return OpticalFlowPair(\n",
    "                uri=uri,\n",
    "                dataset=\"DeepDeform Semi-Synthetic Optical Flow\",\n",
    "                id1=uri.extra['dd.input'],\n",
    "                img1='file://' + os.path.join(DD_DATA_ROOT, uri.extra['dd.input']),\n",
    "                id2=uri.extra['dd.expected_out'],\n",
    "                img2='file://' + os.path.join(DD_DATA_ROOT, uri.extra['dd.expected_out']),\n",
    "                flow=dd_load_oflow(os.path.join(DD_DATA_ROOT, uri.extra['dd.flow_gt'])))\n",
    "\n",
    "\n",
    "class DDFactory(FlowPairFactoryBase):\n",
    "    DATASET = 'deep_deform'\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_all_scenes(cls):\n",
    "        import json\n",
    "        DD_ALIGNMENTS = json.load(open(os.path.join(DD_DATA_ROOT, 'train_alignments.json')))\n",
    "        ALL_DD_SCENES = [\n",
    "            {\n",
    "                \"dd.input\": ascene['source_color'],\n",
    "                \"dd.expected_out\": ascene['target_color'],\n",
    "                \"dd.flow_gt\": ascene['optical_flow'],\n",
    "            }\n",
    "            for ascene in DD_ALIGNMENTS\n",
    "        ]\n",
    "        return ALL_DD_SCENES\n",
    "    \n",
    "    @classmethod\n",
    "    def list_fp_uris(cls, spark):\n",
    "        scenes = cls._get_all_scenes()\n",
    "        return [\n",
    "            datum.URI(dataset=cls.DATASET, extra=scene)\n",
    "            for scene in scenes\n",
    "        ]\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_fp_rdd_for_uris(cls, spark, uris):\n",
    "        uri_rdd = spark.sparkContext.parallelize(uris)\n",
    "        fp_rdd = uri_rdd.map(dd_create_fp)\n",
    "        return fp_rdd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-10 00:21:44,958\toarph 1825795 : Source has changed! Rebuilding Egg ...\n",
      "2021-04-10 00:21:44,959\toarph 1825795 : Using source root /tmp/tmpr1cv1xt4_cheap_optical_flow_eval_analysis/cheap_optical_flow_eval_analysis \n",
      "2021-04-10 00:21:44,959\toarph 1825795 : Using source root /tmp/tmpr1cv1xt4_cheap_optical_flow_eval_analysis \n",
      "2021-04-10 00:21:44,961\toarph 1825795 : Generating egg to /tmp/tmp0ama35c5_oarphpy_eggbuild ...\n",
      "2021-04-10 00:21:44,969\toarph 1825795 : ... done.  Egg at /tmp/tmp0ama35c5_oarphpy_eggbuild/cheap_optical_flow_eval_analysis-0.0.0-py3.8.egg\n"
     ]
    }
   ],
   "source": [
    "from cheap_optical_flow_eval_analysis.deepdeform import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4540 DeepDeform scenes\n"
     ]
    }
   ],
   "source": [
    "from psegs import datum\n",
    "\n",
    "DD_DEMO_URIS = [\n",
    "    datum.URI(dataset=DDFactory.DATASET, extra={\n",
    "        \"dd.input\": \"train/seq000/color/000000.jpg\",\n",
    "        \"dd.expected_out\": \"train/seq000/color/000200.jpg\",\n",
    "        \"dd.flow_gt\": \"train/seq000/optical_flow/blackdog_000000_000200.oflow\",\n",
    "    }),\n",
    "    datum.URI(dataset=DDFactory.DATASET, extra={\n",
    "        \"dd.input\": \"train/seq000/color/000000.jpg\",\n",
    "        \"dd.expected_out\": \"train/seq000/color/001200.jpg\",\n",
    "        \"dd.flow_gt\": \"train/seq000/optical_flow/blackdog_000000_001200.oflow\",\n",
    "    }),\n",
    "    datum.URI(dataset=DDFactory.DATASET, extra={\n",
    "        \"dd.input\": \"train/seq001/color/003400.jpg\",\n",
    "        \"dd.expected_out\": \"train/seq001/color/003600.jpg\",\n",
    "        \"dd.flow_gt\": \"train/seq001/optical_flow/lady_003400_003600.oflow\",\n",
    "    }),\n",
    "    datum.URI(dataset=DDFactory.DATASET, extra={\n",
    "        \"dd.input\": \"train/seq337/color/000050.jpg\",\n",
    "        \"dd.expected_out\": \"train/seq337/color/000350.jpg\",\n",
    "        \"dd.flow_gt\": \"train/seq337/optical_flow/adult_000050_000350.oflow\",\n",
    "    }),\n",
    "]\n",
    "\n",
    "ALL_FP_FACTORY_CLSS.append(DDFactory)\n",
    "\n",
    "print(\"Found %s DeepDeform scenes\" % len(DDFactory.list_fp_uris(spark)))\n",
    "\n",
    "if SHOW_DEMO_OUTPUT:\n",
    "    fp_rdd = DDFactory.get_fp_rdd_for_uris(spark, DD_DEMO_URIS)\n",
    "    fps = fp_rdd.collect()\n",
    "    \n",
    "    for fp in fps:\n",
    "        show_html(fp.to_html() + \"<br/><br/><br/>\")\n",
    "        DEMO_FPS.append(fp)\n",
    "\n",
    "\n",
    "\n",
    "# import json\n",
    "# DD_ALIGNMENTS = json.load(open(os.path.join(DD_DATA_ROOT, 'train_alignments.json')))\n",
    "# ALL_DD_SCENES = [\n",
    "#     {\n",
    "#         \"input\": ascene['source_color'],\n",
    "#         \"expected_out\": ascene['target_color'],\n",
    "#         \"flow_gt\": ascene['optical_flow'],\n",
    "#     }\n",
    "#     for ascene in DD_ALIGNMENTS\n",
    "# ]\n",
    "\n",
    "# print(\"Found %s DeepDeform scenes\" % len(ALL_DD_SCENES))\n",
    "# if SHOW_DEMO_OUTPUT:\n",
    "#     for scene in DD_DEMO_SCENES:\n",
    "#         p = dd_create_fp(scene)\n",
    "#         show_html(p.to_html())\n",
    "#         DEMO_FPS.append(p)\n",
    "\n",
    "# if RUN_FULL_ANALYSIS:\n",
    "#     for scene in ALL_DD_SCENES:\n",
    "#         p = dd_create_fp(scene)\n",
    "#         ALL_FPS.append(p)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kitti Scene Flow Benchmark (2015)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Please unzip `data_scene_flow.zip` and `data_scene_flow_calib.zip` to a directory and provide that target below:\n",
    "# KITTI_SF15_DATA_ROOT = '/opt/psegs/ext_data/kitti_scene_flow_2015/'\n",
    "\n",
    "\n",
    "\n",
    "# from oarphpy import util as oputil\n",
    "# KITTI_SF15_ALL_FLOW_OCC = [\n",
    "#     os.path.basename(p)\n",
    "#     for p in oputil.all_files_recursive(\n",
    "#         os.path.join(KITTI_SF15_DATA_ROOT, 'training/flow_occ'), pattern='*.png')\n",
    "# ]\n",
    "    \n",
    "# KITTI_SF15_ALL_SCENES = [\n",
    "#     {\n",
    "#         \"input\": 'training/image_2/%s' % fname,\n",
    "#         \"expected_out\": 'training/image_2/%s' % fname.replace('_10', '_11'),\n",
    "#         \"flow_gt\": 'training/flow_occ/%s' % fname,\n",
    "#     }\n",
    "#     for fname in KITTI_SF15_ALL_FLOW_OCC\n",
    "# ]\n",
    "# print(\"Found %s KITTI SceneFlow 2015 scenes\" % len(KITTI_SF15_ALL_SCENES))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cheap_optical_flow_eval_analysis/kittisf15.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile cheap_optical_flow_eval_analysis/kittisf15.py\n",
    "\n",
    "from psegs import datum\n",
    "\n",
    "from cheap_optical_flow_eval_analysis.ofp import *\n",
    "\n",
    "# Please unzip `data_scene_flow.zip` and `data_scene_flow_calib.zip` to a directory and provide that target below:\n",
    "KITTI_SF15_DATA_ROOT = '/opt/psegs/ext_data/kitti_scene_flow_2015/'\n",
    "\n",
    "\n",
    "def kittisf15_load_flow(path):\n",
    "    # Based upon https://github.com/liruoteng/OpticalFlowToolkit/blob/master/lib/flowlib.py#L559\n",
    "    import png\n",
    "    import numpy as np\n",
    "    flow_object = png.Reader(filename=path)\n",
    "    flow_direct = flow_object.asDirect()\n",
    "    flow_data = list(flow_direct[2])\n",
    "    w, h = flow_direct[3]['size']\n",
    "    flow = np.zeros((h, w, 3), dtype=np.float64)\n",
    "    for i in range(len(flow_data)):\n",
    "        flow[i, :, 0] = flow_data[i][0::3]\n",
    "        flow[i, :, 1] = flow_data[i][1::3]\n",
    "        flow[i, :, 2] = flow_data[i][2::3]\n",
    "\n",
    "    invalid_idx = (flow[:, :, 2] == 0)\n",
    "    flow[:, :, 0:2] = (flow[:, :, 0:2] - 2 ** 15) / 64.0\n",
    "    flow[invalid_idx, 0] = 0\n",
    "    flow[invalid_idx, 1] = 0\n",
    "    return flow[:, :, :2]\n",
    "\n",
    "def kittisf15_create_fp(uri):\n",
    "    return OpticalFlowPair(\n",
    "                uri=uri,\n",
    "                dataset=\"KITTI Scene Flow 2015\",\n",
    "                id1=uri.extra['ksf15.input'],\n",
    "                img1='file://' + os.path.join(KITTI_SF15_DATA_ROOT, uri.extra['ksf15.input']),\n",
    "                id2=uri.extra['ksf15.expected_out'],\n",
    "                img2='file://' + os.path.join(KITTI_SF15_DATA_ROOT, uri.extra['ksf15.expected_out']),\n",
    "                flow=kittisf15_load_flow(os.path.join(KITTI_SF15_DATA_ROOT, uri.extra['ksf15.flow_gt'])))\n",
    "\n",
    "\n",
    "class KITTISF15Factory(FlowPairFactoryBase):\n",
    "    DATASET = 'kitti_sf15'\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_all_scenes(cls):\n",
    "        from oarphpy import util as oputil\n",
    "        KITTI_SF15_ALL_FLOW_OCC = [\n",
    "            os.path.basename(p)\n",
    "            for p in oputil.all_files_recursive(\n",
    "                os.path.join(KITTI_SF15_DATA_ROOT, 'training/flow_occ'), pattern='*.png')\n",
    "        ]\n",
    "\n",
    "        KITTI_SF15_ALL_SCENES = [\n",
    "            {\n",
    "                \"ksf15.input\": 'training/image_2/%s' % fname,\n",
    "                \"ksf15.expected_out\": 'training/image_2/%s' % fname.replace('_10', '_11'),\n",
    "                \"ksf15.flow_gt\": 'training/flow_occ/%s' % fname,\n",
    "            }\n",
    "            for fname in KITTI_SF15_ALL_FLOW_OCC\n",
    "        ]\n",
    "        return KITTI_SF15_ALL_SCENES\n",
    "\n",
    "    \n",
    "    @classmethod\n",
    "    def list_fp_uris(cls, spark):\n",
    "        scenes = cls._get_all_scenes()\n",
    "        return [\n",
    "            datum.URI(dataset=cls.DATASET, extra=scene)\n",
    "            for scene in scenes\n",
    "        ]\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_fp_rdd_for_uris(cls, spark, uris):\n",
    "        uri_rdd = spark.sparkContext.parallelize(uris)\n",
    "        fp_rdd = uri_rdd.map(kittisf15_create_fp)\n",
    "        return fp_rdd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-10 00:21:49,354\toarph 1825795 : Source has changed! Rebuilding Egg ...\n",
      "2021-04-10 00:21:49,355\toarph 1825795 : Using source root /tmp/tmpr1cv1xt4_cheap_optical_flow_eval_analysis/cheap_optical_flow_eval_analysis \n",
      "2021-04-10 00:21:49,356\toarph 1825795 : Using source root /tmp/tmpr1cv1xt4_cheap_optical_flow_eval_analysis \n",
      "2021-04-10 00:21:49,357\toarph 1825795 : Generating egg to /tmp/tmp8kif9t5u_oarphpy_eggbuild ...\n",
      "2021-04-10 00:21:49,363\toarph 1825795 : ... done.  Egg at /tmp/tmp8kif9t5u_oarphpy_eggbuild/cheap_optical_flow_eval_analysis-0.0.0-py3.8.egg\n"
     ]
    }
   ],
   "source": [
    "from cheap_optical_flow_eval_analysis.kittisf15 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 Kitti Scene Flow 2015 scenes\n"
     ]
    }
   ],
   "source": [
    "from psegs import datum\n",
    "\n",
    "# You have to ls flow_occ to get the paths\n",
    "KITTI_SF15_DEMO_URIS = [\n",
    "    datum.URI(dataset=KITTISF15Factory.DATASET, extra={\n",
    "        'ksf15.input': 'training/image_2/000000_10.png',\n",
    "        'ksf15.expected_out': 'training/image_2/000000_11.png',\n",
    "        'ksf15.flow_gt': 'training/flow_occ/000000_10.png',\n",
    "    }),\n",
    "    datum.URI(dataset=KITTISF15Factory.DATASET, extra={\n",
    "        'ksf15.input': 'training/image_2/000007_10.png',\n",
    "        'ksf15.expected_out': 'training/image_2/000007_11.png',\n",
    "        'ksf15.flow_gt': 'training/flow_occ/000007_10.png',\n",
    "    }),\n",
    "    datum.URI(dataset=KITTISF15Factory.DATASET, extra={\n",
    "        'ksf15.input': 'training/image_2/000023_10.png',\n",
    "        'ksf15.expected_out': 'training/image_2/000023_11.png',\n",
    "        'ksf15.flow_gt': 'training/flow_occ/000023_10.png',\n",
    "    }),\n",
    "    datum.URI(dataset=KITTISF15Factory.DATASET, extra={\n",
    "        'ksf15.input': 'training/image_2/000051_10.png',\n",
    "        'ksf15.expected_out': 'training/image_2/000051_11.png',\n",
    "        'ksf15.flow_gt': 'training/flow_occ/000051_10.png',\n",
    "    }),\n",
    "    datum.URI(dataset=KITTISF15Factory.DATASET, extra={\n",
    "        'ksf15.input': 'training/image_2/000003_10.png',\n",
    "        'ksf15.expected_out': 'training/image_2/000003_11.png',\n",
    "        'ksf15.flow_gt': 'training/flow_occ/000003_10.png',\n",
    "    }),\n",
    "]\n",
    "\n",
    "ALL_FP_FACTORY_CLSS.append(KITTISF15Factory)\n",
    "\n",
    "print(\"Found %s Kitti Scene Flow 2015 scenes\" % len(KITTISF15Factory.list_fp_uris(spark)))\n",
    "\n",
    "if SHOW_DEMO_OUTPUT:\n",
    "    fp_rdd = KITTISF15Factory.get_fp_rdd_for_uris(spark, KITTI_SF15_DEMO_URIS)\n",
    "    fps = fp_rdd.collect()\n",
    "    \n",
    "    for fp in fps:\n",
    "        show_html(fp.to_html() + \"<br/><br/><br/>\")\n",
    "        DEMO_FPS.append(fp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def kitti_sf15_create_fp(info):\n",
    "#      return OpticalFlowPair(\n",
    "#                 dataset=\"KITTI Scene Flow 2015\",\n",
    "#                 id1=scene['input'],\n",
    "#                 img1='file://' + os.path.join(KITTI_SF15_DATA_ROOT, scene['input']),\n",
    "#                 id2=scene['expected_out'],\n",
    "#                 img2='file://' + os.path.join(KITTI_SF15_DATA_ROOT, scene['expected_out']),\n",
    "#                 flow=KITTISF15LoadFlowFromPng(os.path.join(KITTI_SF15_DATA_ROOT, scene['flow_gt'])))\n",
    "\n",
    "# if SHOW_DEMO_OUTPUT:\n",
    "#     for scene in KITTI_SF15_DEMO_SCENES:\n",
    "#         p = kitti_sf15_create_fp(scene)\n",
    "#         show_html(p.to_html())\n",
    "#         DEMO_FPS.append(p)\n",
    "\n",
    "# if RUN_FULL_ANALYSIS:\n",
    "#     for scene in KITTI_SF15_ALL_SCENES:\n",
    "#         p = kitti_sf15_create_fp(scene)\n",
    "#         ALL_FPS.append(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSegs Synthetic Flow from Fused Lidar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSEGS_SYNTHFLOW_PARQUET_ROOT = '/outer_root/media/rocket4q/psegs_flow_records_short'\n",
    "\n",
    "# from psegs.exp.fused_lidar_flow import FlowRecTable\n",
    "\n",
    "# T = FlowRecTable(spark, PSEGS_SYNTHFLOW_PARQUET_ROOT)\n",
    "# synthflow_record_uris = T.get_record_uris()\n",
    "# print(\"Found %s PSegs SynthFlow records\" % len(synthflow_record_uris))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fr_samp_rdd = T.get_records_with_samples_rdd(\n",
    "#                     record_uris=[PSEGS_SYNTHFLOW_DEMO_RECORD_URIS[0]],\n",
    "#                     include_cameras=False,\n",
    "#                     include_cuboids=False,\n",
    "#                     include_point_clouds=False)\n",
    "# flow_rec = fr_samp_rdd.take(1)[0][0]\n",
    "\n",
    "# print(\"Sample record:\")\n",
    "# show_html(flow_rec.to_html())\n",
    "\n",
    "\n",
    "# PSEGS_SYNTHFLOW_DEMO_FPS_DO_CACHE = True\n",
    "# PSEGS_SYNTHFLOW_DEMO_FPS_CACHE_PATH = '/tmp/psegs_synthflow_demo.pkl'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cheap_optical_flow_eval_analysis/psegs_synthflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile cheap_optical_flow_eval_analysis/psegs_synthflow.py\n",
    "\n",
    "from psegs import datum\n",
    "from psegs.exp.fused_lidar_flow import FlowRecTable\n",
    "\n",
    "from cheap_optical_flow_eval_analysis.ofp import *\n",
    "\n",
    "from oarphpy.spark import CloudpickeledCallable\n",
    "\n",
    "\n",
    "# Please provide the PSegs synthetic flow Parquet directory root below:\n",
    "# PSEGS_SYNTHFLOW_PARQUET_ROOT = '/outer_root/media/rocket4q/psegs_flow_records_short'\n",
    "PSEGS_SYNTHFLOW_PARQUET_ROOT = '/outer_root/media/rocket4q/psegs_synthflow.parquet'\n",
    "\n",
    "def psegs_synthflow_flow_rec_to_fp(flow_rec, sample):\n",
    "  fr = flow_rec\n",
    "\n",
    "  uri_str_to_datum = sample.get_uri_str_to_datum()\n",
    "\n",
    "  # Find the camera_images associated with `flow_rec`\n",
    "  ci1_url_str = str(flow_rec.clouds[0].ci_uris[0])\n",
    "  ci1_sd = uri_str_to_datum[ci1_url_str]\n",
    "  ci1 = ci1_sd.camera_image\n",
    "\n",
    "  ci2_url_str = str(flow_rec.clouds[1].ci_uris[0])\n",
    "  ci2_sd = uri_str_to_datum[ci2_url_str]\n",
    "  ci2 = ci2_sd.camera_image\n",
    "\n",
    "  import numpy as np\n",
    "  world_T1 = ci1.ego_pose.translation\n",
    "  world_T2 = ci2.ego_pose.translation\n",
    "  translation_meters = np.linalg.norm(world_T2 - world_T1)\n",
    "\n",
    "  id1 = ci1_url_str + '&extra.psegs_flow_sids=' + str(fr.clouds[0].sample_id)\n",
    "  id2 = ci2_url_str + '&extra.psegs_flow_sids=' + str(fr.clouds[1].sample_id)\n",
    "\n",
    "  import urllib.parse\n",
    "  eval_uri = datum.URI(dataset=PSegsSynthFlowFactory.DATASET, extra={'pssf.ruri': urllib.parse.quote(str(fr.uri))})\n",
    "\n",
    "  fp = OpticalFlowPair(\n",
    "          uri=eval_uri,\n",
    "          dataset=\"PSegs SynthFlow for %s (%s)\" % (fr.uri.dataset, fr.uri.split),\n",
    "          id1=id1,\n",
    "          id2=id2,\n",
    "          img1=CloudpickeledCallable(lambda: ci1.image),\n",
    "          img2=CloudpickeledCallable(lambda: ci2.image),\n",
    "          flow=CloudpickeledCallable(lambda: fr.to_optical_flow()),\n",
    "\n",
    "          diff_time_sec=abs(ci2_sd.uri.timestamp - ci1_sd.uri.timestamp),\n",
    "          translation_meters=translation_meters)\n",
    "  return fp\n",
    "\n",
    "def psegs_synthflow_create_fps(\n",
    "        spark,\n",
    "        flow_record_pq_table_path,\n",
    "        record_uris,\n",
    "        include_cuboids=False,\n",
    "        include_point_clouds=False):\n",
    "\n",
    "  T = FlowRecTable(spark, flow_record_pq_table_path)\n",
    "  rec_sample_rdd = T.get_records_with_samples_rdd(\n",
    "                          record_uris=record_uris,\n",
    "                          include_cameras=True,\n",
    "                          include_cuboids=include_cuboids,\n",
    "                          include_point_clouds=include_point_clouds)\n",
    "\n",
    "  fps = [\n",
    "    flow_rec_to_fp(flow_rec, sample)\n",
    "    for flow_rec, sample in rec_sample_rdd.collect()\n",
    "  ]\n",
    "\n",
    "  return fps\n",
    "\n",
    "\n",
    "class PSegsSynthFlowFactory(FlowPairFactoryBase):\n",
    "    DATASET = 'psegs_synthflow'\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_frec_table(cls, spark):\n",
    "        if not hasattr(cls, '_frec_table'):\n",
    "            cls._frec_table = FlowRecTable(spark, PSEGS_SYNTHFLOW_PARQUET_ROOT)\n",
    "        return cls._frec_table\n",
    "    \n",
    "    @classmethod\n",
    "    def list_fp_uris(cls, spark):\n",
    "        import urllib.parse\n",
    "        T = cls._get_frec_table(spark)\n",
    "        ruris = T.get_record_uris()\n",
    "        return [\n",
    "            datum.URI(dataset=cls.DATASET, extra={'pssf.ruri': urllib.parse.quote(str(ruri))})\n",
    "            for ruri in ruris\n",
    "        ]\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_fp_rdd_for_uris(cls, spark, uris):\n",
    "        import urllib.parse\n",
    "        T = cls._get_frec_table(spark)\n",
    "        ruris = [urllib.parse.unquote(uri.extra['pssf.ruri']) for uri in uris]\n",
    "        rec_sample_rdd = T.get_records_with_samples_rdd(\n",
    "                          record_uris=ruris,\n",
    "                          include_cameras=True,\n",
    "                          include_cuboids=False,\n",
    "                          include_point_clouds=False)\n",
    "        fp_rdd = rec_sample_rdd.map(lambda fs: psegs_synthflow_flow_rec_to_fp(*fs))\n",
    "        return fp_rdd\n",
    "        \n",
    "\n",
    "\n",
    "# def psegs_synthflow_iter_fp_rdds(\n",
    "#         spark,\n",
    "#         flow_record_pq_table_path,\n",
    "#         fps_per_rdd=100,\n",
    "#         include_cuboids=False,\n",
    "#         include_point_clouds=False):\n",
    "  \n",
    "#   T = FlowRecTable(spark, flow_record_pq_table_path)\n",
    "#   ruris = T.get_record_uris()\n",
    "\n",
    "#   # Ensure a sort so that pairs from similar segments will load in the same\n",
    "#   # RDD -- that makes joins smaller and faster\n",
    "#   ruris = sorted(ruris)\n",
    "\n",
    "#   from oarphpy import util as oputil\n",
    "#   for ruri_chunk in oputil.ichunked(ruris, fps_per_rdd):\n",
    "#     frec_sample_rdd = T.get_records_with_samples_rdd(\n",
    "#                           record_uris=rids,\n",
    "#                           include_cuboids=include_cuboids,\n",
    "#                           include_point_clouds=include_point_clouds)\n",
    "#     fp_rdd = frec_sample_rdd.map(flow_rec_to_fp)\n",
    "#     yield fp_rdd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-10 00:21:54,981\toarph 1825795 : Source has changed! Rebuilding Egg ...\n",
      "2021-04-10 00:21:54,982\toarph 1825795 : Using source root /tmp/tmpr1cv1xt4_cheap_optical_flow_eval_analysis/cheap_optical_flow_eval_analysis \n",
      "2021-04-10 00:21:54,982\toarph 1825795 : Using source root /tmp/tmpr1cv1xt4_cheap_optical_flow_eval_analysis \n",
      "2021-04-10 00:21:54,984\toarph 1825795 : Generating egg to /tmp/tmppqa5s4d8_oarphpy_eggbuild ...\n",
      "2021-04-10 00:21:54,990\toarph 1825795 : ... done.  Egg at /tmp/tmppqa5s4d8_oarphpy_eggbuild/cheap_optical_flow_eval_analysis-0.0.0-py3.8.egg\n"
     ]
    }
   ],
   "source": [
    "from cheap_optical_flow_eval_analysis.psegs_synthflow import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 191 PSegs SynthFlow scenes\n"
     ]
    }
   ],
   "source": [
    "from psegs import datum\n",
    "\n",
    "import urllib.parse\n",
    "\n",
    "PSEGS_SYNTHFLOW_DEMO_RECORD_RURIS = (\n",
    "  'psegs://dataset=kitti-360&split=train&segment_id=2013_05_28_drive_0000_sync&extra.psegs_flow_sids=4340,4339',\n",
    "  'psegs://dataset=kitti-360&split=train&segment_id=2013_05_28_drive_0000_sync&extra.psegs_flow_sids=11219,11269',\n",
    "\n",
    "  'psegs://dataset=nuscenes&split=train_track&segment_id=scene-0501&extra.psegs_flow_sids=40009,40010',\n",
    "  'psegs://dataset=nuscenes&split=train_track&segment_id=scene-0501&extra.psegs_flow_sids=50013,50014',\n",
    "\n",
    "#   'psegs://dataset=kitti-360-fused&split=train&segment_id=2013_05_28_drive_0000_sync&extra.psegs_flow_sids=11103,11104',\n",
    "#   'psegs://dataset=kitti-360-fused&split=train&segment_id=2013_05_28_drive_0000_sync&extra.psegs_flow_sids=1181,1182',\n",
    "\n",
    "#   'psegs://dataset=nuscenes&split=train_detect&segment_id=scene-0002&extra.psegs_flow_sids=10016,10017',\n",
    "#   'psegs://dataset=nuscenes&split=train_detect&segment_id=scene-0582&extra.psegs_flow_sids=60035,60036',\n",
    "\n",
    "#   'psegs://dataset=nuscenes&split=train_track&segment_id=scene-0393&extra.psegs_flow_sids=50017,50018',\n",
    "#   'psegs://dataset=nuscenes&split=train_track&segment_id=scene-0501&extra.psegs_flow_sids=40019,40020',\n",
    ")\n",
    "\n",
    "PSEGS_SYNTHFLOW_DEMO_URIS = [\n",
    "    datum.URI(dataset=PSegsSynthFlowFactory.DATASET, extra={\n",
    "        'pssf.ruri': urllib.parse.quote(ruri_str)\n",
    "    })\n",
    "    for ruri_str in PSEGS_SYNTHFLOW_DEMO_RECORD_RURIS\n",
    "]\n",
    "\n",
    "ALL_FP_FACTORY_CLSS.append(PSegsSynthFlowFactory)\n",
    "\n",
    "print(\"Found %s PSegs SynthFlow scenes\" % len(PSegsSynthFlowFactory.list_fp_uris(spark)))\n",
    "\n",
    "if SHOW_DEMO_OUTPUT:\n",
    "    if os.path.exists(PSEGS_SYNTHFLOW_DEMO_FPS_CACHE_PATH):\n",
    "        print(\"Loading demo FlowPairs from %s\" % PSEGS_SYNTHFLOW_DEMO_FPS_CACHE_PATH)\n",
    "        import pickle\n",
    "        fps = pickle.load(open(PSEGS_SYNTHFLOW_DEMO_FPS_CACHE_PATH, 'rb'))\n",
    "    else:\n",
    "        print(\"Building Demo FlowPairs, this might take a while ....\")\n",
    "        fp_rdd = PSegsSynthFlowFactory.get_fp_rdd_for_uris(spark, PSEGS_SYNTHFLOW_DEMO_URIS)\n",
    "        fps = fp_rdd.collect()\n",
    "        if PSEGS_SYNTHFLOW_DEMO_FPS_DO_CACHE:\n",
    "            print(\"Saving demo FlowPairs to %s ...\" % PSEGS_SYNTHFLOW_DEMO_FPS_CACHE_PATH)\n",
    "            import pickle\n",
    "            with open(PSEGS_SYNTHFLOW_DEMO_FPS_CACHE_PATH, 'wb') as f:\n",
    "                pickle.dump(fps, f, protocol=4)\n",
    "    \n",
    "    for fp in fps:\n",
    "        show_html(fp.to_html())\n",
    "        DEMO_FPS.append(fp)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     import urllib.parse\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     for fp in fps:\n",
    "#         show_html(fp.to_html() + \"<br/><br/><br/>\")\n",
    "#         DEMO_FPS.append(fp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if SHOW_DEMO_OUTPUT:\n",
    "#     if os.path.exists(PSEGS_SYNTHFLOW_DEMO_FPS_CACHE_PATH):\n",
    "#         print(\"Loading demo FlowPairs from %s\" % PSEGS_SYNTHFLOW_DEMO_FPS_CACHE_PATH)\n",
    "#         import pickle\n",
    "#         fps = pickle.load(open(PSEGS_SYNTHFLOW_DEMO_FPS_CACHE_PATH, 'rb'))\n",
    "#     else:\n",
    "#         print(\"Building Demo FlowPairs, this might take a while ....\")\n",
    "#         fps = psegs_synthflow_create_fps(spark, PSEGS_SYNTHFLOW_PARQUET_ROOT, PSEGS_SYNTHFLOW_DEMO_RECORD_URIS)\n",
    "#         if PSEGS_SYNTHFLOW_DEMO_FPS_DO_CACHE:\n",
    "#             print(\"Saving demo FlowPairs to %s ...\" % PSEGS_SYNTHFLOW_DEMO_FPS_CACHE_PATH)\n",
    "#             import pickle\n",
    "#             with open(PSEGS_SYNTHFLOW_DEMO_FPS_CACHE_PATH, 'wb') as f:\n",
    "#                 pickle.dump(fps, f, protocol=4)\n",
    "    \n",
    "#     for fp in fps:\n",
    "#         show_html(fp.to_html())\n",
    "#         DEMO_FPS.append(fp)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction via Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Reconstruction via Optical Flow\n",
    "\n",
    "def zero_flow(flow):\n",
    "    return (flow[:, :, :2] == np.array([0, 0])).all(axis=-1)\n",
    "\n",
    "def warp_flow_backwards(img, flow):\n",
    "    \"\"\"Given an image, apply the inverse of `flow`\"\"\"\n",
    "    h, w = flow.shape[:2]\n",
    "    flow = -flow\n",
    "    flow[:,:,0] += np.arange(w)\n",
    "    flow[:,:,1] += np.arange(h)[:,np.newaxis]\n",
    "    res = cv2.remap(img, flow.astype(np.float32), None, cv2.INTER_LINEAR)\n",
    "    return res\n",
    "    \n",
    "def warp_flow_forwards(img, flow):\n",
    "    \"\"\"Given an image, apply the given optical flow `flow`.  Returns not only the warped\n",
    "    image, but a `mask` indicating warped pixels (i.e. there was non-zero flow *into* these pixels ).\n",
    "    With some help from https://stackoverflow.com/questions/41703210/inverting-a-real-valued-index-grid/46009462#46009462\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    pts = flow.copy()\n",
    "    pts[:, :, 0] += np.arange(w)\n",
    "    pts[:, :, 1] += np.arange(h)[:, np.newaxis]\n",
    "    exclude = zero_flow(flow)\n",
    "    if exclude.all():\n",
    "        # No flow anywhere!\n",
    "        return img.copy(), np.zeros((h, w)).astype(np.bool)\n",
    "    else:\n",
    "        inpts = pts[~exclude]\n",
    "    \n",
    "    from scipy.interpolate import griddata\n",
    "    inpts = np.reshape(inpts, [-1, 2])\n",
    "    grid_y, grid_x = np.mgrid[:h, :w]\n",
    "    chan_out = []\n",
    "    for ch in range(img.shape[-1]):\n",
    "        spts = img[:, :, ch][~exclude].reshape([-1, 1])\n",
    "        mapped = griddata(inpts, spts, (grid_x, grid_y), method='linear')\n",
    "        chan_out.append(mapped.astype(img.dtype))\n",
    "    out = np.stack(chan_out, axis=-1)\n",
    "    out = out.reshape([h, w, len(chan_out)])\n",
    "\n",
    "    mask = np.reshape(inpts, [-1, 2])\n",
    "    mask = np.rint(mask).astype(np.int)\n",
    "    mask = mask[np.where((mask[:, 0] >= 0) & (mask[:, 0] < w) & (mask[:, 1] >= 0) & (mask[:, 1] < h))]\n",
    "    valid_mask = np.zeros((h, w))\n",
    "    valid_mask[mask[:, 1], mask[:, 0]] = 1\n",
    "    \n",
    "    return out, valid_mask.astype(np.bool)\n",
    "\n",
    "# @attr.s(slots=True, eq=False, weakref_slot=False)\n",
    "class FlowReconstructedImagePair(object):\n",
    "    \"\"\"A pair of reconstructed images using an input pair of images and optical\n",
    "    flow field (i.e. an `OpticalFlowPair` instance).\"\"\"\n",
    "\n",
    "    slots = (\n",
    "        'opair',\n",
    "        'img2_recon_fwd',\n",
    "        'img2_recon_fwd_valid',\n",
    "        'img1_recon_bkd',\n",
    "        'img1_recon_bkd_valid'\n",
    "    )\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        for k in self.slots:\n",
    "            setattr(self, k, kwargs.get(k))\n",
    "    \n",
    "#     opair = attr.ib(default=OpticalFlowPair())\n",
    "#     \"\"\"The original `OpticalFlowPair` with the source of the data for this reconstruction result.\"\"\"\n",
    "    \n",
    "#     img2_recon_fwd = attr.ib(default=np.array([]))\n",
    "#     \"\"\"A Numpy image containing the result of FORWARDS-WARPING OpticalFlowPair::img1\n",
    "#     via OpticalFlowPair::flow to reconstruct OpticalFlowPair::img2\"\"\"\n",
    "\n",
    "#     img2_recon_fwd_valid = attr.ib(default=np.array([]))\n",
    "#     \"\"\"A Numpy boolean mask indicating which pixels of `img2_recon_fwd` were modified via non-zero flow\"\"\"\n",
    "    \n",
    "#     img1_recon_bkd = attr.ib(default=np.array([]))\n",
    "#     \"\"\"A Numpy image containing the result of BACKWARDS-WARPING OpticalFlowPair::img2\n",
    "#     via OpticalFlowPair::flow to reconstruct OpticalFlowPair::img1\"\"\"\n",
    "\n",
    "#     img1_recon_bkd_valid = attr.ib(default=np.array([]))\n",
    "#     \"\"\"A Numpy boolean mask indicating which pixels of `img1_recon_bkd` were modified via non-zero flow\"\"\"\n",
    "        \n",
    "    @classmethod\n",
    "    def create_from(cls, oflow_pair: OpticalFlowPair):\n",
    "        flow = oflow_pair.get_flow()\n",
    "        \n",
    "        # Forward Warp\n",
    "        fwarped, fvalid = warp_flow_forwards(oflow_pair.get_img1(), flow)\n",
    "\n",
    "        # Backwards Warp\n",
    "        exclude = zero_flow(flow)\n",
    "        bwarped = warp_flow_backwards(oflow_pair.get_img2(), -flow[:, :, :2])\n",
    "        bvalid = ~exclude\n",
    "        \n",
    "        return FlowReconstructedImagePair(\n",
    "                opair=oflow_pair,\n",
    "                img2_recon_fwd=fwarped,\n",
    "                img2_recon_fwd_valid=fvalid,\n",
    "                img1_recon_bkd=bwarped,\n",
    "                img1_recon_bkd_valid=bvalid)\n",
    "    \n",
    "    def to_html(self):\n",
    "        # We use pixels from the destination image in order to make the reconstruction \n",
    "        # easier to interpret; we'll fade them in intensity so that they are more\n",
    "        # conspicuous.        \n",
    "        FADE_UNTOUCHED_PIXELS = 0.3\n",
    "        \n",
    "        viz_fwd = self.img2_recon_fwd.copy().astype(np.float32)\n",
    "        im2 = self.opair.get_img2()\n",
    "        if (~self.img2_recon_fwd_valid).any():\n",
    "            viz_fwd[~self.img2_recon_fwd_valid] = im2[~self.img2_recon_fwd_valid]\n",
    "            viz_fwd[~self.img2_recon_fwd_valid] *= FADE_UNTOUCHED_PIXELS\n",
    "        else:\n",
    "            # viz_fwd = im2.copy() * FADE_UNTOUCHED_PIXELS\n",
    "            print('no invalids forward!')\n",
    "        \n",
    "        viz_bkd = self.img1_recon_bkd.copy().astype(np.float32)\n",
    "        im1 = self.opair.get_img1()\n",
    "        if (~self.img1_recon_bkd_valid).any():\n",
    "            viz_bkd[~self.img1_recon_bkd_valid] = im1[~self.img1_recon_bkd_valid]\n",
    "            viz_bkd[~self.img1_recon_bkd_valid] *= FADE_UNTOUCHED_PIXELS\n",
    "        else:\n",
    "            # viz_bkd = im1.copy() * FADE_UNTOUCHED_PIXELS\n",
    "            print('no invalids backwards!')\n",
    "        \n",
    "        html = \"\"\"\n",
    "            <table>\n",
    "            \n",
    "            <tr><td style=\"text-align:left\"><b>Forwards Warped <i>(dark pixels unwarped)</i></b></td></tr>\n",
    "            <tr><td><img src=\"{viz_fwd}\" width=\"100%\" /></td></tr>\n",
    "\n",
    "            <tr><td style=\"text-align:left\"><b>Backwards Warped <i>(dark pixels unwarped)</i></b></td></tr>\n",
    "            <tr><td><img src=\"{viz_bkd}\" width=\"100%\" /></td></tr>\n",
    "\n",
    "            </table>\n",
    "        \"\"\".format(\n",
    "                viz_fwd=img_to_data_uri(viz_fwd.astype(np.uint8)),\n",
    "                viz_bkd=img_to_data_uri(viz_bkd.astype(np.uint8)))\n",
    "        return html\n",
    "\n",
    "        \n",
    "if SHOW_DEMO_OUTPUT:\n",
    "    DEMO_RECONS = []\n",
    "    for p in DEMO_FPS:\n",
    "        recon = FlowReconstructedImagePair.create_from(p)\n",
    "        show_html(recon.to_html() + \"</br></br></br>\")\n",
    "        DEMO_RECONS.append(recon)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Analysis Utils\n",
    "\n",
    "def mse(i1, i2, valid):\n",
    "    return np.mean((i1[valid] - i2[valid]) ** 2)\n",
    "\n",
    "def rmse(i1, i2, valid):\n",
    "    return math.sqrt(mse(i1, i2, valid))\n",
    "\n",
    "def psnr(i1, i2, valid):\n",
    "    return 20 * math.log10(255) - 10 * math.log10(max((mse(i1, i2, valid), 1e-12)))\n",
    "\n",
    "def ssim(i1, i2, valid):\n",
    "    # Some variance out there ...\n",
    "    # https://github.com/scikit-image/scikit-image/blob/master/skimage/metrics/_structural_similarity.py#L12-L232\n",
    "    # https://github.com/nianticlabs/monodepth2/blob/13200ab2f29f2f10dec3aa5db29c32a23e29d376/layers.py#L218\n",
    "    # https://cvnote.ddlee.cn/2019/09/12/psnr-ssim-python\n",
    "    # We will just use SKImage for now ...\n",
    "    from skimage.metrics import structural_similarity as ssim\n",
    "    mssim, S = ssim(i1, i2, win_size=11, multichannel=True, full=True)\n",
    "    return np.mean(S[valid])\n",
    "\n",
    "def to_edge_im(img):\n",
    "    return np.stack([\n",
    "        cv2.Laplacian(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY), cv2.CV_32F, ksize=1),\n",
    "        cv2.Sobel(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY), cv2.CV_32F, 1, 0, ksize=3),\n",
    "        cv2.Sobel(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY), cv2.CV_32F, 0, 1, ksize=3),\n",
    "    ], axis=-1)\n",
    "\n",
    "def edges_mse(i1, i2, valid):\n",
    "    return mse(to_edge_im(i1), to_edge_im(i2), valid)\n",
    "\n",
    "\n",
    "def oflow_coverage(valid):\n",
    "    return valid.sum() / (valid.shape[0] * valid.shape[1])\n",
    "\n",
    "def oflow_magnitude_hist(flow, valid, bins=50):\n",
    "    flow_l2s = np.sqrt( flow[valid][:, 0] ** 2 + flow[valid][:, 1] ** 2 )\n",
    "    bin_counts, bin_edges = np.histogram(flow_l2s, bins=bins)\n",
    "    return bin_edges, bin_counts\n",
    "\n",
    "\n",
    "# Analysis Data Model\n",
    "\n",
    "class OFlowReconErrors(object):\n",
    "    \"\"\"Various measures of reconstruction error for a `FlowReconstructedImagePair` instance.\n",
    "    Encapsulated as two dictionaries of stats for easy interop with Spark SQL.\"\"\"\n",
    "\n",
    "    RECONSTRUCTION_ERR_METRICS = {\n",
    "        'SSIM': ssim,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'PSNR': psnr,\n",
    "        'Edges_MSE': edges_mse,\n",
    "    }\n",
    "    \n",
    "    def __init__(self, recon_pair: FlowReconstructedImagePair):\n",
    "        im2 = recon_pair.opair.get_img2()\n",
    "        img2_recon_fwd = recon_pair.img2_recon_fwd\n",
    "        img2_recon_fwd_valid = recon_pair.img2_recon_fwd_valid\n",
    "        self.forward_stats = dict(\n",
    "            (name, func(im2, img2_recon_fwd, img2_recon_fwd_valid))\n",
    "            for name, func in self.RECONSTRUCTION_ERR_METRICS.items())\n",
    "        \n",
    "        im1 = recon_pair.opair.get_img1()\n",
    "        img1_recon_fwd = recon_pair.img1_recon_bkd\n",
    "        img1_recon_fwd_valid = recon_pair.img1_recon_bkd_valid\n",
    "        self.backward_stats = dict(\n",
    "            (name, func(im1, img1_recon_fwd, img1_recon_fwd_valid))\n",
    "            for name, func in self.RECONSTRUCTION_ERR_METRICS.items())\n",
    "\n",
    "    def to_html(self):\n",
    "        stat_names = self.RECONSTRUCTION_ERR_METRICS.keys()\n",
    "\n",
    "        rows = [\n",
    "            \"\"\"\n",
    "            <tr>\n",
    "              <td style=\"text-align:left\"><b>{name}</b></td>\n",
    "              <td style=\"text-align:left\">{fwd:.2f}</td>\n",
    "              <td style=\"text-align:left\">{bkd:.2f}</td>\n",
    "            </tr>\n",
    "            \"\"\".format(name=name, fwd=self.forward_stats[name], bkd=self.backward_stats[name])\n",
    "            for name in stat_names\n",
    "        ]\n",
    "        \n",
    "        \n",
    "        html = \"\"\"\n",
    "            <table>\n",
    "              <tr>\n",
    "                  <th></th> <th><b>Forwards Warp</b></th> <th><b>Backwards Warp</b></th>\n",
    "              </tr>\n",
    "\n",
    "              {table_rows}\n",
    "\n",
    "            </table>\n",
    "        \"\"\".format(table_rows=\"\".join(rows))\n",
    "        \n",
    "        return html\n",
    "            \n",
    "# @attr.s(slots=True, eq=False, weakref_slot=False)\n",
    "class OFlowStats(object):\n",
    "    \"\"\"Stats on the optical flow of a `OpticalFlowPair` instance\"\"\"\n",
    "\n",
    "    slots = (\n",
    "        'opair',\n",
    "        'coverage',\n",
    "        'magnitude_hist',\n",
    "    )\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        for k in self.slots:\n",
    "            setattr(self, k, kwargs.get(k))\n",
    "    \n",
    "#     opair = attr.ib(default=OpticalFlowPair())\n",
    "#     \"\"\"The original `OpticalFlowPair` with the source of the data for this reconstruction result.\"\"\"\n",
    "    \n",
    "#     coverage = attr.ib(default=0)\n",
    "#     \"\"\"Fraction of the image with valid flow\"\"\"\n",
    "    \n",
    "#     magnitude_hist = attr.ib(default=[np.array([]), np.array([])])\n",
    "#     \"\"\"Histogram [bin edges, bin counts] of flow magnitudes\"\"\"\n",
    "    \n",
    "    @classmethod\n",
    "    def create_from(cls, oflow_pair: OpticalFlowPair):\n",
    "        flow = oflow_pair.get_flow()\n",
    "        valid = ~zero_flow(flow)\n",
    "        return OFlowStats(\n",
    "                 opair=oflow_pair,\n",
    "                 coverage=oflow_coverage(valid),\n",
    "                 magnitude_hist=oflow_magnitude_hist(flow, valid))\n",
    "                 \n",
    "    def to_html(self):\n",
    "        import matplotlib.pyplot as plt\n",
    "        fig = plt.figure()\n",
    "        bin_edges, bin_counts = self.magnitude_hist\n",
    "        plt.bar(bin_edges[:-1], bin_counts)\n",
    "        plt.title(\"Histogram of Flow Magnitudes\")\n",
    "        plt.xlabel('Flow Magnitude (pixels)')\n",
    "        plt.ylabel('Count')\n",
    "\n",
    "        hist_img = matplotlib_fig_to_img(fig)\n",
    "        \n",
    "        html = \"\"\"\n",
    "            <table>           \n",
    "            <tr><td style=\"text-align:left\"><b>Flow Coverage:</b> {coverage:.2f}% </td></tr>\n",
    "            <tr><td><img src=\"{flow_hist}\" width=\"100%\" /></td></tr>\n",
    "            </table>\n",
    "        \"\"\".format(\n",
    "                coverage=100. * self.coverage,\n",
    "                flow_hist=img_to_data_uri(matplotlib_fig_to_img(hist_img)))\n",
    "        return html\n",
    "\n",
    "\n",
    "# Misc\n",
    "\n",
    "def matplotlib_fig_to_img(fig):\n",
    "    import io\n",
    "    import matplotlib.pyplot as plt\n",
    "    from PIL import Image\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    im = Image.open(buf)\n",
    "    im.show()\n",
    "    buf.seek(0)\n",
    "\n",
    "    import imageio\n",
    "    hist_img = imageio.imread(buf)\n",
    "    buf.close()\n",
    "    return hist_img\n",
    "\n",
    "\n",
    "if SHOW_DEMO_OUTPUT:\n",
    "    %matplotlib agg\n",
    "    for recon in DEMO_RECONS:\n",
    "        p = recon.opair\n",
    "        errors = OFlowReconErrors(recon)\n",
    "        err_html = errors.to_html()  \n",
    "            \n",
    "        fstats = OFlowStats.create_from(p)\n",
    "        stats_html = fstats.to_html()\n",
    "            \n",
    "        title = \"<b>{dataset} {id1} -> {id2}</b>\".format(dataset=p.dataset, id1=p.id1, id2=p.id2)\n",
    "        \n",
    "        show_html(title + stats_html + err_html + \"</br></br></br>\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis on Full Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analysis_uris_full 4934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-10 00:25:20,418\toarph 1825795 : Progress for \n",
      "run_analysis [Pid:1825795 Id:140039269114928]\n",
      "-----------------------  ----------------------------\n",
      "Thruput\n",
      "N thru                   100 (of 4934)\n",
      "N chunks                 1\n",
      "Total time               40.85 seconds\n",
      "Total thru               0 bytes\n",
      "Rate                     0.0 bytes / sec\n",
      "Hz                       2\n",
      "Progress\n",
      "Percent Complete         2.026753\n",
      "Est. Time To Completion  32 minutes and 54.64 seconds\n",
      "-----------------------  ----------------------------\n",
      "2021-04-10 00:25:50,569\toarph 1825795 : Progress for \n",
      "run_analysis [Pid:1825795 Id:140039269114928]\n",
      "-----------------------  ---------------------------------------------------------------------\n",
      "Thruput\n",
      "N thru                   200 (of 4934)\n",
      "N chunks                 2\n",
      "Total time               1 minute and 10.99 seconds\n",
      "Total thru               0 bytes\n",
      "Rate                     0.0 bytes / sec\n",
      "Hz                       3\n",
      "Progress\n",
      "Percent Complete         4.053506\n",
      "Est. Time To Completion  28 minutes and 0.35 seconds\n",
      "Latency (per chunk)\n",
      "Avg                      35 seconds, 495 milliseconds, 386 microseconds and 719.7 nanoseconds\n",
      "p50                      35 seconds, 495 milliseconds, 386 microseconds and 719.7 nanoseconds\n",
      "p95                      40 seconds, 313 milliseconds, 718 microseconds and 473.91 nanoseconds\n",
      "p99                      40 seconds, 742 milliseconds, 14 microseconds and 629.84 nanoseconds\n",
      "-----------------------  ---------------------------------------------------------------------\n",
      "2021-04-10 00:26:16,215\toarph 1825795 : Progress for \n",
      "run_analysis [Pid:1825795 Id:140039269114928]\n",
      "-----------------------  ---------------------------------------------------------------------\n",
      "Thruput\n",
      "N thru                   300 (of 4934)\n",
      "N chunks                 3\n",
      "Total time               1 minute and 36.63 seconds\n",
      "Total thru               0 bytes\n",
      "Rate                     0.0 bytes / sec\n",
      "Hz                       3\n",
      "Progress\n",
      "Percent Complete         6.080259\n",
      "Est. Time To Completion  24 minutes and 52.63 seconds\n",
      "Latency (per chunk)\n",
      "Avg                      32 seconds, 210 milliseconds, 414 microseconds and 12.27 nanoseconds\n",
      "p50                      30 seconds, 141 milliseconds, 684 microseconds and 770.58 nanoseconds\n",
      "p95                      39 seconds, 778 milliseconds, 348 microseconds and 279 nanoseconds\n",
      "p99                      40 seconds, 634 milliseconds, 940 microseconds and 590.86 nanoseconds\n",
      "-----------------------  ---------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-fd5df83f6bda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mresult_rdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp_rdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow_pair_to_full_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_rdd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     df.write.save(\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'append'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/outer_root/media/rocket4q/oflow_pq_eval_test.parquet'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyspark-3.0.1-py3.8.egg/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m    825\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/py4j-0.10.9-py3.8.egg/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/py4j-0.10.9-py3.8.egg/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/py4j-0.10.9-py3.8.egg/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# sys.path.append('/opt/psegs')\n",
    "\n",
    "# from oarphpy.spark import NBSpark\n",
    "# NBSpark.SRC_ROOT = os.path.join(ALIB_SRC_DIR, 'cheap_optical_flow_eval_analysis')\n",
    "# NBSpark.CONF_KV.update({\n",
    "#     'spark.driver.maxResultSize': '2g',\n",
    "#     'spark.driver.memory': '16g',\n",
    "#   })\n",
    "# spark = NBSpark.getOrCreate()\n",
    "\n",
    "\n",
    "from oarphpy.spark import RowAdapter\n",
    "\n",
    "from pyspark import Row\n",
    "\n",
    "\n",
    "def flow_pair_to_full_row(fp):\n",
    "    from threadpoolctl import threadpool_limits\n",
    "    with threadpool_limits(limits=1, user_api='blas'):\n",
    "        recon = FlowReconstructedImagePair.create_from(fp)\n",
    "        fstats = OFlowStats.create_from(fp)\n",
    "        errors = OFlowReconErrors(recon)\n",
    "\n",
    "        rowdata = dict(\n",
    "                fp_uri=str(fp.uri),\n",
    "                flow_coverage=fstats.coverage,\n",
    "        )\n",
    "        rowdata.update(\n",
    "            ('Forwards_' + k, float(v))\n",
    "            for k, v in errors.forward_stats.items())\n",
    "        rowdata.update(\n",
    "            ('Backwards_' + k, float(v))\n",
    "            for k, v in errors.backward_stats.items())\n",
    "        return RowAdapter.to_row(rowdata)\n",
    "\n",
    "\n",
    "analysis_uris_demo = MiddFactory.list_fp_uris(spark) + PSEGS_SYNTHFLOW_DEMO_URIS + KITTI_SF15_DEMO_URIS + DD_DEMO_URIS\n",
    "\n",
    "\n",
    "class UnionFactory(FlowPairUnionFactory):\n",
    "    FACTORIES = ALL_FP_FACTORY_CLSS\n",
    "\n",
    "analysis_uris_full = UnionFactory.list_fp_uris(spark)\n",
    "print('analysis_uris_full', len(analysis_uris_full))\n",
    "\n",
    "from oarphpy import util as oputil\n",
    "thru = oputil.ThruputObserver(name='run_analysis', n_total=len(analysis_uris_full))\n",
    "for uri_chunk in oputil.ichunked(analysis_uris_full, 100):\n",
    "    thru.start_block()\n",
    "    fp_rdd = UnionFactory.get_fp_rdd_for_uris(spark, uri_chunk)\n",
    "    result_rdd = fp_rdd.map(flow_pair_to_full_row)\n",
    "    df = spark.createDataFrame(result_rdd)\n",
    "    df.write.save(\n",
    "            mode='append',\n",
    "            path='/outer_root/media/rocket4q/oflow_pq_eval_test.parquet',\n",
    "            format='parquet',\n",
    "            compression='lz4')\n",
    "    thru.stop_block(n=len(uri_chunk))\n",
    "    thru.maybe_log_progress(every_n=1)\n",
    "\n",
    "\n",
    "# if True:#RUN_FULL_ANALYSIS:\n",
    "# #     spark = Spark.getOrCreate()\n",
    "    \n",
    "# #     for p in ALL_FPS:\n",
    "# #         import cloudpickle\n",
    "# #         try:\n",
    "# #             cloudpickle.dumps(p)\n",
    "# #         except Exception:\n",
    "# #             assert False, p\n",
    "# #     print('all good')\n",
    "    \n",
    "#     import pickle\n",
    "#     fp_rdd = spark.sparkContext.parallelize(ALL_FPS, numSlices=200)\n",
    "# #     print(fp_rdd.count())\n",
    "#     df = spark.createDataFrame(fp_rdd.map(flow_pair_to_full_row)).persist()\n",
    "\n",
    "#     print(df.count())\n",
    "#     df.show(10)\n",
    "#     df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oarphpy import plotting as pl\n",
    "class Plotter(pl.HistogramWithExamplesPlotter):\n",
    "    NUM_BINS = 10\n",
    "    ROWS_TO_DISPLAY_PER_BUCKET = 3\n",
    "    SUB_PIVOT_COL = 'fp.dataset'\n",
    "\n",
    "    def display_bucket(self, sub_pivot, bucket_id, irows):\n",
    "        import itertools\n",
    "        from oarphpy.spark import RowAdapter\n",
    "        \n",
    "        row_htmls = []\n",
    "        for row in itertools.islice(irows, self.ROWS_TO_DISPLAY_PER_BUCKET):\n",
    "            rowdata = RowAdapter.from_row(row)\n",
    "            \n",
    "            fp = rowdata['fp']\n",
    "            recon = FlowReconstructedImagePair.create_from(fp)\n",
    "            fstats = OFlowStats.create_from(fp)\n",
    "            errors = OFlowReconErrors(recon)\n",
    "            \n",
    "            row_html = \"<br/>\".join((fp.to_html(), recon.to_html(), fstats.to_html(), errors.to_html()))\n",
    "            row_htmls.append(row_html)\n",
    "        \n",
    "        HTML = \"\"\"\n",
    "        <b>Pivot: {spv} Bucket: {bucket_id} </b> <br/>\n",
    "        \n",
    "        {row_bodies}\n",
    "        \"\"\".format(\n",
    "              spv=sub_pivot,\n",
    "              bucket_id=bucket_id,\n",
    "              row_bodies=\"<br/><br/><br/>\".join(row_htmls))\n",
    "        \n",
    "        return bucket_id, HTML\n",
    "\n",
    "plotter = Plotter()\n",
    "\n",
    "for col in df.columns:\n",
    "    col = str(col)\n",
    "    if col == 'fp':\n",
    "        continue\n",
    "    \n",
    "    fig = plotter.run(df, col)\n",
    "    pl.save_bokeh_fig(fig, '/tmp/%s.html' % col)\n",
    "\n",
    "# from bokeh.io import output_notebook\n",
    "# output_notebook()\n",
    "# from bokeh.plotting import show\n",
    "# show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
