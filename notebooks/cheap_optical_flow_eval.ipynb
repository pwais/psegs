{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cheap Optical Flow: Is It Good?\n",
    "\n",
    "\n",
    "## Quickstart\n",
    "\n",
    "## Credits\n",
    "\n",
    "Some portions of this notebook adapted from:\n",
    " * [Middlebury Flow code by Johannes Oswald](https://github.com/Johswald/flow-code-python/blob/master/readFlowFile.py)\n",
    " * [DeepDeform Demo Code](https://github.com/AljazBozic/DeepDeform)\n",
    " * [OpticalFlowToolkit by RUOTENG LI](https://github.com/liruoteng/OpticalFlowToolkit)\n",
    " * [OpenCV Samples](https://github.com/opencv/opencv/blob/master/samples/python/opt_flow.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "SHOW_DEMO_OUTPUT = False\n",
    "DEMO_FPS = []\n",
    "\n",
    "RUN_FULL_ANALYSIS = True\n",
    "ALL_FPS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypng in /usr/local/lib/python3.6/dist-packages (0.0.20)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (0.17.2)\n",
      "Requirement already satisfied: numpy>=1.15.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.18.1)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (7.0.0)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.5)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (3.1.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2020.9.3)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.4.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image) (4.4.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (46.0.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.14.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "Putting analysis lib in /tmp/tmptk_89y2q_cheap_optical_flow_eval_analysis\n"
     ]
    }
   ],
   "source": [
    "## Setup\n",
    "\n",
    "!pip3 install pypng scikit-image\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "import copy\n",
    "import imageio\n",
    "import IPython.display\n",
    "import math\n",
    "import os\n",
    "import PIL.Image\n",
    "import six\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "\n",
    "## General Notebook Utilities\n",
    "    \n",
    "def imshow(x):\n",
    "    IPython.display.display(PIL.Image.fromarray(x))\n",
    "\n",
    "def show_html(x):\n",
    "    from IPython.core.display import display, HTML\n",
    "    display(HTML(x))\n",
    "\n",
    "\n",
    "## Create a random temporary directory for analysis library (for Spark-enabled full analysis mode)\n",
    "old_cwd = os.getcwd()\n",
    "tempdir = tempfile.TemporaryDirectory(suffix='_cheap_optical_flow_eval_analysis')\n",
    "ALIB_SRC_DIR = tempdir.name\n",
    "print(\"Putting analysis lib in %s\" % ALIB_SRC_DIR)\n",
    "os.chdir(ALIB_SRC_DIR)\n",
    "!mkdir -p cheap_optical_flow_eval_analysis\n",
    "!touch cheap_optical_flow_eval_analysis/__init__.py\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append(ALIB_SRC_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cheap_optical_flow_eval_analysis/ofp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile cheap_optical_flow_eval_analysis/ofp.py\n",
    "\n",
    "## Data Model & Utility Code\n",
    "\n",
    "import attr\n",
    "import cv2\n",
    "import imageio\n",
    "import math\n",
    "import os\n",
    "import PIL.Image\n",
    "import six\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from oarphpy import plotting as op_plt\n",
    "img_to_data_uri = lambda x: op_plt.img_to_data_uri(x, format='png')\n",
    "\n",
    "@attr.s(slots=True, eq=False, weakref_slot=False)\n",
    "class OpticalFlowPair(object):\n",
    "    \"\"\"A flyweight for a pair of images with an optical flow field.\n",
    "    Supports lazy-loading of large data attributes.\"\"\"\n",
    "    \n",
    "#     slots = (\n",
    "#         'dataset',\n",
    "#         'id1',\n",
    "#         'id2',\n",
    "#         'img1',\n",
    "#         'img2',\n",
    "#         'flow',\n",
    "#     )\n",
    "    \n",
    "#     def __init__(self, **kwargs):\n",
    "#         for k in self.slots:\n",
    "#             setattr(self, k, kwargs.get(k))\n",
    "    \n",
    "    dataset = attr.ib(type=str, default='')\n",
    "    \"\"\"To which dataset does this pair belong?\"\"\"\n",
    "    \n",
    "    id1 = attr.ib(type=str, default='')\n",
    "    \"\"\"Identifier or URI for the first image\"\"\"\n",
    "    \n",
    "    id2 = attr.ib(type=str, default='')\n",
    "    \"\"\"Identifier or URI for the second image\"\"\"\n",
    "    \n",
    "    img1 = attr.ib(default=None)\n",
    "    \"\"\"URI or numpy array for the first image (source image)\"\"\"\n",
    "\n",
    "    img2 = attr.ib(default=None)\n",
    "    \"\"\"URI or numpy array for the second image (target image)\"\"\"\n",
    "    \n",
    "    flow = attr.ib(default=None)\n",
    "    \"\"\"A callable or numpy array representing optical flow from img1 -> img2\"\"\"\n",
    "    \n",
    "    def get_img1(self):\n",
    "        if isinstance(self.img1, six.string_types):\n",
    "            self.img1 = imageio.imread(self.img1)\n",
    "        return self.img1\n",
    "    \n",
    "    def get_img2(self):\n",
    "        if isinstance(self.img2, six.string_types):\n",
    "            self.img2 = imageio.imread(self.img2)\n",
    "        return self.img2\n",
    "    \n",
    "    def get_flow(self):\n",
    "        if not isinstance(self.flow, (np.ndarray, np.generic)):\n",
    "            self.flow = self.flow()\n",
    "        return self.flow\n",
    "    \n",
    "    def to_html(self):\n",
    "        im1 = self.get_img1()\n",
    "        im2 = self.get_img2()\n",
    "        flow = self.get_flow()\n",
    "        fviz = draw_flow(im1, flow)\n",
    "        html = \"\"\"\n",
    "            <table>\n",
    "            \n",
    "            <tr><td style=\"text-align:left\"><b>Dataset:</b> {dataset}</td></tr>\n",
    "            \n",
    "            <tr><td style=\"text-align:left\"><b>Source Image:</b> {id1}</td></tr>\n",
    "            <tr><td><img src=\"{im1}\" width=\"100%\" /></td></tr>\n",
    "\n",
    "            <tr><td style=\"text-align:left\"><b>Target Image:</b> {id2}</td></tr>\n",
    "            <tr><td><img src=\"{im2}\" width=\"100%\" /></td></tr>\n",
    "\n",
    "            <tr><td style=\"text-align:left\"><b>Flow</b></td></tr>\n",
    "            <tr><td><img src=\"{fviz}\" width=\"100%\" /></td></tr>\n",
    "            </table>\n",
    "        \"\"\".format(\n",
    "                dataset=self.dataset,\n",
    "                id1=self.id1, id2=self.id2,\n",
    "                im1=img_to_data_uri(im1), im2=img_to_data_uri(im2),\n",
    "                fviz=img_to_data_uri(fviz))\n",
    "        return html\n",
    "\n",
    "def draw_flow(img, flow, step=8):\n",
    "    \"\"\"Based upon OpenCV sample: https://github.com/opencv/opencv/blob/master/samples/python/opt_flow.py\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    y, x = np.mgrid[step/2:h:step, step/2:w:step].reshape(2,-1).astype(int)\n",
    "    fx, fy = flow[y,x].T\n",
    "    lines = np.vstack([x, y, x+fx, y+fy]).T.reshape(-1, 2, 2)\n",
    "    lines = np.int32(lines + 0.5)\n",
    "    vis = img.copy()\n",
    "    cv2.polylines(vis, lines, 0, (0, 255, 0))\n",
    "    for (x1, y1), (_x2, _y2) in lines:\n",
    "        cv2.circle(vis, (x1, y1), 1, (0, 255, 0), -1)\n",
    "    return vis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cheap_optical_flow_eval_analysis.ofp import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Middlebury Optical Flow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Please unzip `other-color-allframes.zip` and `other-gt-flow.zip` to a directory and provide the target below:\n",
    "MIDD_DATA_ROOT = '/outer_root/host_mnt/Volumes/970-evo-raid0/middlebury-flow/'\n",
    "\n",
    "# For the Middlebury Flow dataset, we only consider the real scenes\n",
    "MIDD_SCENES = [\n",
    "    {\n",
    "        'input': 'other-data/Dimetrodon/frame10.png',\n",
    "        'expected_out': 'other-data/Dimetrodon/frame11.png',\n",
    "        'flow_gt': 'other-gt-flow/Dimetrodon/flow10.flo',\n",
    "    },\n",
    "        {\n",
    "        'input': 'other-data/Hydrangea/frame10.png',\n",
    "        'expected_out': 'other-data/Hydrangea/frame11.png',\n",
    "        'flow_gt': 'other-gt-flow/Hydrangea/flow10.flo',\n",
    "    },\n",
    "        {\n",
    "        'input': 'other-data/RubberWhale/frame10.png',\n",
    "        'expected_out': 'other-data/RubberWhale/frame11.png',\n",
    "        'flow_gt': 'other-gt-flow/RubberWhale/flow10.flo',\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cheap_optical_flow_eval_analysis/midd.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile cheap_optical_flow_eval_analysis/midd.py\n",
    "\n",
    "import attr\n",
    "\n",
    "# Written as a functor to make it easier to pickle\n",
    "@attr.s(slots=True, eq=False, weakref_slot=False)\n",
    "class MiddReadFlow(object):\n",
    "    path = attr.ib(default='')\n",
    "    def __call__(self):\n",
    "        import os\n",
    "        import numpy as np\n",
    "        # Based upon: https://github.com/Johswald/flow-code-python/blob/master/readFlowFile.py\n",
    "        # compute colored image to visualize optical flow file .flo\n",
    "        # Author: Johannes Oswald, Technical University Munich\n",
    "        # Contact: johannes.oswald@tum.de\n",
    "        # Date: 26/04/2017\n",
    "        # For more information, check http://vision.middlebury.edu/flow/ \n",
    "        path = self.path\n",
    "        assert os.path.exists(path) and path.endswith('.flo'), path\n",
    "        f = open(path, 'rb')\n",
    "        flo_number = np.fromfile(f, np.float32, count=1)[0]\n",
    "        TAG_FLOAT = 202021.25\n",
    "        assert flo_number == TAG_FLOAT, 'Flow number %r incorrect.' % flo_number\n",
    "        w = np.fromfile(f, np.int32, count=1)\n",
    "        h = np.fromfile(f, np.int32, count=1)\n",
    "\n",
    "        #if error try: data = np.fromfile(f, np.float32, count=2*w[0]*h[0])\n",
    "        data = np.fromfile(f, np.float32, count=int(2*w*h))\n",
    "\n",
    "        # Reshape data into 3D array (columns, rows, bands)\n",
    "        flow = np.resize(data, (int(h), int(w), 2))\t\n",
    "        f.close()\n",
    "\n",
    "        # We found that there are some invalid (?) (i.e. very large) flows, so we're going\n",
    "        # to ignore those for this experiment.\n",
    "        invalid = (flow >= 1666)\n",
    "        flow[invalid] = 0\n",
    "\n",
    "        return flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cheap_optical_flow_eval_analysis.midd import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, scene in enumerate(MIDD_SCENES):\n",
    "    p = OpticalFlowPair(\n",
    "            dataset=\"Middlebury Optical Flow\",\n",
    "            id1=scene['input'],\n",
    "            img1='file://' + os.path.join(MIDD_DATA_ROOT, scene['input']),\n",
    "            id2=scene['expected_out'],\n",
    "            img2='file://' + os.path.join(MIDD_DATA_ROOT, scene['expected_out']),\n",
    "            flow=MiddReadFlow(os.path.join(MIDD_DATA_ROOT, scene['flow_gt'])))\n",
    "    \n",
    "    if RUN_FULL_ANALYSIS:\n",
    "        ALL_FPS.append(copy.deepcopy(p))\n",
    "    \n",
    "    if SHOW_DEMO_OUTPUT:\n",
    "        show_html(p.to_html() + \"<br/><br/><br/>\")\n",
    "        DEMO_FPS.append(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepDeform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Please extract deepdeform_v1.7z to a directory and provide the target below:\n",
    "DD_DATA_ROOT = '/outer_root/host_mnt/Volumes/970-evo-raid0/deepdeform_v1/'\n",
    "\n",
    "DD_DEMO_SCENES = [\n",
    "    {\n",
    "        \"input\": \"train/seq000/color/000000.jpg\",\n",
    "        \"expected_out\": \"train/seq000/color/000200.jpg\",\n",
    "        \"flow_gt\": \"train/seq000/optical_flow/blackdog_000000_000200.oflow\",\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        \"input\": \"train/seq000/color/000000.jpg\",\n",
    "        \"expected_out\": \"train/seq000/color/001200.jpg\",\n",
    "        \"flow_gt\": \"train/seq000/optical_flow/blackdog_000000_001200.oflow\",\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        \"input\": \"train/seq001/color/003400.jpg\",\n",
    "        \"expected_out\": \"train/seq001/color/003600.jpg\",\n",
    "        \"flow_gt\": \"train/seq001/optical_flow/lady_003400_003600.oflow\",\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        \"input\": \"train/seq337/color/000050.jpg\",\n",
    "        \"expected_out\": \"train/seq337/color/000350.jpg\",\n",
    "        \"flow_gt\": \"train/seq337/optical_flow/adult_000050_000350.oflow\",\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cheap_optical_flow_eval_analysis/deepdeform.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile cheap_optical_flow_eval_analysis/deepdeform.py\n",
    "\n",
    "import attr\n",
    "\n",
    "# Written as a functor to make it easier to pickle\n",
    "@attr.s(slots=True, eq=False, weakref_slot=False)\n",
    "class DDLoadFLow(object):\n",
    "    path = attr.ib(default='')\n",
    "    def __call__(self):\n",
    "        path = self.path\n",
    "        # Based upon https://github.com/AljazBozic/DeepDeform/blob/master/utils.py#L1\n",
    "        import shutil\n",
    "        import struct\n",
    "        import os\n",
    "        import numpy as np\n",
    "\n",
    "        # Flow is stored row-wise in order [channels, height, width].\n",
    "        assert os.path.isfile(path)\n",
    "\n",
    "        flow_gt = None\n",
    "        with open(path, 'rb') as fin:\n",
    "            width = struct.unpack('I', fin.read(4))[0]\n",
    "            height = struct.unpack('I', fin.read(4))[0]\n",
    "            channels = struct.unpack('I', fin.read(4))[0]\n",
    "            n_elems = height * width * channels\n",
    "\n",
    "            flow = struct.unpack('f' * n_elems, fin.read(n_elems * 4))\n",
    "            flow_gt = np.asarray(flow, dtype=np.float32).reshape([channels, height, width])\n",
    "\n",
    "        # Match format used in this analysis\n",
    "        flow_gt = np.moveaxis(flow_gt, 0, -1) # (h, w, 2)\n",
    "        invalid_flow = flow_gt == -np.Inf\n",
    "        flow_gt[invalid_flow] = 0.0\n",
    "        return flow_gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cheap_optical_flow_eval_analysis.deepdeform import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4540 DeepDeform scenes\n"
     ]
    }
   ],
   "source": [
    "def dd_create_fp(info):\n",
    "     return OpticalFlowPair(\n",
    "                dataset=\"DeepDeform Semi-Synthetic Optical Flow\",\n",
    "                id1=scene['input'],\n",
    "                img1='file://' + os.path.join(DD_DATA_ROOT, scene['input']),\n",
    "                id2=scene['expected_out'],\n",
    "                img2='file://' + os.path.join(DD_DATA_ROOT, scene['expected_out']),\n",
    "                flow=DDLoadFLow(os.path.join(DD_DATA_ROOT, scene['flow_gt'])))\n",
    "\n",
    "import json\n",
    "DD_ALIGNMENTS = json.load(open(os.path.join(DD_DATA_ROOT, 'train_alignments.json')))\n",
    "ALL_DD_SCENES = [\n",
    "    {\n",
    "        \"input\": ascene['source_color'],\n",
    "        \"expected_out\": ascene['target_color'],\n",
    "        \"flow_gt\": ascene['optical_flow'],\n",
    "    }\n",
    "    for ascene in DD_ALIGNMENTS\n",
    "]\n",
    "\n",
    "print(\"Found %s DeepDeform scenes\" % len(ALL_DD_SCENES))\n",
    "if SHOW_DEMO_OUTPUT:\n",
    "    for scene in DD_DEMO_SCENES:\n",
    "        p = dd_create_fp(scene)\n",
    "        show_html(p.to_html())\n",
    "        DEMO_FPS.append(p)\n",
    "\n",
    "if RUN_FULL_ANALYSIS:\n",
    "    for scene in ALL_DD_SCENES:\n",
    "        p = dd_create_fp(scene)\n",
    "        ALL_FPS.append(p)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kitti Scene Flow Benchmark (2015)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 KITTI SceneFlow 2015 scenes\n"
     ]
    }
   ],
   "source": [
    "# Please unzip `data_scene_flow.zip` and `data_scene_flow_calib.zip` to a directory and provide that target below:\n",
    "KITTI_SF15_DATA_ROOT = '/outer_root/host_mnt/Volumes/970-evo-raid0/kitti_sceneflow_scratch/'\n",
    "\n",
    "# You have to ls flow_occ \n",
    "KITTI_SF15_DEMO_SCENES = [\n",
    "    {\n",
    "        'input': 'training/image_2/000000_10.png',\n",
    "        'expected_out': 'training/image_2/000000_11.png',\n",
    "        'flow_gt': 'training/flow_occ/000000_10.png',\n",
    "    },\n",
    "    {\n",
    "        'input': 'training/image_2/000007_10.png',\n",
    "        'expected_out': 'training/image_2/000007_11.png',\n",
    "        'flow_gt': 'training/flow_occ/000007_10.png',\n",
    "    },\n",
    "    {\n",
    "        'input': 'training/image_2/000023_10.png',\n",
    "        'expected_out': 'training/image_2/000023_11.png',\n",
    "        'flow_gt': 'training/flow_occ/000023_10.png',\n",
    "    },\n",
    "    {\n",
    "        'input': 'training/image_2/000051_10.png',\n",
    "        'expected_out': 'training/image_2/000051_11.png',\n",
    "        'flow_gt': 'training/flow_occ/000051_10.png',\n",
    "    },\n",
    "    {\n",
    "        'input': 'training/image_2/000003_10.png',\n",
    "        'expected_out': 'training/image_2/000003_11.png',\n",
    "        'flow_gt': 'training/flow_occ/000003_10.png',\n",
    "    },\n",
    "]\n",
    "\n",
    "from oarphpy import util as oputil\n",
    "KITTI_SF15_ALL_FLOW_OCC = [\n",
    "    os.path.basename(p)\n",
    "    for p in oputil.all_files_recursive(\n",
    "        os.path.join(KITTI_SF15_DATA_ROOT, 'training/flow_occ'), pattern='*.png')\n",
    "]\n",
    "    \n",
    "KITTI_SF15_ALL_SCENES = [\n",
    "    {\n",
    "        \"input\": 'training/image_2/%s' % fname,\n",
    "        \"expected_out\": 'training/image_2/%s' % fname.replace('_10', '_11'),\n",
    "        \"flow_gt\": 'training/flow_occ/%s' % fname,\n",
    "    }\n",
    "    for fname in KITTI_SF15_ALL_FLOW_OCC\n",
    "]\n",
    "print(\"Found %s KITTI SceneFlow 2015 scenes\" % len(KITTI_SF15_ALL_SCENES))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cheap_optical_flow_eval_analysis/kittisf15.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile cheap_optical_flow_eval_analysis/kittisf15.py\n",
    "\n",
    "import attr\n",
    "\n",
    "# Written as a functor to make it easier to pickle\n",
    "@attr.s(slots=True, eq=False, weakref_slot=False)\n",
    "class KITTISF15LoadFlowFromPng(object):\n",
    "    path = attr.ib(default='')\n",
    "    def __call__(self):\n",
    "        path = self.path\n",
    "        # Based upon https://github.com/liruoteng/OpticalFlowToolkit/blob/master/lib/flowlib.py#L559\n",
    "        import png\n",
    "        import numpy as np\n",
    "        flow_object = png.Reader(filename=path)\n",
    "        flow_direct = flow_object.asDirect()\n",
    "        flow_data = list(flow_direct[2])\n",
    "        w, h = flow_direct[3]['size']\n",
    "        flow = np.zeros((h, w, 3), dtype=np.float64)\n",
    "        for i in range(len(flow_data)):\n",
    "            flow[i, :, 0] = flow_data[i][0::3]\n",
    "            flow[i, :, 1] = flow_data[i][1::3]\n",
    "            flow[i, :, 2] = flow_data[i][2::3]\n",
    "\n",
    "        invalid_idx = (flow[:, :, 2] == 0)\n",
    "        flow[:, :, 0:2] = (flow[:, :, 0:2] - 2 ** 15) / 64.0\n",
    "        flow[invalid_idx, 0] = 0\n",
    "        flow[invalid_idx, 1] = 0\n",
    "        return flow[:, :, :2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cheap_optical_flow_eval_analysis.kittisf15 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kitti_sf15_create_fp(info):\n",
    "     return OpticalFlowPair(\n",
    "                dataset=\"KITTI Scene Flow 2015\",\n",
    "                id1=scene['input'],\n",
    "                img1='file://' + os.path.join(KITTI_SF15_DATA_ROOT, scene['input']),\n",
    "                id2=scene['expected_out'],\n",
    "                img2='file://' + os.path.join(KITTI_SF15_DATA_ROOT, scene['expected_out']),\n",
    "                flow=KITTISF15LoadFlowFromPng(os.path.join(KITTI_SF15_DATA_ROOT, scene['flow_gt'])))\n",
    "\n",
    "if SHOW_DEMO_OUTPUT:\n",
    "    for scene in KITTI_SF15_DEMO_SCENES:\n",
    "        p = kitti_sf15_create_fp(scene)\n",
    "        show_html(p.to_html())\n",
    "        DEMO_FPS.append(p)\n",
    "\n",
    "if RUN_FULL_ANALYSIS:\n",
    "    for scene in KITTI_SF15_ALL_SCENES:\n",
    "        p = kitti_sf15_create_fp(scene)\n",
    "        ALL_FPS.append(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction via Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Reconstruction via Optical Flow\n",
    "\n",
    "def zero_flow(flow):\n",
    "    return (flow[:, :, :2] == np.array([0, 0])).all(axis=-1)\n",
    "\n",
    "def warp_flow_backwards(img, flow):\n",
    "    \"\"\"Given an image, apply the inverse of `flow`\"\"\"\n",
    "    h, w = flow.shape[:2]\n",
    "    flow = -flow\n",
    "    flow[:,:,0] += np.arange(w)\n",
    "    flow[:,:,1] += np.arange(h)[:,np.newaxis]\n",
    "    res = cv2.remap(img, flow.astype(np.float32), None, cv2.INTER_LINEAR)\n",
    "    return res\n",
    "    \n",
    "def warp_flow_forwards(img, flow):\n",
    "    \"\"\"Given an image, apply the given optical flow `flow`.  Returns not only the warped\n",
    "    image, but a `mask` indicating warped pixels (i.e. there was non-zero flow *into* these pixels ).\n",
    "    With some help from https://stackoverflow.com/questions/41703210/inverting-a-real-valued-index-grid/46009462#46009462\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    pts = flow.copy()\n",
    "    pts[:, :, 0] += np.arange(w)\n",
    "    pts[:, :, 1] += np.arange(h)[:, np.newaxis]\n",
    "    exclude = zero_flow(flow)\n",
    "    if exclude.all():\n",
    "        # No flow anywhere!\n",
    "        return img.copy(), np.zeros((h, w)).astype(np.bool)\n",
    "    else:\n",
    "        inpts = pts[~exclude]\n",
    "    \n",
    "    from scipy.interpolate import griddata\n",
    "    inpts = np.reshape(inpts, [-1, 2])\n",
    "    grid_y, grid_x = np.mgrid[:h, :w]\n",
    "    chan_out = []\n",
    "    for ch in range(img.shape[-1]):\n",
    "        spts = img[:, :, ch][~exclude].reshape([-1, 1])\n",
    "        mapped = griddata(inpts, spts, (grid_x, grid_y), method='linear')\n",
    "        chan_out.append(mapped.astype(img.dtype))\n",
    "    out = np.stack(chan_out, axis=-1)\n",
    "    out = out.reshape([h, w, len(chan_out)])\n",
    "\n",
    "    mask = np.reshape(inpts, [-1, 2])\n",
    "    mask = np.rint(mask).astype(np.int)\n",
    "    mask = mask[np.where((mask[:, 0] >= 0) & (mask[:, 0] < w) & (mask[:, 1] >= 0) & (mask[:, 1] < h))]\n",
    "    valid_mask = np.zeros((h, w))\n",
    "    valid_mask[mask[:, 1], mask[:, 0]] = 1\n",
    "    \n",
    "    return out, valid_mask.astype(np.bool)\n",
    "\n",
    "# @attr.s(slots=True, eq=False, weakref_slot=False)\n",
    "class FlowReconstructedImagePair(object):\n",
    "    \"\"\"A pair of reconstructed images using an input pair of images and optical\n",
    "    flow field (i.e. an `OpticalFlowPair` instance).\"\"\"\n",
    "\n",
    "    slots = (\n",
    "        'opair',\n",
    "        'img2_recon_fwd',\n",
    "        'img2_recon_fwd_valid',\n",
    "        'img1_recon_bkd',\n",
    "        'img1_recon_bkd_valid'\n",
    "    )\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        for k in self.slots:\n",
    "            setattr(self, k, kwargs.get(k))\n",
    "    \n",
    "#     opair = attr.ib(default=OpticalFlowPair())\n",
    "#     \"\"\"The original `OpticalFlowPair` with the source of the data for this reconstruction result.\"\"\"\n",
    "    \n",
    "#     img2_recon_fwd = attr.ib(default=np.array([]))\n",
    "#     \"\"\"A Numpy image containing the result of FORWARDS-WARPING OpticalFlowPair::img1\n",
    "#     via OpticalFlowPair::flow to reconstruct OpticalFlowPair::img2\"\"\"\n",
    "\n",
    "#     img2_recon_fwd_valid = attr.ib(default=np.array([]))\n",
    "#     \"\"\"A Numpy boolean mask indicating which pixels of `img2_recon_fwd` were modified via non-zero flow\"\"\"\n",
    "    \n",
    "#     img1_recon_bkd = attr.ib(default=np.array([]))\n",
    "#     \"\"\"A Numpy image containing the result of BACKWARDS-WARPING OpticalFlowPair::img2\n",
    "#     via OpticalFlowPair::flow to reconstruct OpticalFlowPair::img1\"\"\"\n",
    "\n",
    "#     img1_recon_bkd_valid = attr.ib(default=np.array([]))\n",
    "#     \"\"\"A Numpy boolean mask indicating which pixels of `img1_recon_bkd` were modified via non-zero flow\"\"\"\n",
    "        \n",
    "    @classmethod\n",
    "    def create_from(cls, oflow_pair: OpticalFlowPair):\n",
    "        flow = oflow_pair.get_flow()\n",
    "        \n",
    "        # Forward Warp\n",
    "        fwarped, fvalid = warp_flow_forwards(oflow_pair.get_img1(), flow)\n",
    "\n",
    "        # Backwards Warp\n",
    "        exclude = zero_flow(flow)\n",
    "        bwarped = warp_flow_backwards(oflow_pair.get_img2(), -flow[:, :, :2])\n",
    "        bvalid = ~exclude\n",
    "        \n",
    "        return FlowReconstructedImagePair(\n",
    "                opair=oflow_pair,\n",
    "                img2_recon_fwd=fwarped,\n",
    "                img2_recon_fwd_valid=fvalid,\n",
    "                img1_recon_bkd=bwarped,\n",
    "                img1_recon_bkd_valid=bvalid)\n",
    "    \n",
    "    def to_html(self):\n",
    "        # We use pixels from the destination image in order to make the reconstruction \n",
    "        # easier to interpret; we'll fade them in intensity so that they are more\n",
    "        # conspicuous.        \n",
    "        FADE_UNTOUCHED_PIXELS = 0.3\n",
    "        \n",
    "        viz_fwd = self.img2_recon_fwd.copy().astype(np.float32)\n",
    "        im2 = self.opair.get_img2()\n",
    "        if (~self.img2_recon_fwd_valid).any():\n",
    "            viz_fwd[~self.img2_recon_fwd_valid] = im2[~self.img2_recon_fwd_valid]\n",
    "            viz_fwd[~self.img2_recon_fwd_valid] *= FADE_UNTOUCHED_PIXELS\n",
    "        else:\n",
    "            # viz_fwd = im2.copy() * FADE_UNTOUCHED_PIXELS\n",
    "            print('no invalids forward!')\n",
    "        \n",
    "        viz_bkd = self.img1_recon_bkd.copy().astype(np.float32)\n",
    "        im1 = self.opair.get_img1()\n",
    "        if (~self.img1_recon_bkd_valid).any():\n",
    "            viz_bkd[~self.img1_recon_bkd_valid] = im1[~self.img1_recon_bkd_valid]\n",
    "            viz_bkd[~self.img1_recon_bkd_valid] *= FADE_UNTOUCHED_PIXELS\n",
    "        else:\n",
    "            # viz_bkd = im1.copy() * FADE_UNTOUCHED_PIXELS\n",
    "            print('no invalids backwards!')\n",
    "        \n",
    "        html = \"\"\"\n",
    "            <table>\n",
    "            \n",
    "            <tr><td style=\"text-align:left\"><b>Forwards Warped <i>(dark pixels unwarped)</i></b></td></tr>\n",
    "            <tr><td><img src=\"{viz_fwd}\" width=\"100%\" /></td></tr>\n",
    "\n",
    "            <tr><td style=\"text-align:left\"><b>Backwards Warped <i>(dark pixels unwarped)</i></b></td></tr>\n",
    "            <tr><td><img src=\"{viz_bkd}\" width=\"100%\" /></td></tr>\n",
    "\n",
    "            </table>\n",
    "        \"\"\".format(\n",
    "                viz_fwd=img_to_data_uri(viz_fwd.astype(np.uint8)),\n",
    "                viz_bkd=img_to_data_uri(viz_bkd.astype(np.uint8)))\n",
    "        return html\n",
    "\n",
    "        \n",
    "if SHOW_DEMO_OUTPUT:\n",
    "    DEMO_RECONS = []\n",
    "    for p in DEMO_FPS:\n",
    "        recon = FlowReconstructedImagePair.create_from(p)\n",
    "        show_html(recon.to_html() + \"</br></br></br>\")\n",
    "        DEMO_RECONS.append(recon)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Analysis Utils\n",
    "\n",
    "def mse(i1, i2, valid):\n",
    "    return np.mean((i1[valid] - i2[valid]) ** 2)\n",
    "\n",
    "def rmse(i1, i2, valid):\n",
    "    return math.sqrt(mse(i1, i2, valid))\n",
    "\n",
    "def psnr(i1, i2, valid):\n",
    "    return 20 * math.log10(255) - 10 * math.log10(max((mse(i1, i2, valid), 1e-12)))\n",
    "\n",
    "def ssim(i1, i2, valid):\n",
    "    # Some variance out there ...\n",
    "    # https://github.com/scikit-image/scikit-image/blob/master/skimage/metrics/_structural_similarity.py#L12-L232\n",
    "    # https://github.com/nianticlabs/monodepth2/blob/13200ab2f29f2f10dec3aa5db29c32a23e29d376/layers.py#L218\n",
    "    # https://cvnote.ddlee.cn/2019/09/12/psnr-ssim-python\n",
    "    # We will just use SKImage for now ...\n",
    "    from skimage.metrics import structural_similarity as ssim\n",
    "    mssim, S = ssim(i1, i2, win_size=11, multichannel=True, full=True)\n",
    "    return np.mean(S[valid])\n",
    "\n",
    "def to_edge_im(img):\n",
    "    return np.stack([\n",
    "        cv2.Laplacian(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY), cv2.CV_32F, ksize=1),\n",
    "        cv2.Sobel(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY), cv2.CV_32F, 1, 0, ksize=3),\n",
    "        cv2.Sobel(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY), cv2.CV_32F, 0, 1, ksize=3),\n",
    "    ], axis=-1)\n",
    "\n",
    "def edges_mse(i1, i2, valid):\n",
    "    return mse(to_edge_im(i1), to_edge_im(i2), valid)\n",
    "\n",
    "\n",
    "def oflow_coverage(valid):\n",
    "    return valid.sum() / (valid.shape[0] * valid.shape[1])\n",
    "\n",
    "def oflow_magnitude_hist(flow, valid, bins=50):\n",
    "    flow_l2s = np.sqrt( flow[valid][:, 0] ** 2 + flow[valid][:, 1] ** 2 )\n",
    "    bin_counts, bin_edges = np.histogram(flow_l2s, bins=bins)\n",
    "    return bin_edges, bin_counts\n",
    "\n",
    "\n",
    "# Analysis Data Model\n",
    "\n",
    "class OFlowReconErrors(object):\n",
    "    \"\"\"Various measures of reconstruction error for a `FlowReconstructedImagePair` instance.\n",
    "    Encapsulated as two dictionaries of stats for easy interop with Spark SQL.\"\"\"\n",
    "\n",
    "    RECONSTRUCTION_ERR_METRICS = {\n",
    "        'SSIM': ssim,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'PSNR': psnr,\n",
    "        'Edges_MSE': edges_mse,\n",
    "    }\n",
    "    \n",
    "    def __init__(self, recon_pair: FlowReconstructedImagePair):\n",
    "        im2 = recon_pair.opair.get_img2()\n",
    "        img2_recon_fwd = recon_pair.img2_recon_fwd\n",
    "        img2_recon_fwd_valid = recon_pair.img2_recon_fwd_valid\n",
    "        self.forward_stats = dict(\n",
    "            (name, func(im2, img2_recon_fwd, img2_recon_fwd_valid))\n",
    "            for name, func in self.RECONSTRUCTION_ERR_METRICS.items())\n",
    "        \n",
    "        im1 = recon_pair.opair.get_img1()\n",
    "        img1_recon_fwd = recon_pair.img1_recon_bkd\n",
    "        img1_recon_fwd_valid = recon_pair.img1_recon_bkd_valid\n",
    "        self.backward_stats = dict(\n",
    "            (name, func(im1, img1_recon_fwd, img1_recon_fwd_valid))\n",
    "            for name, func in self.RECONSTRUCTION_ERR_METRICS.items())\n",
    "\n",
    "    def to_html(self):\n",
    "        stat_names = self.RECONSTRUCTION_ERR_METRICS.keys()\n",
    "\n",
    "        rows = [\n",
    "            \"\"\"\n",
    "            <tr>\n",
    "              <td style=\"text-align:left\"><b>{name}</b></td>\n",
    "              <td style=\"text-align:left\">{fwd:.2f}</td>\n",
    "              <td style=\"text-align:left\">{bkd:.2f}</td>\n",
    "            </tr>\n",
    "            \"\"\".format(name=name, fwd=self.forward_stats[name], bkd=self.backward_stats[name])\n",
    "            for name in stat_names\n",
    "        ]\n",
    "        \n",
    "        \n",
    "        html = \"\"\"\n",
    "            <table>\n",
    "              <tr>\n",
    "                  <th></th> <th><b>Forwards Warp</b></th> <th><b>Backwards Warp</b></th>\n",
    "              </tr>\n",
    "\n",
    "              {table_rows}\n",
    "\n",
    "            </table>\n",
    "        \"\"\".format(table_rows=\"\".join(rows))\n",
    "        \n",
    "        return html\n",
    "            \n",
    "# @attr.s(slots=True, eq=False, weakref_slot=False)\n",
    "class OFlowStats(object):\n",
    "    \"\"\"Stats on the optical flow of a `OpticalFlowPair` instance\"\"\"\n",
    "\n",
    "    slots = (\n",
    "        'opair',\n",
    "        'coverage',\n",
    "        'magnitude_hist',\n",
    "    )\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        for k in self.slots:\n",
    "            setattr(self, k, kwargs.get(k))\n",
    "    \n",
    "#     opair = attr.ib(default=OpticalFlowPair())\n",
    "#     \"\"\"The original `OpticalFlowPair` with the source of the data for this reconstruction result.\"\"\"\n",
    "    \n",
    "#     coverage = attr.ib(default=0)\n",
    "#     \"\"\"Fraction of the image with valid flow\"\"\"\n",
    "    \n",
    "#     magnitude_hist = attr.ib(default=[np.array([]), np.array([])])\n",
    "#     \"\"\"Histogram [bin edges, bin counts] of flow magnitudes\"\"\"\n",
    "    \n",
    "    @classmethod\n",
    "    def create_from(cls, oflow_pair: OpticalFlowPair):\n",
    "        flow = oflow_pair.get_flow()\n",
    "        valid = ~zero_flow(flow)\n",
    "        return OFlowStats(\n",
    "                 opair=oflow_pair,\n",
    "                 coverage=oflow_coverage(valid),\n",
    "                 magnitude_hist=oflow_magnitude_hist(flow, valid))\n",
    "                 \n",
    "    def to_html(self):\n",
    "        import matplotlib.pyplot as plt\n",
    "        fig = plt.figure()\n",
    "        bin_edges, bin_counts = self.magnitude_hist\n",
    "        plt.bar(bin_edges[:-1], bin_counts)\n",
    "        plt.title(\"Histogram of Flow Magnitudes\")\n",
    "        plt.xlabel('Flow Magnitude (pixels)')\n",
    "        plt.ylabel('Count')\n",
    "\n",
    "        hist_img = matplotlib_fig_to_img(fig)\n",
    "        \n",
    "        html = \"\"\"\n",
    "            <table>           \n",
    "            <tr><td style=\"text-align:left\"><b>Flow Coverage:</b> {coverage:.2f}% </td></tr>\n",
    "            <tr><td><img src=\"{flow_hist}\" width=\"100%\" /></td></tr>\n",
    "            </table>\n",
    "        \"\"\".format(\n",
    "                coverage=100. * self.coverage,\n",
    "                flow_hist=img_to_data_uri(matplotlib_fig_to_img(hist_img)))\n",
    "        return html\n",
    "\n",
    "\n",
    "# Misc\n",
    "\n",
    "def matplotlib_fig_to_img(fig):\n",
    "    import io\n",
    "    import matplotlib.pyplot as plt\n",
    "    from PIL import Image\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    im = Image.open(buf)\n",
    "    im.show()\n",
    "    buf.seek(0)\n",
    "\n",
    "    import imageio\n",
    "    hist_img = imageio.imread(buf)\n",
    "    buf.close()\n",
    "    return hist_img\n",
    "\n",
    "\n",
    "if SHOW_DEMO_OUTPUT:\n",
    "    %matplotlib agg\n",
    "    for recon in DEMO_RECONS:\n",
    "        p = recon.opair\n",
    "        errors = OFlowReconErrors(recon)\n",
    "        err_html = errors.to_html()  \n",
    "            \n",
    "        fstats = OFlowStats.create_from(p)\n",
    "        stats_html = fstats.to_html()\n",
    "            \n",
    "        title = \"<b>{dataset} {id1} -> {id2}</b>\".format(dataset=p.dataset, id1=p.id1, id2=p.id2)\n",
    "        \n",
    "        show_html(title + stats_html + err_html + \"</br></br></br>\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis on Full Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-04 21:46:17,056\toarph 9935 : Using source root /opt/oarphpy/oarphpy \n",
      "2021-02-04 21:46:17,057\toarph 9935 : Using source root /opt/oarphpy \n",
      "2021-02-04 21:46:17,060\toarph 9935 : Generating egg to /tmp/tmpq4bbhuyn_oarphpy_eggbuild ...\n",
      "2021-02-04 21:46:17,094\toarph 9935 : ... done.  Egg at /tmp/tmpq4bbhuyn_oarphpy_eggbuild/oarphpy-0.0.0-py3.6.egg\n",
      "2021-02-04 21:46:17,103\toarph 9935 : Using source root /tmp/tmptk_89y2q_cheap_optical_flow_eval_analysis/cheap_optical_flow_eval_analysis \n",
      "2021-02-04 21:46:17,104\toarph 9935 : Using source root /tmp/tmptk_89y2q_cheap_optical_flow_eval_analysis \n",
      "2021-02-04 21:46:17,106\toarph 9935 : Generating egg to /tmp/tmp9km09yze_oarphpy_eggbuild ...\n",
      "2021-02-04 21:46:17,117\toarph 9935 : ... done.  Egg at /tmp/tmp9km09yze_oarphpy_eggbuild/cheap_optical_flow_eval_analysis-0.0.0-py3.6.egg\n",
      "/opt/spark/python/pyspark/sql/session.py:366: UserWarning: Using RDD of dict to inferSchema is deprecated. Use pyspark.sql.Row instead\n",
      "  warnings.warn(\"Using RDD of dict to inferSchema is deprecated. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4743\n",
      "+-------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+--------------------+--------------------+\n",
      "|Backwards_Edges_MSE|     Backwards_MSE|    Backwards_PSNR|    Backwards_RMSE|    Backwards_SSIM|Forwards_Edges_MSE|      Forwards_MSE|     Forwards_PSNR|     Forwards_RMSE|     Forwards_SSIM|       flow_coverage|                  fp|\n",
      "+-------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+--------------------+--------------------+\n",
      "|   81.1972427368164| 5.826628672041516|  40.4766301925312|2.4138410618848782|0.9688232937170571|   507.72802734375| 6.529287857121507| 39.98214545073427|2.5552471225150626|0.9348639854026914|  0.9524608106199689|[cheap_optical_fl...|\n",
      "|    718.86279296875|11.585101458585248| 37.49180519314141|3.4036893892635454|0.9358539110677977|461.71490478515625|11.882650279757065| 37.38167045348493|3.4471220285561497|0.9520399565112353|  0.9343313091371275|[cheap_optical_fl...|\n",
      "|  91.03426361083984| 4.792967663811275|41.324758618731394| 2.189284737947825|0.9819405226631645| 863.6701049804688|5.2067438753588124| 40.96514146021898|  2.28182906357133|0.9607198777127243|  0.9840153226945346|[cheap_optical_fl...|\n",
      "|  462.7218322753906| 7.197305000209565| 39.55910453692252|2.6827793424375335| 0.864983848463645| 149.2679901123047| 7.450564219601876| 39.40891198430854|2.7295721678684144|0.8711389440563724|       0.05177734375|[cheap_optical_fl...|\n",
      "|  704.1644897460938| 35.13215124649542| 32.67375617114104| 5.927238079113696|0.6556017680302483| 198.2032928466797| 37.33638696683234| 32.40948071793868|6.1103508055456475|0.8045417391827318|      0.042958984375|[cheap_optical_fl...|\n",
      "|    1004.1904296875|15.532929768510733| 36.21826982261457| 3.941183802934181|0.7734072614888903|167.31045532226562|16.430763019781995|35.974226289857086| 4.053487759915157|0.8114796300271883| 0.03871744791666667|[cheap_optical_fl...|\n",
      "|  688.7952270507812| 25.11843079200592| 34.13087856362455| 5.011829086471916|0.6743579955830725|182.16770935058594|25.928585049580473|33.993015433629694| 5.092011886237155|0.8109640092970622| 0.04397786458333333|[cheap_optical_fl...|\n",
      "|  597.9923706054688|23.988407106293284|34.330789502454216| 4.897796147890731|0.7557758029575428| 153.8397216796875|24.746754995421984| 34.19562102243851| 4.974611039611236|0.8262159207038795|        0.0432421875|[cheap_optical_fl...|\n",
      "|  3049.464599609375| 29.10247557309282| 33.49150427483201| 5.394671034742788|0.6778141194432816|232.03073120117188|27.745684769584507| 33.69884913102406| 5.267417276956944|0.7890881306782513|0.046197916666666665|[cheap_optical_fl...|\n",
      "|  792.5049438476562| 45.03763545100067|31.595047795916578| 6.711008527114287|0.7090287734131049|210.25064086914062|47.092494443494616|31.401286656608356| 6.862397135367103|0.7723315377067602| 0.05036783854166667|[cheap_optical_fl...|\n",
      "+-------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "root\n",
      " |-- Backwards_Edges_MSE: double (nullable = true)\n",
      " |-- Backwards_MSE: double (nullable = true)\n",
      " |-- Backwards_PSNR: double (nullable = true)\n",
      " |-- Backwards_RMSE: double (nullable = true)\n",
      " |-- Backwards_SSIM: double (nullable = true)\n",
      " |-- Forwards_Edges_MSE: double (nullable = true)\n",
      " |-- Forwards_MSE: double (nullable = true)\n",
      " |-- Forwards_PSNR: double (nullable = true)\n",
      " |-- Forwards_RMSE: double (nullable = true)\n",
      " |-- Forwards_SSIM: double (nullable = true)\n",
      " |-- flow_coverage: double (nullable = true)\n",
      " |-- fp: struct (nullable = true)\n",
      " |    |-- __pyclass__: string (nullable = true)\n",
      " |    |-- dataset: string (nullable = true)\n",
      " |    |-- flow: struct (nullable = true)\n",
      " |    |    |-- __pyclass__: string (nullable = true)\n",
      " |    |    |-- path: string (nullable = true)\n",
      " |    |-- id1: string (nullable = true)\n",
      " |    |-- id2: string (nullable = true)\n",
      " |    |-- img1: string (nullable = true)\n",
      " |    |-- img2: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/opt/psegs')\n",
    "\n",
    "from oarphpy import plotting as pl\n",
    "from oarphpy.spark import NBSpark\n",
    "NBSpark.SRC_ROOT = os.path.join(ALIB_SRC_DIR, 'cheap_optical_flow_eval_analysis')\n",
    "NBSpark.CONF_KV.update({\n",
    "    'spark.driver.maxResultSize': '2g',\n",
    "    'spark.driver.memory': '16g',\n",
    "  })\n",
    "spark = NBSpark.getOrCreate()\n",
    "\n",
    "\n",
    "from oarphpy.spark import RowAdapter\n",
    "\n",
    "from pyspark import Row\n",
    "\n",
    "\n",
    "def flow_pair_to_full_row(fp):\n",
    "    fp_lite = copy.deepcopy(fp)\n",
    "    recon = FlowReconstructedImagePair.create_from(fp)\n",
    "    fstats = OFlowStats.create_from(fp)\n",
    "    errors = OFlowReconErrors(recon)\n",
    "    \n",
    "    rowdata = dict(\n",
    "            fp=fp_lite,\n",
    "            flow_coverage=fstats.coverage,\n",
    "    )\n",
    "    rowdata.update(\n",
    "        ('Forwards_' + k, float(v))\n",
    "        for k, v in errors.forward_stats.items())\n",
    "    rowdata.update(\n",
    "        ('Backwards_' + k, float(v))\n",
    "        for k, v in errors.backward_stats.items())\n",
    "    return RowAdapter.to_row(rowdata)\n",
    "  \n",
    "if RUN_FULL_ANALYSIS:\n",
    "#     spark = Spark.getOrCreate()\n",
    "    \n",
    "#     for p in ALL_FPS:\n",
    "#         import cloudpickle\n",
    "#         try:\n",
    "#             cloudpickle.dumps(p)\n",
    "#         except Exception:\n",
    "#             assert False, p\n",
    "#     print('all good')\n",
    "    \n",
    "    import pickle\n",
    "    fp_rdd = spark.sparkContext.parallelize(ALL_FPS, numSlices=200)\n",
    "#     print(fp_rdd.count())\n",
    "    df = spark.createDataFrame(fp_rdd.map(flow_pair_to_full_row)).persist()\n",
    "\n",
    "    print(df.count())\n",
    "    df.show(10)\n",
    "    df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Backwards_Edges_MSE',\n",
       " 'Backwards_MSE',\n",
       " 'Backwards_PSNR',\n",
       " 'Backwards_RMSE',\n",
       " 'Backwards_SSIM',\n",
       " 'Forwards_Edges_MSE',\n",
       " 'Forwards_MSE',\n",
       " 'Forwards_PSNR',\n",
       " 'Forwards_RMSE',\n",
       " 'Forwards_SSIM',\n",
       " 'flow_coverage',\n",
       " 'fp']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-04 22:13:33,215\toarph 9935 : Plotting histogram for Backwards_Edges_MSE of DataFrame[Backwards_Edges_MSE: double, Backwards_MSE: double, Backwards_PSNR: double, Backwards_RMSE: double, Backwards_SSIM: double, Forwards_Edges_MSE: double, Forwards_MSE: double, Forwards_PSNR: double, Forwards_RMSE: double, Forwards_SSIM: double, flow_coverage: double, fp: struct<__pyclass__:string,dataset:string,flow:struct<__pyclass__:string,path:string>,id1:string,id2:string,img1:string,img2:string>] ...\n",
      "2021-02-04 22:13:36,031\toarph 9935 : ... building data source for ALL ...\n",
      "2021-02-04 22:13:36,032\toarph 9935 : ... histogramming ALL ...\n",
      "2021-02-04 22:13:39,090\toarph 9935 : ... display-ifying examples for ALL ...\n",
      "2021-02-04 22:14:27,230\toarph 9935 : ... building data source for DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:14:27,289\toarph 9935 : ... histogramming DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:14:31,222\toarph 9935 : ... display-ifying examples for DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:14:53,430\toarph 9935 : ... building data source for KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:14:53,484\toarph 9935 : ... histogramming KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:14:57,078\toarph 9935 : ... display-ifying examples for KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:15:45,115\toarph 9935 : ... building data source for Middlebury Optical Flow ...\n",
      "2021-02-04 22:15:45,194\toarph 9935 : ... histogramming Middlebury Optical Flow ...\n",
      "2021-02-04 22:15:48,789\toarph 9935 : ... display-ifying examples for Middlebury Optical Flow ...\n",
      "2021-02-04 22:16:22,396\toarph 9935 : Wrote Bokeh figure to /outer_root/host_mnt/Volumes/970-evo-raid0/Backwards_Edges_MSE.html\n",
      "2021-02-04 22:16:22,398\toarph 9935 : Plotting histogram for Backwards_MSE of DataFrame[Backwards_Edges_MSE: double, Backwards_MSE: double, Backwards_PSNR: double, Backwards_RMSE: double, Backwards_SSIM: double, Forwards_Edges_MSE: double, Forwards_MSE: double, Forwards_PSNR: double, Forwards_RMSE: double, Forwards_SSIM: double, flow_coverage: double, fp: struct<__pyclass__:string,dataset:string,flow:struct<__pyclass__:string,path:string>,id1:string,id2:string,img1:string,img2:string>] ...\n",
      "2021-02-04 22:16:24,674\toarph 9935 : ... building data source for ALL ...\n",
      "2021-02-04 22:16:24,676\toarph 9935 : ... histogramming ALL ...\n",
      "2021-02-04 22:16:29,186\toarph 9935 : ... display-ifying examples for ALL ...\n",
      "2021-02-04 22:17:12,801\toarph 9935 : ... building data source for DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:17:12,857\toarph 9935 : ... histogramming DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:17:16,361\toarph 9935 : ... display-ifying examples for DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:17:36,727\toarph 9935 : ... building data source for KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:17:36,766\toarph 9935 : ... histogramming KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:17:40,324\toarph 9935 : ... display-ifying examples for KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:18:26,497\toarph 9935 : ... building data source for Middlebury Optical Flow ...\n",
      "2021-02-04 22:18:26,570\toarph 9935 : ... histogramming Middlebury Optical Flow ...\n",
      "2021-02-04 22:18:30,262\toarph 9935 : ... display-ifying examples for Middlebury Optical Flow ...\n",
      "2021-02-04 22:18:57,116\toarph 9935 : Wrote Bokeh figure to /outer_root/host_mnt/Volumes/970-evo-raid0/Backwards_MSE.html\n",
      "2021-02-04 22:18:57,117\toarph 9935 : Plotting histogram for Backwards_PSNR of DataFrame[Backwards_Edges_MSE: double, Backwards_MSE: double, Backwards_PSNR: double, Backwards_RMSE: double, Backwards_SSIM: double, Forwards_Edges_MSE: double, Forwards_MSE: double, Forwards_PSNR: double, Forwards_RMSE: double, Forwards_SSIM: double, flow_coverage: double, fp: struct<__pyclass__:string,dataset:string,flow:struct<__pyclass__:string,path:string>,id1:string,id2:string,img1:string,img2:string>] ...\n",
      "2021-02-04 22:18:59,434\toarph 9935 : ... building data source for ALL ...\n",
      "2021-02-04 22:18:59,438\toarph 9935 : ... histogramming ALL ...\n",
      "2021-02-04 22:19:02,872\toarph 9935 : ... display-ifying examples for ALL ...\n",
      "2021-02-04 22:19:42,921\toarph 9935 : ... building data source for DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:19:42,967\toarph 9935 : ... histogramming DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:19:46,443\toarph 9935 : ... display-ifying examples for DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:20:16,043\toarph 9935 : ... building data source for KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:20:16,097\toarph 9935 : ... histogramming KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:20:19,488\toarph 9935 : ... display-ifying examples for KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:21:09,093\toarph 9935 : ... building data source for Middlebury Optical Flow ...\n",
      "2021-02-04 22:21:09,131\toarph 9935 : ... histogramming Middlebury Optical Flow ...\n",
      "2021-02-04 22:21:12,466\toarph 9935 : ... display-ifying examples for Middlebury Optical Flow ...\n",
      "2021-02-04 22:21:38,751\toarph 9935 : Wrote Bokeh figure to /outer_root/host_mnt/Volumes/970-evo-raid0/Backwards_PSNR.html\n",
      "2021-02-04 22:21:38,754\toarph 9935 : Plotting histogram for Backwards_RMSE of DataFrame[Backwards_Edges_MSE: double, Backwards_MSE: double, Backwards_PSNR: double, Backwards_RMSE: double, Backwards_SSIM: double, Forwards_Edges_MSE: double, Forwards_MSE: double, Forwards_PSNR: double, Forwards_RMSE: double, Forwards_SSIM: double, flow_coverage: double, fp: struct<__pyclass__:string,dataset:string,flow:struct<__pyclass__:string,path:string>,id1:string,id2:string,img1:string,img2:string>] ...\n",
      "2021-02-04 22:21:41,018\toarph 9935 : ... building data source for ALL ...\n",
      "2021-02-04 22:21:41,020\toarph 9935 : ... histogramming ALL ...\n",
      "2021-02-04 22:21:44,460\toarph 9935 : ... display-ifying examples for ALL ...\n",
      "2021-02-04 22:22:21,710\toarph 9935 : ... building data source for DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:22:21,766\toarph 9935 : ... histogramming DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:22:27,266\toarph 9935 : ... display-ifying examples for DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:22:54,180\toarph 9935 : ... building data source for KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:22:54,223\toarph 9935 : ... histogramming KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:22:57,124\toarph 9935 : ... display-ifying examples for KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:23:32,414\toarph 9935 : ... building data source for Middlebury Optical Flow ...\n",
      "2021-02-04 22:23:32,451\toarph 9935 : ... histogramming Middlebury Optical Flow ...\n",
      "2021-02-04 22:23:35,170\toarph 9935 : ... display-ifying examples for Middlebury Optical Flow ...\n",
      "2021-02-04 22:23:55,777\toarph 9935 : Wrote Bokeh figure to /outer_root/host_mnt/Volumes/970-evo-raid0/Backwards_RMSE.html\n",
      "2021-02-04 22:23:55,780\toarph 9935 : Plotting histogram for Backwards_SSIM of DataFrame[Backwards_Edges_MSE: double, Backwards_MSE: double, Backwards_PSNR: double, Backwards_RMSE: double, Backwards_SSIM: double, Forwards_Edges_MSE: double, Forwards_MSE: double, Forwards_PSNR: double, Forwards_RMSE: double, Forwards_SSIM: double, flow_coverage: double, fp: struct<__pyclass__:string,dataset:string,flow:struct<__pyclass__:string,path:string>,id1:string,id2:string,img1:string,img2:string>] ...\n",
      "2021-02-04 22:23:57,589\toarph 9935 : ... building data source for ALL ...\n",
      "2021-02-04 22:23:57,590\toarph 9935 : ... histogramming ALL ...\n",
      "2021-02-04 22:24:00,429\toarph 9935 : ... display-ifying examples for ALL ...\n",
      "2021-02-04 22:24:37,015\toarph 9935 : ... building data source for DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:24:37,051\toarph 9935 : ... histogramming DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:24:39,743\toarph 9935 : ... display-ifying examples for DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:24:59,328\toarph 9935 : ... building data source for KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:24:59,365\toarph 9935 : ... histogramming KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:25:02,400\toarph 9935 : ... display-ifying examples for KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:25:37,046\toarph 9935 : ... building data source for Middlebury Optical Flow ...\n",
      "2021-02-04 22:25:37,085\toarph 9935 : ... histogramming Middlebury Optical Flow ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-04 22:25:39,701\toarph 9935 : ... display-ifying examples for Middlebury Optical Flow ...\n",
      "2021-02-04 22:26:00,565\toarph 9935 : Wrote Bokeh figure to /outer_root/host_mnt/Volumes/970-evo-raid0/Backwards_SSIM.html\n",
      "2021-02-04 22:26:00,566\toarph 9935 : Plotting histogram for Forwards_Edges_MSE of DataFrame[Backwards_Edges_MSE: double, Backwards_MSE: double, Backwards_PSNR: double, Backwards_RMSE: double, Backwards_SSIM: double, Forwards_Edges_MSE: double, Forwards_MSE: double, Forwards_PSNR: double, Forwards_RMSE: double, Forwards_SSIM: double, flow_coverage: double, fp: struct<__pyclass__:string,dataset:string,flow:struct<__pyclass__:string,path:string>,id1:string,id2:string,img1:string,img2:string>] ...\n",
      "2021-02-04 22:26:02,235\toarph 9935 : ... building data source for ALL ...\n",
      "2021-02-04 22:26:02,235\toarph 9935 : ... histogramming ALL ...\n",
      "2021-02-04 22:26:04,948\toarph 9935 : ... display-ifying examples for ALL ...\n",
      "2021-02-04 22:26:39,238\toarph 9935 : ... building data source for DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:26:39,274\toarph 9935 : ... histogramming DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:26:41,823\toarph 9935 : ... display-ifying examples for DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:26:56,604\toarph 9935 : ... building data source for KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:26:56,643\toarph 9935 : ... histogramming KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:26:59,290\toarph 9935 : ... display-ifying examples for KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:27:27,798\toarph 9935 : ... building data source for Middlebury Optical Flow ...\n",
      "2021-02-04 22:27:27,803\toarph 9935 : ... histogramming Middlebury Optical Flow ...\n",
      "2021-02-04 22:27:30,356\toarph 9935 : ... display-ifying examples for Middlebury Optical Flow ...\n",
      "2021-02-04 22:27:48,815\toarph 9935 : Wrote Bokeh figure to /outer_root/host_mnt/Volumes/970-evo-raid0/Forwards_Edges_MSE.html\n",
      "2021-02-04 22:27:48,817\toarph 9935 : Plotting histogram for Forwards_MSE of DataFrame[Backwards_Edges_MSE: double, Backwards_MSE: double, Backwards_PSNR: double, Backwards_RMSE: double, Backwards_SSIM: double, Forwards_Edges_MSE: double, Forwards_MSE: double, Forwards_PSNR: double, Forwards_RMSE: double, Forwards_SSIM: double, flow_coverage: double, fp: struct<__pyclass__:string,dataset:string,flow:struct<__pyclass__:string,path:string>,id1:string,id2:string,img1:string,img2:string>] ...\n",
      "2021-02-04 22:27:50,492\toarph 9935 : ... building data source for ALL ...\n",
      "2021-02-04 22:27:50,492\toarph 9935 : ... histogramming ALL ...\n",
      "2021-02-04 22:27:53,071\toarph 9935 : ... display-ifying examples for ALL ...\n",
      "2021-02-04 22:28:28,556\toarph 9935 : ... building data source for DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:28:28,593\toarph 9935 : ... histogramming DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:28:31,203\toarph 9935 : ... display-ifying examples for DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:28:46,445\toarph 9935 : ... building data source for KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:28:46,488\toarph 9935 : ... histogramming KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:28:49,204\toarph 9935 : ... display-ifying examples for KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:29:23,307\toarph 9935 : ... building data source for Middlebury Optical Flow ...\n",
      "2021-02-04 22:29:23,344\toarph 9935 : ... histogramming Middlebury Optical Flow ...\n",
      "2021-02-04 22:29:25,880\toarph 9935 : ... display-ifying examples for Middlebury Optical Flow ...\n",
      "2021-02-04 22:29:46,195\toarph 9935 : Wrote Bokeh figure to /outer_root/host_mnt/Volumes/970-evo-raid0/Forwards_MSE.html\n",
      "2021-02-04 22:29:46,198\toarph 9935 : Plotting histogram for Forwards_PSNR of DataFrame[Backwards_Edges_MSE: double, Backwards_MSE: double, Backwards_PSNR: double, Backwards_RMSE: double, Backwards_SSIM: double, Forwards_Edges_MSE: double, Forwards_MSE: double, Forwards_PSNR: double, Forwards_RMSE: double, Forwards_SSIM: double, flow_coverage: double, fp: struct<__pyclass__:string,dataset:string,flow:struct<__pyclass__:string,path:string>,id1:string,id2:string,img1:string,img2:string>] ...\n",
      "2021-02-04 22:29:47,938\toarph 9935 : ... building data source for ALL ...\n",
      "2021-02-04 22:29:47,938\toarph 9935 : ... histogramming ALL ...\n",
      "2021-02-04 22:29:50,542\toarph 9935 : ... display-ifying examples for ALL ...\n",
      "2021-02-04 22:30:21,109\toarph 9935 : ... building data source for DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:30:21,145\toarph 9935 : ... histogramming DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:30:23,819\toarph 9935 : ... display-ifying examples for DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:30:47,164\toarph 9935 : ... building data source for KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:30:47,201\toarph 9935 : ... histogramming KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:30:49,883\toarph 9935 : ... display-ifying examples for KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:31:25,948\toarph 9935 : ... building data source for Middlebury Optical Flow ...\n",
      "2021-02-04 22:31:25,990\toarph 9935 : ... histogramming Middlebury Optical Flow ...\n",
      "2021-02-04 22:31:28,618\toarph 9935 : ... display-ifying examples for Middlebury Optical Flow ...\n",
      "2021-02-04 22:31:49,709\toarph 9935 : Wrote Bokeh figure to /outer_root/host_mnt/Volumes/970-evo-raid0/Forwards_PSNR.html\n",
      "2021-02-04 22:31:49,711\toarph 9935 : Plotting histogram for Forwards_RMSE of DataFrame[Backwards_Edges_MSE: double, Backwards_MSE: double, Backwards_PSNR: double, Backwards_RMSE: double, Backwards_SSIM: double, Forwards_Edges_MSE: double, Forwards_MSE: double, Forwards_PSNR: double, Forwards_RMSE: double, Forwards_SSIM: double, flow_coverage: double, fp: struct<__pyclass__:string,dataset:string,flow:struct<__pyclass__:string,path:string>,id1:string,id2:string,img1:string,img2:string>] ...\n",
      "2021-02-04 22:31:51,385\toarph 9935 : ... building data source for ALL ...\n",
      "2021-02-04 22:31:51,387\toarph 9935 : ... histogramming ALL ...\n",
      "2021-02-04 22:31:54,034\toarph 9935 : ... display-ifying examples for ALL ...\n",
      "2021-02-04 22:32:28,001\toarph 9935 : ... building data source for DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:32:28,057\toarph 9935 : ... histogramming DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:32:31,623\toarph 9935 : ... display-ifying examples for DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:32:58,243\toarph 9935 : ... building data source for KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:32:58,289\toarph 9935 : ... histogramming KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:33:01,778\toarph 9935 : ... display-ifying examples for KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:33:51,252\toarph 9935 : ... building data source for Middlebury Optical Flow ...\n",
      "2021-02-04 22:33:51,301\toarph 9935 : ... histogramming Middlebury Optical Flow ...\n",
      "2021-02-04 22:33:54,676\toarph 9935 : ... display-ifying examples for Middlebury Optical Flow ...\n",
      "2021-02-04 22:34:20,444\toarph 9935 : Wrote Bokeh figure to /outer_root/host_mnt/Volumes/970-evo-raid0/Forwards_RMSE.html\n",
      "2021-02-04 22:34:20,447\toarph 9935 : Plotting histogram for Forwards_SSIM of DataFrame[Backwards_Edges_MSE: double, Backwards_MSE: double, Backwards_PSNR: double, Backwards_RMSE: double, Backwards_SSIM: double, Forwards_Edges_MSE: double, Forwards_MSE: double, Forwards_PSNR: double, Forwards_RMSE: double, Forwards_SSIM: double, flow_coverage: double, fp: struct<__pyclass__:string,dataset:string,flow:struct<__pyclass__:string,path:string>,id1:string,id2:string,img1:string,img2:string>] ...\n",
      "2021-02-04 22:34:22,621\toarph 9935 : ... building data source for ALL ...\n",
      "2021-02-04 22:34:22,623\toarph 9935 : ... histogramming ALL ...\n",
      "2021-02-04 22:34:26,068\toarph 9935 : ... display-ifying examples for ALL ...\n",
      "2021-02-04 22:35:10,277\toarph 9935 : ... building data source for DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:35:10,326\toarph 9935 : ... histogramming DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:35:13,656\toarph 9935 : ... display-ifying examples for DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:35:34,021\toarph 9935 : ... building data source for KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:35:34,065\toarph 9935 : ... histogramming KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:35:37,471\toarph 9935 : ... display-ifying examples for KITTI Scene Flow 2015 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-04 22:36:23,984\toarph 9935 : ... building data source for Middlebury Optical Flow ...\n",
      "2021-02-04 22:36:24,028\toarph 9935 : ... histogramming Middlebury Optical Flow ...\n",
      "2021-02-04 22:36:27,330\toarph 9935 : ... display-ifying examples for Middlebury Optical Flow ...\n",
      "2021-02-04 22:36:53,875\toarph 9935 : Wrote Bokeh figure to /outer_root/host_mnt/Volumes/970-evo-raid0/Forwards_SSIM.html\n",
      "2021-02-04 22:36:53,877\toarph 9935 : Plotting histogram for flow_coverage of DataFrame[Backwards_Edges_MSE: double, Backwards_MSE: double, Backwards_PSNR: double, Backwards_RMSE: double, Backwards_SSIM: double, Forwards_Edges_MSE: double, Forwards_MSE: double, Forwards_PSNR: double, Forwards_RMSE: double, Forwards_SSIM: double, flow_coverage: double, fp: struct<__pyclass__:string,dataset:string,flow:struct<__pyclass__:string,path:string>,id1:string,id2:string,img1:string,img2:string>] ...\n",
      "2021-02-04 22:36:55,999\toarph 9935 : ... building data source for ALL ...\n",
      "2021-02-04 22:36:56,001\toarph 9935 : ... histogramming ALL ...\n",
      "2021-02-04 22:36:59,710\toarph 9935 : ... display-ifying examples for ALL ...\n",
      "2021-02-04 22:37:58,341\toarph 9935 : ... building data source for DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:37:58,401\toarph 9935 : ... histogramming DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:38:01,827\toarph 9935 : ... display-ifying examples for DeepDeform Semi-Synthetic Optical Flow ...\n",
      "2021-02-04 22:38:59,508\toarph 9935 : ... building data source for KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:38:59,550\toarph 9935 : ... histogramming KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:39:03,726\toarph 9935 : ... display-ifying examples for KITTI Scene Flow 2015 ...\n",
      "2021-02-04 22:39:51,231\toarph 9935 : ... building data source for Middlebury Optical Flow ...\n",
      "2021-02-04 22:39:51,281\toarph 9935 : ... histogramming Middlebury Optical Flow ...\n",
      "2021-02-04 22:39:55,436\toarph 9935 : ... display-ifying examples for Middlebury Optical Flow ...\n",
      "2021-02-04 22:40:21,449\toarph 9935 : Wrote Bokeh figure to /outer_root/host_mnt/Volumes/970-evo-raid0/flow_coverage.html\n"
     ]
    }
   ],
   "source": [
    "class Plotter(pl.HistogramWithExamplesPlotter):\n",
    "    NUM_BINS = 10\n",
    "    ROWS_TO_DISPLAY_PER_BUCKET = 3\n",
    "    SUB_PIVOT_COL = 'fp.dataset'\n",
    "\n",
    "    def display_bucket(self, sub_pivot, bucket_id, irows):\n",
    "        import itertools\n",
    "        \n",
    "        row_htmls = []\n",
    "        for row in itertools.islice(irows, self.ROWS_TO_DISPLAY_PER_BUCKET):\n",
    "            rowdata = RowAdapter.from_row(row)\n",
    "            \n",
    "            fp = rowdata['fp']\n",
    "            recon = FlowReconstructedImagePair.create_from(fp)\n",
    "            fstats = OFlowStats.create_from(fp)\n",
    "            errors = OFlowReconErrors(recon)\n",
    "            \n",
    "            row_html = \"<br/>\".join((fp.to_html(), recon.to_html(), fstats.to_html(), errors.to_html()))\n",
    "            row_htmls.append(row_html)\n",
    "        \n",
    "        HTML = \"\"\"\n",
    "        <b>Pivot: {spv} Bucket: {bucket_id} </b> <br/>\n",
    "        \n",
    "        {row_bodies}\n",
    "        \"\"\".format(\n",
    "              spv=sub_pivot,\n",
    "              bucket_id=bucket_id,\n",
    "              row_bodies=\"<br/><br/><br/>\".join(row_htmls))\n",
    "        \n",
    "        return bucket_id, HTML\n",
    "\n",
    "plotter = Plotter()\n",
    "\n",
    "for col in df.columns:\n",
    "    col = str(col)\n",
    "    if col == 'fp':\n",
    "        continue\n",
    "    \n",
    "    fig = plotter.run(df, col)\n",
    "    pl.save_bokeh_fig(fig, '/outer_root/host_mnt/Volumes/970-evo-raid0/%s.html' % col)\n",
    "\n",
    "# from bokeh.io import output_notebook\n",
    "# output_notebook()\n",
    "# from bokeh.plotting import show\n",
    "# show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
